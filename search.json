[
  {
    "objectID": "topics.html",
    "href": "topics.html",
    "title": "Topics",
    "section": "",
    "text": "What is a topic?\n\n\n\nA topic is a specific subject that can be helpful to know about in your daily research. Each page can be read on its own. These pages are a quick way to learn about specific things.\nMissing a topic? You can submit suggestion using the Contribution portal.\n\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nADA HPC\n\n\n4 min\n\n\n\n\n\n\nAcademic Integrity\n\n\n3 min\n\n\n\n\n\n\nCARE Principles\n\n\n7 min\n\n\n\n\n\n\nCitation File Format (CFF)\n\n\n1 min\n\n\n\n\n\n\nData Archiving\n\n\n2 min\n\n\n\n\n\n\nData Backup\n\n\n3 min\n\n\n\n\n\n\nData Citation\n\n\n2 min\n\n\n\n\n\n\nData Classification\n\n\n4 min\n\n\n\n\n\n\nData Collection\n\n\n6 min\n\n\n\n\n\n\nData Documentation\n\n\n3 min\n\n\n\n\n\n\nData Licensing\n\n\n4 min\n\n\n\n\n\n\nData Management Plan (DMP)\n\n\n6 min\n\n\n\n\n\n\nData Management Section\n\n\n1 min\n\n\n\n\n\n\nData Protection\n\n\n5 min\n\n\n\n\n\n\nData Publishing\n\n\n4 min\n\n\n\n\n\n\nData Registration in PURE\n\n\n2 min\n\n\n\n\n\n\nData Storage\n\n\n5 min\n\n\n\n\n\n\nDataverseNL\n\n\n4 min\n\n\n\n\n\n\nEthical Review\n\n\n1 min\n\n\n\n\n\n\nFAIR Principles\n\n\n4 min\n\n\n\n\n\n\nFinding Existing Data\n\n\n5 min\n\n\n\n\n\n\nFinding Existing Research Software\n\n\n5 min\n\n\n\n\n\n\nGeneral Data Protection Regulation\n\n\n3 min\n\n\n\n\n\n\nIT for Research (ITvO)\n\n\n2 min\n\n\n\n\n\n\nKnowledge Security\n\n\n4 min\n\n\n\n\n\n\nMetadata\n\n\n4 min\n\n\n\n\n\n\nOpen Science\n\n\n2 min\n\n\n\n\n\n\nOpen Science Framework (OSF)\n\n\n5 min\n\n\n\n\n\n\nPersistent Identifier\n\n\n3 min\n\n\n\n\n\n\nPure (VU Research Information System)\n\n\n4 min\n\n\n\n\n\n\nQualtrics\n\n\n5 min\n\n\n\n\n\n\nResearch Data Management (RDM)\n\n\n1 min\n\n\n\n\n\n\nResearch Data and Software Management Policy\n\n\n2 min\n\n\n\n\n\n\nResearch Data and Software Management Terminology\n\n\n4 min\n\n\n\n\n\n\nResearch Drive\n\n\n4 min\n\n\n\n\n\n\nResearch Software\n\n\n2 min\n\n\n\n\n\n\nSURF Research Cloud\n\n\n3 min\n\n\n\n\n\n\nSafe Data Transportation and Transfer\n\n\n4 min\n\n\n\n\n\n\nSciCloud\n\n\n3 min\n\n\n\n\n\n\nSciStor\n\n\n7 min\n\n\n\n\n\n\nSnellius\n\n\n3 min\n\n\n\n\n\n\nSoftware Archiving\n\n\n5 min\n\n\n\n\n\n\nSoftware Licensing\n\n\n3 min\n\n\n\n\n\n\nSoftware Publishing\n\n\n6 min\n\n\n\n\n\n\nSoftware Registration in PURE\n\n\n2 min\n\n\n\n\n\n\nStoring vs. Archiving Data\n\n\n5 min\n\n\n\n\n\n\nTrainings\n\n\n7 min\n\n\n\n\n\n\nVU Compute Hub\n\n\n2 min\n\n\n\n\n\n\nYoda\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/02-plan-design.html",
    "href": "lifecycle/02-plan-design.html",
    "title": "Plan & Design",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nData Classification\n\n\n4 min\n\n\n\n\n\n\nData Management Plan (DMP)\n\n\n6 min\n\n\n\n\n\n\nData Management Section\n\n\n1 min\n\n\n\n\n\n\nEthical Review\n\n\n1 min\n\n\n\n\n\n\nGeneral Data Protection Regulation\n\n\n3 min\n\n\n\n\n\n\nResearch Data and Software Management Policy\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/02-plan-design.html#topics",
    "href": "lifecycle/02-plan-design.html#topics",
    "title": "Plan & Design",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nData Classification\n\n\n4 min\n\n\n\n\n\n\nData Management Plan (DMP)\n\n\n6 min\n\n\n\n\n\n\nData Management Section\n\n\n1 min\n\n\n\n\n\n\nEthical Review\n\n\n1 min\n\n\n\n\n\n\nGeneral Data Protection Regulation\n\n\n3 min\n\n\n\n\n\n\nResearch Data and Software Management Policy\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/02-plan-design.html#guides",
    "href": "lifecycle/02-plan-design.html#guides",
    "title": "Plan & Design",
    "section": "Guides",
    "text": "Guides\n\n\n\n\n\n\n\n\n\n\nHow can you comply with the GDPR?\n\n\nPersonal data must be protected.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you set up research data management from the start?\n\n\nA good plan is half the work.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/05-document-preserve.html",
    "href": "lifecycle/05-document-preserve.html",
    "title": "Document & Preserve",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nData Archiving\n\n\n2 min\n\n\n\n\n\n\nData Documentation\n\n\n3 min\n\n\n\n\n\n\nDataverseNL\n\n\n4 min\n\n\n\n\n\n\nFAIR Principles\n\n\n4 min\n\n\n\n\n\n\nMetadata\n\n\n4 min\n\n\n\n\n\n\nPersistent Identifier\n\n\n3 min\n\n\n\n\n\n\nSoftware Archiving\n\n\n5 min\n\n\n\n\n\n\nStoring vs. Archiving Data\n\n\n5 min\n\n\n\n\n\n\nYoda\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/05-document-preserve.html#topics",
    "href": "lifecycle/05-document-preserve.html#topics",
    "title": "Document & Preserve",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nData Archiving\n\n\n2 min\n\n\n\n\n\n\nData Documentation\n\n\n3 min\n\n\n\n\n\n\nDataverseNL\n\n\n4 min\n\n\n\n\n\n\nFAIR Principles\n\n\n4 min\n\n\n\n\n\n\nMetadata\n\n\n4 min\n\n\n\n\n\n\nPersistent Identifier\n\n\n3 min\n\n\n\n\n\n\nSoftware Archiving\n\n\n5 min\n\n\n\n\n\n\nStoring vs. Archiving Data\n\n\n5 min\n\n\n\n\n\n\nYoda\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/05-document-preserve.html#guides",
    "href": "lifecycle/05-document-preserve.html#guides",
    "title": "Document & Preserve",
    "section": "Guides",
    "text": "Guides\n\n\n\n\n\n\n\n\n\n\nHow can you ensure research data is FAIR?\n\n\nMaking your data Findable, Accessible, Interopable, Reusable is more doable than you might think.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/06-publish-share.html",
    "href": "lifecycle/06-publish-share.html",
    "title": "Publish & Share",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nData Licensing\n\n\n4 min\n\n\n\n\n\n\nData Publishing\n\n\n4 min\n\n\n\n\n\n\nData Registration in PURE\n\n\n2 min\n\n\n\n\n\n\nDataverseNL\n\n\n4 min\n\n\n\n\n\n\nFAIR Principles\n\n\n4 min\n\n\n\n\n\n\nOpen Science Framework (OSF)\n\n\n5 min\n\n\n\n\n\n\nPersistent Identifier\n\n\n3 min\n\n\n\n\n\n\nSoftware Licensing\n\n\n3 min\n\n\n\n\n\n\nSoftware Publishing\n\n\n6 min\n\n\n\n\n\n\nSoftware Registration in PURE\n\n\n2 min\n\n\n\n\n\n\nYoda\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/06-publish-share.html#topics",
    "href": "lifecycle/06-publish-share.html#topics",
    "title": "Publish & Share",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nData Licensing\n\n\n4 min\n\n\n\n\n\n\nData Publishing\n\n\n4 min\n\n\n\n\n\n\nData Registration in PURE\n\n\n2 min\n\n\n\n\n\n\nDataverseNL\n\n\n4 min\n\n\n\n\n\n\nFAIR Principles\n\n\n4 min\n\n\n\n\n\n\nOpen Science Framework (OSF)\n\n\n5 min\n\n\n\n\n\n\nPersistent Identifier\n\n\n3 min\n\n\n\n\n\n\nSoftware Licensing\n\n\n3 min\n\n\n\n\n\n\nSoftware Publishing\n\n\n6 min\n\n\n\n\n\n\nSoftware Registration in PURE\n\n\n2 min\n\n\n\n\n\n\nYoda\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/06-publish-share.html#guides",
    "href": "lifecycle/06-publish-share.html#guides",
    "title": "Publish & Share",
    "section": "Guides",
    "text": "Guides\n\n\n\n\n\n\n\n\n\n\nHow can you archive and publish your data?\n\n\nAll data and software leading to a published result, must be archived and published.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you publish FAIR software\n\n\nA step-wise guide to make your software Findable, Accesible, Interoperable and Reusable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you use Open Science Framework (OSF) in your research project?\n\n\nOSF supports an open research life cycle.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2024-05-23welcome.html",
    "href": "blog/2024-05-23welcome.html",
    "title": "Hello world!",
    "section": "",
    "text": "This is the first blog entry on the Research Support Handbook. We will be posting more at a later time, and are looking forward to your contributions as well.\nWe will follow up with more details later."
  },
  {
    "objectID": "blog/2024-11-01hackathon.html",
    "href": "blog/2024-11-01hackathon.html",
    "title": "Fourth Handbook Hackathon",
    "section": "",
    "text": "On October 30th, 2024, all authors participated in the fourth hackathon for the Research Support Handbook. Since the third hackathon, we migrated to rdm.vu.nl, which is a huge milestone! 🎉\nFor the fourth hackathon, we focused on tying up loose ends that we accumulated. The migration means we are now in a stable state, yet there is always more work to be done. During this hackathon, we focused on picking up stale discussions, reviewing open pull requests, and generally closing issues that we took too long to revisit.\nWe considered how (un)balanced the various Topics had gotten, because we want readers to be able to form consistent expectations. We observed that some topics are related to tools, others to concepts. Some topics are concise, whereas others are lengthy.\nOne breakout group focused on creating templates for both kinds of topics, resulting in an initial structure that will make it easier to start new topics in the future. Specifically we propose the following template structure for tools (for example, Qualtrics, HPC, DMPonline):\nAnd the following structure for concepts (for example, DMP, data citation, data storage):\nWe will follow up with a new hackathon in late november."
  },
  {
    "objectID": "blog/2024-11-01hackathon.html#issues-worked-on",
    "href": "blog/2024-11-01hackathon.html#issues-worked-on",
    "title": "Fourth Handbook Hackathon",
    "section": "Issues worked on",
    "text": "Issues worked on\nhttps://github.com/ubvu/open-handbook/issues/232\nhttps://github.com/ubvu/open-handbook/issues/233"
  },
  {
    "objectID": "blog/2024-11-01hackathon.html#pull-requests-worked-on",
    "href": "blog/2024-11-01hackathon.html#pull-requests-worked-on",
    "title": "Fourth Handbook Hackathon",
    "section": "Pull Requests worked on",
    "text": "Pull Requests worked on\nhttps://github.com/ubvu/open-handbook/pull/229\nhttps://github.com/ubvu/open-handbook/pull/231\nhttps://github.com/ubvu/open-handbook/pull/234\nhttps://github.com/ubvu/open-handbook/pull/235\nhttps://github.com/ubvu/open-handbook/pull/236\nhttps://github.com/ubvu/open-handbook/pull/237"
  },
  {
    "objectID": "blog/2024-06-27hackathon.html",
    "href": "blog/2024-06-27hackathon.html",
    "title": "First Handbook Hackathon",
    "section": "",
    "text": "On June 27th, 2024, the first hackathon for the Research Support Handbook took place with all the post authors. For this hackathon, we focused on non-GitHub based contributions, to make it as easy as possible to contribute. To make getting started with contributing easier, we created a choose your own adventure game. We document some lessons and clarifications below, in addition to the twelve reported problems and suggested changes.\nThe workshop helped articulate the dynamic relation between topics and pathways. Topics are contained pages around a specific subject; pathways are a collection of topics. This means that pathways include the topics directly and that this content should be up to date at any given time. When topics are changed, pathways are dynamically updated, making sure there are no discrepancies. The only situation where this may not be the case, is when a pathway is still a work in progress and the topics are not yet properly linked.\nPathways will become more efficient to create as we include more topics in the handbook. Given that pathways are primarily collections of topics, this means that there is barely any new content in there, if any at all. As we include more topics (eight at this time), pathways can focus more and more on the structuring of content, and focus less on creating the content itself.\nWith new contributions, contributors surfaced the need to preview the changes to the handbook. We documented two ways to render the handbook for such previews: (1) creating a Pull Request automatically deploys a preview website and (2) running quarto render locally on the code. Option 1 requires no additional software to be installed, but requires some knowledge of GitHub. Option 2 does not require much knowledge of GitHub, but requires the Quarto software to be installed. There was also the note that deploying the handbook using GitHub pages required a change to the URL, which may cause issues when merging the changes back into the main handbook. This highlights that ensuring reliable previews of contributed content is of importance to some contributors to the handbook.\nLastly, the hackathon surfaced many questions and discussions around the collaborative decisions that will need to be made. When does a topic become too long and should it be split up into multiple topics? Can a topic include subtopics? How is the GitHub environment maintained? How much technical expertise is necessary to ensure the content does not go offline? What contributor roles are there and who has which role? How do roles get distributed and can people volunteer for them? This highlights the engagement with the handbook, and we encourage everyone (including ourselves) to generously surface these discussions in issues or in a next hackathon.\nIn summary, the first hackathon is a success! This is the start of the next phase of the handbook journey, moving from design and scaffolding to nurturing and growing the contents. There will be more hackathons, and these will be announced on this blog and on other channels at VU Amsterdam. Until the next one!"
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html",
    "href": "blog/2024-10-22post-mortem.html",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "",
    "text": "On Friday October 18th 2024, we experienced around ten hours of downtime on the rdm.vu.nl website. The downtime started around 10AM after merging changes to the handbook and was resolved the same day, by 8PM.1"
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#root-cause",
    "href": "blog/2024-10-22post-mortem.html#root-cause",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "Root cause",
    "text": "Root cause\nThe downtime started after merging changes to the handbook in commit 669b065. These changes themselves, did not cause the downtime. The root cause was an incorrect configuration in the deployment of the webpage, which inadvertently removed the rdm.vu.nl domain name from the GitHub settings every time we made changes in the handbook and redeployed the website. This resulted in 404 errors that the page could not be found.\nWe first observed this issue on Thursday, one day prior to the downtime, in commit 678ff88. We proposed a fix for this issue in #220, before the downtime started."
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#how-could-the-downtime-happen-if-the-fix-was-clear",
    "href": "blog/2024-10-22post-mortem.html#how-could-the-downtime-happen-if-the-fix-was-clear",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "How could the downtime happen if the fix was clear?",
    "text": "How could the downtime happen if the fix was clear?\nThe fix for the domain specification was not merged in time for two reasons.\n\nReason 1\nAt this time, we require two reviews before merging changes to the handbook. The fix was proposed at 1.11PM on Thursday, and did not receive the required reviews by the time the downtime happened (reason 1). However, this was a technical administration task and could have been merged immediately, as this supercedes regular review procedures.\n\n\nReason 2\nThe domain specification fix was not immediately merged to allow time to pass and ensure the fix was appropriate upon further reflection. This is because administrator (chartgerink?) both proposed the fix and would also be the one to supercede the “two reviews” requirement. Due to travel, the administrator forgot about it in the morning, and only saw the messages about the downtime at 8PM. At that time, the fix was quickly merged and the downtime resolved."
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#improvements",
    "href": "blog/2024-10-22post-mortem.html#improvements",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "Improvements",
    "text": "Improvements\nThe domain configuration is corrected and the deployment ensures the domain name is re-added to the GitHub settings every time there are changes to the handbook. This is now automated, which ensures that the domain name will not be removed inadvertently when future changes are incorporated.\nHowever, we also learned that critical administration fixes should not be left open for longer than is absolutely necessary. Here it was left open for longer than absolutely necessary due to travel, and a second administrator could have caught this issue sooner. This means we should work towards resilient reporting mechanisms to escalate such critical issues, and build capacity in the editor team to ensure no one person is responsible for merging critical fixes that are already available."
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#acknowledgements",
    "href": "blog/2024-10-22post-mortem.html#acknowledgements",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to thank the editors for dealing with the stress from this inadvertent issue. We also thank the community for their patience as we only recently migrated to rdm.vu.nl and figure out these initial unexpected hurdles."
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#references",
    "href": "blog/2024-10-22post-mortem.html#references",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "References",
    "text": "References\n\nRoot cause for the downtime first observed in commit 678ff88\nProposed a fix for the root cause in pull Request #220\nDowntime started at commit 669b065 is where the\nResolved downtime in commit 678ff88"
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#footnotes",
    "href": "blog/2024-10-22post-mortem.html#footnotes",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nubvu.github.io/open-handbook remained online during this entire time, and functions indirectly as a backup.↩︎"
  },
  {
    "objectID": "blog/2025-07-29itvoblog.html",
    "href": "blog/2025-07-29itvoblog.html",
    "title": "ITvO blog",
    "section": "",
    "text": "From now on the ITvO (IT for Research) team will be using the Handbook Blog for sharing news, updates, and important announcements related to SciCloud, ADA HPC, SciStor, and other services provided by ITvO. Here you will find information about new features, scheduled maintenance, service improvements. Stay tuned for the latest developments and insights from the ITvO team."
  },
  {
    "objectID": "blog/2025-07-29itvoblog.html#first-itvo-blog",
    "href": "blog/2025-07-29itvoblog.html#first-itvo-blog",
    "title": "ITvO blog",
    "section": "",
    "text": "From now on the ITvO (IT for Research) team will be using the Handbook Blog for sharing news, updates, and important announcements related to SciCloud, ADA HPC, SciStor, and other services provided by ITvO. Here you will find information about new features, scheduled maintenance, service improvements. Stay tuned for the latest developments and insights from the ITvO team."
  },
  {
    "objectID": "guides/discover-and-initiate.html",
    "href": "guides/discover-and-initiate.html",
    "title": "How can you discover and reuse existing research data?",
    "section": "",
    "text": "Re-using Existing Data\nAnything that can be used for analysis can be considered “data(sets)”. Many national and international organisations provide access to large datasets free of charge: this is called Open Data.\nDatasets may contain different kinds of data files, e.g. raw or edited/cleaned data, and macro or micro data. Raw data refers to the data as they are primarily collected, and includes all data, even the missed or mismatched pieces in the data file. Edited or cleaned data refers to data that have been tidied up for analysis and publication. Macro data and statistics are results based on micro data units and provide a general overview of the micro data. Although datasets can contain data of varying type or aggregation level, and there may be overlap between these definitions, each element can contain very important information.\nWhen re-using research data, scientists must be familiar with the rules and regulations governing data copyright, intellectual property rights, and laws governing sensitive or personal information. SURF has compiled a report on the legal status of raw data including information on the types of consent required for the re-use of data. Your 🔒 Privacy Champion can answer questions about the use of personal data. IXA can provide legal help with the re-use of data.\nSee also the ZonMw explanation of different kinds of property rights in the Netherlands (text available in Dutch only).\n\n\nSources for Finding Existing Datasets\nThe number of datasets that are available grows rapidly. Datasets are made available in many formats, by many people or organizations. Some datasets are raw files and some are specifically organised and formatted as databases that require a licence or subscription to use them. The library of VU Amsterdam has collected links to some of the data repositories used and has licensed several databases.\n\nPopular Free and Licensed Databases: These can be found with LibSearch Advanced.\n\nIf you need help finding & using free or licensed sources you can contact the Research Data Services Helpdesk. For students and personnel in the fields of economics, finance, or organisation science a separate LibGuide has been created to help them find and use/re-use data.\nYou can also start looking for data in these four places:\n\nThe literature. Research articles may point you to the data that they are based on. Sometimes, (part of) the data are added to the article as supplementary files, and sometimes the data are published separately in a data repository. In the latter case, the article usually provides a clear reference to the published dataset. Some datasets may even be specifically published in Data Journals.\nScientific data repositories. Data repositories are platforms used to access and archive research data. Universities often provide a repository for data archiving, but other platforms arranged by discipline or by country also exist. Some repositories are only accessible to consortium members, whereas others are free of charge. Many universities in the Netherlands use DataverseNL to archive datasets for the mid-term. Long-term archiving is provided by the national research data archives DANS and 4TU.Research Data. In Europe, B2SHARE and Zenodo are platforms used to access research data. Data repositories can be accessed by searching by topic or country using Re3data, a data repository registry. VU Amsterdam has its own research portal, PURE, where researchers register their datasets. You can find instructions on how to register your own dataset in PURE on the Dataset Registration page of this LibGuide.\nData search engines. Search engines allow you to quickly browse data sets and supplementary data files published by researchers. They cover data sets from many sources. This makes them useful for quick orientation on a topic. Example of a search engines are: DataCite, Google DataSet Search.\nData portals of (governmental) organisations. Organisations that regularly collect (statistical) data sometimes offer these data through their own portal. An example is Eurostat, which collects and disseminates statistics at the European level, by country and by theme. Some of these websites have been linked in the Finding data LibGuide.\n\n\n\nData Sources for VU Researchers\nResearchers from VU Amsterdam have also developed some databases containing data collected during research. See here for some examples:\n\nNederlands Tweelingenregister (Netherlands Twin Register) The database contains data on twins and their families and was created to do research on the relationship between genetics and growth, development, personality, behaviour, diseases, mental health and all kinds of risks.\nGeoplaza VU - the portal for all matters related to GIS (Geographical Information Systems) and geodata at VU Amsterdam. It offers students and employers a platform to exchange, examine and download digital map material.\nDutch monasteries - database with information about Dutch monasteries of the Middle Ages.\nSlave owners in Amsterdam 1863 - the place of living of owners of slaves in Amsterdam in 1863, visualized in GeoPlaza.\nDeaths at the Borders Database - collection of official, state-produced evidence on people who died while attempting to reach southern EU countries from the Balkans, the Middle East, and North & West Africa, and whose bodies were found in or brought to Europe.\nDatasets published by VU Researchers can be found at the VU Research Portal.\n\n\n\nCitation Elements\nCiting data is not different from citing a journal publication. Similar to citing a journal publication, it helps to give and receive credit, and show the impact of the original source.\nMake sure to check the rules of the journal to know how you should cite when writing an article for a specific academic journal. For all of the journals, however, the minimum compulsory elements in a data citation include:\n\nAuthor(s): Name of the author (creator) of the dataset\nTitle: Name of the dataset\nDate of publication\nPublisher: Archive where dataset is stored\nPersistent Identifier: Unique identifier, most common is the DOI (see section Persistent Identifier).\n\nOptional elements that may be included in the reference are:\n\nFile Type: Codebook, movie, software\nVersion: Version number of the edition\nCreation Date\nDate of Consultation (last)\n\nIf you (re)used another, openly accessible dataset to create your own, it is also important to (first check that the original dataset’s licence permits this and to) cite that dataset correctly. If you want to make clear in a journal article that another dataset was reused, you can add this information, including a citation to the original dataset, to the data availability statement, besides the reference list. In your own dataset, you can use the README file to cite the original dataset and explain how it was reused. You should also add documentation about what processing you did to the original dataset to create your own, and refer to this documentation in the README file. Many repositories prescribe a standard way to cite datasets for several citation styles, and one can very often simply copy and paste that. For example, Zenodo has a citation box on the bottom right of the page, and there one can choose a citation style and simply copy that or export the citation to a citation file (which is useful if you are using EndNote or Zotero). The same can be done in Datacite (example).\n\nExample data citation\nStephens, William, 2020, “Resiliences to Radicalisation - QSort Data”, https://doi.org/10.34894/35MTMN, DataverseNL, V1.\n\nFor more information, see the following guidelines:\n\nDataverse\nDataCite\nDCC UK\nData Citation Synthesis Group (2014). Joint Declaration of Data Citation Principles. Martone M. (ed.) San Diego CA: FORCE11\nCESSDA on accessing, using and citing data\nCESSDA on citing your own data\n\nRelevant is also the Citation File Format (CFF)."
  },
  {
    "objectID": "guides/plan-and-design.html",
    "href": "guides/plan-and-design.html",
    "title": "How can you set up research data management from the start?",
    "section": "",
    "text": "Grant programmes from organisations like NWO, ZonMw and ERC require you to think about the method of data collection, the journey of the data in your research project and how to protect or share data during and after the research project. It is important to bear in mind the specific laws and regulations that apply to the kind of data that is collected. If a project involves data on individuals and organisations this impacts the design of the necessary IT infrastructure. A more detailed description of this will later be captured in the data management plan.\nWhen writing your research proposal the following items are important:\n\nFill in the Data Management Section if your funder requires this\nPlanning: One of the early deliverables will be a detailed Data Management Plan. Instructions for writing a DMP are available in the DMP section below. You can find more information about aspects to be addressed in a DMP in RDM requirements, Collaboration, Data Security, GDPR & Privacy and Policies & Regulations.\nBudget: Take into account the costs (labour and material) for data storage during and data archiving after your project.\nWriting: Funders that distribute grants like to maximise the effectiveness of this investment. It is therefore highly recommended that the data will be made Findable, Accessible, Interoperable and Re-usable (FAIR Principles). For that reason, it is useful to make explicit in your proposal how you will aim to make your data FAIR. This does not mean that the data have to be open: Laws, licenses and contracts regarding personal and sensitive data may limit the possibility to share the data publicly.\n\nThe RDM Support Desk provides advice and help when writing a Data Management Section as part of the research proposal. Also make sure to reach out to VU Amsterdam Grants Office (IXA-GO) for advice and practical aid for your grant in general as early as possible.\n\n\nMany funders require researchers to include a section in their project proposal about Research Data Management, in which they explain whether existing data will be reused, whether new data will be collected or generated during the project, and how they plan to structure, archive and share their data. Depending on requirements of the funder, the paragraph can be short or more extensive.\nFunders may have different requirements for the data management section in the project proposal. Always check what your funder asks for. Below is a list of information on data management sections from main Dutch funding bodies.\n\nNWO\nZonMw\n\nWe recommend you to ask advice from the RDM Support Desk when writing your data management section.\n\n\n\nMany research funders encourage applicants to include data management and sharing costs in research proposals. Some funders will provide advice on costs related to data management. Some remarks on costs are provided here:\n\nThe Data Management Plan should describe the activities that incur costs and provide justification for the allocation of resources (example: acquisition of a programmer who will write software needed to capture the data).\nNo expenditure can be ‘double funded’, i.e. a service that is centrally supported by indirect costs must not be included as a direct cost as well (example: computers that are already provided to employees and paid for by the university may not be included).\nThe budget and justification should broadly indicate where RDM costs will be incurred, where possible. E.g. data capture and cleaning, data curation and preservation, data sharing.\nInclude budget for long-term storage if data are expected to be deposited in a repository not funded by the university or external funders (VU repositories are: DataverseNL, Yoda). 🔒 VU has an internal breakdown of costs for storage and archiving for VU-managed storage and repositories.\n\nA practical costing tool is available from the UK Data Archive. Based on this costing tool, Utrecht University has developed a guide to calculate the costs of data management. You can use those guides as well to estimate the costs needed specifically for RDM.\nMost material costs of the storage solutions offered by VU Amsterdam are covered centrally (up to 500 GB), but if you need to specify the costs for your project, look at the 🔒 Research & Archiving Storage Cost Model\nExamples to put in a data management plan:\n\n\n\n\n\n\n\n\n\nData Stage\nDataset\nType of data\nCosts\n\n\n\n\nRaw data\nInterviews\nAudio files\nAudio equipment rental\n\n\n\n\n\nLocation rental costs\n\n\n\n\n\nData storage & backup\n\n\nProcessed data\nTranscription of interviews\nWord files\nPersonnel costs: hiring research assistants for manual entry\n\n\n\n\n\nData storage & backup\n\n\n\nAnalysis software\nR script\nPersonnel costs: programmer to write a programme to mine the data\n\n\nAnalysed data\nRegression graphic\nPhotoshop files\nSoftware costs\n\n\n\nProject Website\nHTML, Java\nHosting fee\n\n\n\n\n\nPersonnel to build initial website"
  },
  {
    "objectID": "guides/plan-and-design.html#research-proposal",
    "href": "guides/plan-and-design.html#research-proposal",
    "title": "How can you set up research data management from the start?",
    "section": "",
    "text": "Grant programmes from organisations like NWO, ZonMw and ERC require you to think about the method of data collection, the journey of the data in your research project and how to protect or share data during and after the research project. It is important to bear in mind the specific laws and regulations that apply to the kind of data that is collected. If a project involves data on individuals and organisations this impacts the design of the necessary IT infrastructure. A more detailed description of this will later be captured in the data management plan.\nWhen writing your research proposal the following items are important:\n\nFill in the Data Management Section if your funder requires this\nPlanning: One of the early deliverables will be a detailed Data Management Plan. Instructions for writing a DMP are available in the DMP section below. You can find more information about aspects to be addressed in a DMP in RDM requirements, Collaboration, Data Security, GDPR & Privacy and Policies & Regulations.\nBudget: Take into account the costs (labour and material) for data storage during and data archiving after your project.\nWriting: Funders that distribute grants like to maximise the effectiveness of this investment. It is therefore highly recommended that the data will be made Findable, Accessible, Interoperable and Re-usable (FAIR Principles). For that reason, it is useful to make explicit in your proposal how you will aim to make your data FAIR. This does not mean that the data have to be open: Laws, licenses and contracts regarding personal and sensitive data may limit the possibility to share the data publicly.\n\nThe RDM Support Desk provides advice and help when writing a Data Management Section as part of the research proposal. Also make sure to reach out to VU Amsterdam Grants Office (IXA-GO) for advice and practical aid for your grant in general as early as possible.\n\n\nMany funders require researchers to include a section in their project proposal about Research Data Management, in which they explain whether existing data will be reused, whether new data will be collected or generated during the project, and how they plan to structure, archive and share their data. Depending on requirements of the funder, the paragraph can be short or more extensive.\nFunders may have different requirements for the data management section in the project proposal. Always check what your funder asks for. Below is a list of information on data management sections from main Dutch funding bodies.\n\nNWO\nZonMw\n\nWe recommend you to ask advice from the RDM Support Desk when writing your data management section.\n\n\n\nMany research funders encourage applicants to include data management and sharing costs in research proposals. Some funders will provide advice on costs related to data management. Some remarks on costs are provided here:\n\nThe Data Management Plan should describe the activities that incur costs and provide justification for the allocation of resources (example: acquisition of a programmer who will write software needed to capture the data).\nNo expenditure can be ‘double funded’, i.e. a service that is centrally supported by indirect costs must not be included as a direct cost as well (example: computers that are already provided to employees and paid for by the university may not be included).\nThe budget and justification should broadly indicate where RDM costs will be incurred, where possible. E.g. data capture and cleaning, data curation and preservation, data sharing.\nInclude budget for long-term storage if data are expected to be deposited in a repository not funded by the university or external funders (VU repositories are: DataverseNL, Yoda). 🔒 VU has an internal breakdown of costs for storage and archiving for VU-managed storage and repositories.\n\nA practical costing tool is available from the UK Data Archive. Based on this costing tool, Utrecht University has developed a guide to calculate the costs of data management. You can use those guides as well to estimate the costs needed specifically for RDM.\nMost material costs of the storage solutions offered by VU Amsterdam are covered centrally (up to 500 GB), but if you need to specify the costs for your project, look at the 🔒 Research & Archiving Storage Cost Model\nExamples to put in a data management plan:\n\n\n\n\n\n\n\n\n\nData Stage\nDataset\nType of data\nCosts\n\n\n\n\nRaw data\nInterviews\nAudio files\nAudio equipment rental\n\n\n\n\n\nLocation rental costs\n\n\n\n\n\nData storage & backup\n\n\nProcessed data\nTranscription of interviews\nWord files\nPersonnel costs: hiring research assistants for manual entry\n\n\n\n\n\nData storage & backup\n\n\n\nAnalysis software\nR script\nPersonnel costs: programmer to write a programme to mine the data\n\n\nAnalysed data\nRegression graphic\nPhotoshop files\nSoftware costs\n\n\n\nProject Website\nHTML, Java\nHosting fee\n\n\n\n\n\nPersonnel to build initial website"
  },
  {
    "objectID": "guides/plan-and-design.html#data-management-plan",
    "href": "guides/plan-and-design.html#data-management-plan",
    "title": "How can you set up research data management from the start?",
    "section": "Data Management Plan",
    "text": "Data Management Plan\nIf you receive funding from a funder, one of the early deliverables will be a Data Management Plan. In general, every research benefits from writing a data management plan. It will help you to address data management aspects in a systematic way, so that you can set up useful RDM practices for your research and identify potential things for which you need to arrange something, like sufficient storage space, a particular data collection methodology, etc.\n\nWhat is a DMP\nA Data Management Plan (DMP) is a document outlining how research data will be handled throughout the research life cycle. A DMP is a structured way to address data collection, organization, storage, sharing, and preservation. It also outlines the measures taken to ensure data security and addresses how data will be preserved and made available for future use.\n\n\nDMPonline\nVU Amsterdam offers the online tool DMPonline for writing Data Management Plans. DMPonline is a platform that offers a range of templates, ensuring that researchers can create DMPs to meet the standards of diverse funders and institutions associated with their projects. DMPonline makes it easy to work on a DMP together with colleagues, advisors, or other stakeholders. VU Amsterdam researchers can use the request feedback function of DMPonline to get their DMP reviewed by a faculty data steward or RDM Support Desk colleague.\nInstructions for selecting the right DMP template in DMPonline are available in the guide How can you set up research data management from the start?.\nIf you have questions about DMPonline, or encounter problems when using the tool, please get in touch with rdm@vu.nl.\n\n\nWhat is data\nResearch data is any information that has been collected, observed, generated or created to validate original research findings. Examples of data could be interview recordings, experiment results, physical measurement, notes from focus group’s meetings, notes from fieldwork, observations captured in photographs, film or audio, text files extracted from a corpus, image of archival items or artworks, scraped websites, responses to survey questions. Algorithms, simulations, code, scripts and software are often also considered as research data. There is also physical data: (biological) samples, collections, artifacts etc.\nAdministrative documents, like informed consent forms and key files should be acknowledged as important elements of research data as well.\n\n\nData Assets\nAt VU Amsterdam, we sometimes use the term ‘Data Assets’. You can think of data assets as small ‘parcels’ of data that can change form or format throughout the research. For example, if you’re sending out surveys for your research, the survey responses are considered a data asset. If, in addition to the surveys, you’re also holding focus groups, the data collected from the focus group are also considered a data asset, separate from the survey results. Most projects will have more than one data asset per data stage. It is common to provide data assets based on the data stage such as raw, processed, or analysed. Raw Data refers to original data collected, Processed Data is data that has undergone some level of transformation or organisation. Processing involves cleaning, formatting, and structuring raw data to make them more understandable and suitable for analysis. Analysed Data usually results from statistical methods, detailed examination or interpretation.\nHere are some examples of data assets in research data management:\n\n\n\n\n\n\n\n\n\nData Stage\nDataset description\nType of data\nFormat\n\n\n\n\nRaw data\nInterviews\nAudio files\nMP3\n\n\n\nSpectographic analysis\nText files\nCSV\n\n\nProcessed data\nTranscription of interviews\nText files\nDocx\n\n\n\nData spreadsheet\nSPSS files\nSAV\n\n\nAnalysed data\nRegression graphic\nGraph\nPNG\n\n\n\nData table\nWord file\nDocx\n\n\nOther\nPoster presentation\nPowerpoint\nPPS\n\n\n\nProject Website\nHTML\n\n\n\n\nAnalysis code\nText files\nPython\n\n\n\nNote that these data assets also change in the different phases of the research! While the interview data are audio files in the raw stage, they are transcribed and become text files in the processed stage.\n\n\nDMP Elements\nVU Amsterdam DMP template consists of seven sections with questions. In DMPonline, there is guidance available for all sections, as well as example answers. When you are writing your DMP, you can consult this information directly in DMPonline. Below we provide references to information and support available for various RDM-related aspects.\n\nLegal and ethical requirements\n\nWorking with personal data\nIf you have questions about working with personal data in research, please get in touch with the Privacy Champion of your faculty. The 🔒 overview of Privacy Champions can be found on VU Amsterdam website. Make sure to contact your Privacy Champion in the following situations:\n\nIf you need to carry out a DPIA, or if you’re unsure if you need to do one\nIf you work with special category personal data, or otherwise very sensitive data\nIf you are collaborating with other parties\nIf you need software for which no licence is set up on behalf of VU Amsterdam\nIf you wish to reuse existing data containing personal data\n\nIt is impossible to provide an overview of tasks to be carried out to ensure compliance with the GDPR that fits all research projects. For that reason, it is important to contact your Privacy Champion. They will be able to identify what needs to be arranged to adhere to the GDPR.\n\n\nEthical Review\nIn cases where research involves human or animal participants, a research proposal may need to be reviewed by an ethics committee. VU Amsterdam and Amsterdam UMC (location VUmc), have several ethics committees, which are listed below. Please note that researchers at VU Amsterdam also have to go to the METc at VUmc if their research is subject to the WMO, which is not restricted to research at VUmc.\n\nEthics committees\n\nACTA: ACTA Ethics Review Board (ETC), Academisch Centrum Tandheelkunde Amsterdam\nBeta: Research ethics review committee Faculty of Science (BETHCIE), Faculty of Science\nFGB: 🔒 Scientific and Ethical Review Board (VCWE), Faculty of Behavioural and Movement Sciences\nFSG, Faculty of Social Sciences and Humanities:\n\nSGW: Ethische Toetsingscommissie Onderzoek (EtCO), School of Humanities\nSSW: 🔒 Research Ethics Review Committee (RERC), School of Social Sciences\n\nRCH: Ethics Committee, Faculty of Law\nSBE: Ethical Review Board (ERB), School of Business and Economics\nVUmc (Amsterdam UMC): Medical Ethical Review Committee (METc)\n\n\n\n\n\nStorage and backup during the research process\nAn overview of storage facilities at VU Amsterdam is available in the Data Storage Finder. You can use this as a starting point to navigate storage solutions.\nIf you have questions about data storage and backup, send an email to rdm@vu.nl.\n\n\nData archiving and publishing\nIf your research data contains personal data and you’re unsure about which data may be published, please contact your 🔒 Privacy Champion.\n\n\n\nChoosing the right template\nVarious templates exist in which you can set up your DMP. We strongly recommend that you use the VU template, which is called VU DMP template 2021 (NWO & ZonMw certified) v1.4. Below you’ll find an explanation of how to access this template. If you need to write a DMP for funding agencies NWO, ZonMw or ERC, you can use the VU template as well.\n\nVU template\nYou can find the VU DMP template in DMPonline. It includes concise guidance on how to complete your DMP.\nYou can select the VU template by taking the following steps (see also the picture below).\n\nOn your dashboard, click on Create plan.\nEnter the title of your research project (you don’t have to select the check box for mock testing).\nSelect Vrije Universiteit Amsterdam as your primary research organisation.\nFor the question on primary funding organisation, select the check box on the right, saying that no funder is associated with your plan.\n\nNote: Follow these steps as well if you receive funding from NWO or ZonMw (see also below).\n\n\n\nScreenshot of a form for creating a data management plan, asking for the research project, where it is being done, who is funding it and what template you would like to use.\n\n\nIf you’re aiming to write a full DMP based on VU Amsterdam DMP template, please make sure you don’t select the GDPR registration form.\n\n\n\nA screenshot highlighting to not use VU Amsterdam GDPR Registration form\n\n\n\n\nFunder template\nWe recommend researchers to use VU Amsterdam DMP template whenever possible, especially for researchers who work with personal data. The VU DMP template includes questions that serve as input for the GDPR record of processing activities. This means that when you write a DMP based on the VU DMP template, you simultaneousely comply with the VU requirement to register the personal data you use in your research.\nHowever, it is also possible to use other templates in DMPonline. If your funder or partner organization requires you to use a certain template, it is possible to select that template in DMPonline. Please follow the steps below to select a funder’s template.\n\nOn your dashboard, click on Create plan.\nEnter the title of your research project (you don’t have to select the check box for mock testing).\nSelect Vrije Universiteit Amsterdam as your primary research organisation.\nIn the field under Select the primary funding organisation, start typing the name of your funder and select their template.\n\n\n\n\nScreenshot of a filled out form for creating a data management plan, with example data included.\n\n\nResearchers who don’t work with personal data and who wish to use another DMP template than the VU template, can also follow the steps above.\n\n\nGDPR registration form\nIf you work with personal data, you need to register your processing activities. If you don’t need to write a (new) DMP, you can use the VU GDPR registration form for research v1.1. Your faculty’s 🔒 Privacy Champion can help you with your registration."
  },
  {
    "objectID": "guides/plan-and-design.html#rdm-requirements",
    "href": "guides/plan-and-design.html#rdm-requirements",
    "title": "How can you set up research data management from the start?",
    "section": "RDM Requirements",
    "text": "RDM Requirements\nIf you do research at VU Amsterdam, you may be subject to the requirements for Research Data Management formulated by various parties. Please check which requirements apply to your research project.\nMany funders have specific requirements for RDM. The exact requirements vary by funder. They usually include a Data Management Section in the project proposal and a Data Management Plan (DMP) after funding has been granted. As funding agencies invest financially in your research project, they often have demands concerning research integrity, data quality, data publication and reusability. As research output, data are often compared to a kind of public good that should be made available to the community for re-use if possible. Always check what demands are set by a funder before you apply.\n\nFunding agencies\n\nData management section in project proposal\nAt a grant application, some funders request a short data section in your project proposal or an outline of a Data Management Plan. Without these your proposal will not be eligible for review.\n\nNWO: Data management section\nZonMw: Orientation of data management in project proposal\n\n\n\nData Management Plan\nIn a Data Management Plan (DMP; see also the section Data Management Plan) you explain how you will handle your research data. Check with your funder at what stage a DMP has to be submitted and how it should be composed. VU has a DMP template that has been acknowledged by NWO, ZonMw and ERC. We recommend you to use this VU template. See the DMP page for more information and instructions on how to select this template in DMPonline.\nThe tool DMPonline can be used to access and fill in a DMP template. You can also write a DMP in collaboration and invite a third party to comment or give feedback on your DMP. You can use the button ‘Request feedback’ to ask for feedback from a data steward. In order to write a DMP, you need to create your own account.\n\n\nOverview of funders’ RDM requirements and DMP templates\nThe Consortium of European Social Science Data Archives (CESSDA) presents a comprehensive overview of data management requirements and templates of the main Dutch and European funding bodies. This is helpful if you want to quickly find more information. However, make sure you always check the details that you receive in the documentation of your actual funding agency, so that you are aware of all up-to-date requirements.\n\nNational: NWO, ZonMw\n\n\n\nPublishing your data and terms of use\nNormally a funder requires you to publish your data in a data repository at the end of the project (unless this is prohibited by legislation). For that reason, DMP templates usually include the following questions:\n\nwhere your dataset can be found\nwhether your dataset has a Persistent Identifier\nhow your data are documented\nwhether your data may be reused freely or not and which terms and conditions apply\n\nPlease consider your funder’s data publishing requirements, so that you can take the necessary steps before and during your research project. For example, if you are working with personal data and you want to publish them in a data repository, this needs to be included in the informed consent forms that your participants have to sign.\n\n\n\nLocal requirements from your university and faculty\nVU Amsterdam is committed to support research that meets the highest requirements of replicability and transparency. The FAIR data principles, the purpose of which is to render research data Findable, Accessible, Interoperable and Reusable, the General Data Protection Regulation (GDPR) and the principles of Open Science are at the foundation of the Research Data Management (RDM) policy of VU Amsterdam.\nIn addition to the central policy for RDM, faculties of VU Amsterdam also have developed their own implementation of this policy.\nPlease check the relevant local policies and Standard Operating Procedures relevant for your faculty or department before you start your research project. An overview of all available policy documents can be found in the section VU policies and regulations.\n\n\nConsortium partners\nPartner institutions in a consortium may also have research data management requirements, for example with respect to data security. They may ask for:\n\ncertification in relation to data security of VU Amsterdam’s infrastructure\nstatements from the IT department about the IT systems being used at VU Amsterdam\n\nThe RDM Support Desk or your faculty’s research support office can help you with this."
  },
  {
    "objectID": "guides/plan-and-design.html#collaboration",
    "href": "guides/plan-and-design.html#collaboration",
    "title": "How can you set up research data management from the start?",
    "section": "Collaboration",
    "text": "Collaboration\nSome research projects involve more than one partner organisation. Be sure to indicate exactly who is responsible for collecting and managing the data in each case, where, and how. If more than one organisation is involved, it may also be necessary to create a Consortium Agreement. Depending on the area or sector of each project and of the degree of technical complexity that is involved, the Consortium Agreement usually contains the following information:\n\nprovisions on the governance structure of the consortium;\ntechnical provisions (e.g. the tasks of each party and the project schedule, description of the data collection responsibilities);\nfinancial provisions (e.g. the distribution of funds among participants, the financial plan, etc).\n\nThe agreement can include a section on who is ultimately responsible for the data and whether the data will be shared afterwards or whether certain restrictions on re-use apply. These restrictions can also be related to copyright issues or pending patent requests. IXA can help you to draw up a consortium agreement. The RDM Support Desk at the University Library can also help with questions about legal matters.\nIf you are working with personal data, GDPR requires that all parties working with the data sign a joint controller agreement. You can ask your 🔒 Privacy Champion for advice about this. For multi-centre clinical research, a Clinical Trial Agreement is recommended.\nFor projects funded by the European Union, several sources are available:\n\nFor Horizon 2020 projects a document is available, called “Guidance How to draw up your consortium agreement”."
  },
  {
    "objectID": "guides/plan-and-design.html#data-security",
    "href": "guides/plan-and-design.html#data-security",
    "title": "How can you set up research data management from the start?",
    "section": "Data Security",
    "text": "Data Security\n\nData classification\n‘Security’ is often regarded as a fixed state. Therefore, people tend to think of security measures as fixed solutions in the form of technological measures. In reality, security is an assessment of the level of protection against a certain threat, that you consider to deal with that threat adequately enough. Whether or not security is accurate depends on the value of the data and the quality of protective measures.\nThe value of data or applications is established through classification in Confidentiality, Integrity and Availability (CIA) or in Dutch Beschikbaarheid, Integriteit en Vertrouwelijkheid (BIV).\nTraditionally, this classification assesses the value of an entity (data or application) to an organisation. For research data, however, the value to the University is in all cases the same. The value of each research project is the same. Does that mean that there is no need to classify research data? Referring back to the definition of security, it is the assessment of the level of protection against a certain threat and its accuracy depends on the value of (in this case) data. The reason to classify research data is that there is a huge variety in potential risks in case of data loss or theft.\nThe reason that VU and its reseachers need to classify data is to understand the variety in risk that exists in order to assess if security measures are accurate.\nData classification is about the level of sensitivity (low, medium or high) of your data assets so you can judge the risks to your research (group). This will help you when deciding what security and protection measures you need to take for handling the data or parts of the data.\n\nPolicy Classification of Research Data\nThe Policy Classification of Research Data addresses classification of research data in terms of availability, integrity and confidentiality, and how the classification process should be carried out. It is connected to the Research Data and Software Management Policy, because the latter states that data must be handled in a secure and reliable manner. The Research Data Classification Policy will determine what level of security measures are necessary to manage data securely.\n\n\nData classification criteria\nIn order to classify your data collection or data processing (in categories from low, to medium, or high), the following properties are considered.\n\nAvailability: what risks are associated with accessibility to data (i.e. how readily do the data need to be available for use and how damaging would it be to your research if data are lost), what measures should you take to prevent data loss?\nIntegrity: what do you do to prevent measurement or data entry errors, corruption of stored data or unauthorised changes to the stored data?\nConfidentiality: how securely do data need to be managed to prevent sharing of data with unauthorised individuals? The necessity for confidentiality depends on the sensitivity of the information, either as sensitive personal information or confidential business information, as well as the vulnerability of the subjects from whom the data is collected and the laws that apply to the data being collected and analysed. In some cases, confidentiality can be very high; when the confidentiality is high or very high, please contact the RDM Support Desk.\n\nFor all of these aspects, the damage impact should be considered, i.e. te risks to all parties involved (i.e. participants, but also VU Amsterdam as an institute, the researchers, any collaborators etc.). Untoward outcomes could be loss of privacy/secrecy, reputation damage, financial costs, fraud, mental, social or physical harm.\n\n\nExamples of Highly classified data\nYour data are classified as ‘high’ when you collect or process the following data:\n\npersonal data\nstate secrets\ncompetitive corporate information\nanimal-testing data\n\n\n\nPersonal data\nDo not confuse the risks of data loss with the need to comply to legal regulations. Data security is part of risk management and is aimed at balancing protection against productivity, investments against profit. The General Data Protection Regulation is a European Law in the legal area of Human Rights and concerns the use of personal data. Personal data are a type of data that is commonly processed in many fields of scientific research. You collect or process personal data when the data can be linked to a unique individual, either directly through direct identifiers such as name, address, IP-address etc., or indirectly through a combination of information. Personal data need to be protected. More information about personal data, data protection and the GDPR can be found in the section GDPR & Privacy.\n\n\nData Classification tool for researchers\nTo help you to determine the data classification for your research data assets, VU Amsterdam has developed a tool that will help you to assess and classify the availability, integrity and confidentiality risks of these assets. Based on your results from using the tool, you may need to seek further advice from VU Security and Privacy Experts (see below). Some basic security tips were compiled by the data steward of the Faculty of Behavioural and Movement Sciences.\n\n\nVU Security and Privacy experts\nVU Security and Privacy experts can help you with the details on these aspects.\n\nGeneral questions about information security: RDM Support Desk. If you need advice when determining the data classification of your data assets, you can contact them.\nReporting a (potential) data breach: IT Servicedesk. A data breach is an incident in which the possibility exists that the confidentiality, integrity or availability of information or data processing systems has been potentially threatened, for example attempts to gain unauthorised access to information or systems (hacking), the loss of a USB stick with sensitive information, data theft of hardware.\nTailored advice or support: The RDM Support Desk can assist researchers in the process of requesting capacity at IT for setting up and/or assessing of information security plans or paragraphs. An information security plan is particularly important in projects with a complex infrastructure (e.g. international collaboration, use of various data sources and databases), tailored solutions and requirements from funding agencies or external partners.\n\nRead more practical information about this below in the section Data Protection & Security, or the GDPR support section.\n\n\n\nData Protection & Security\nWhere sensitive information is collected, the researcher must consider the following:\n\nwho has access to the data during the study, and how the data will be made available after publication\nwhat security regimes apply to sensitive data, and how data are protected\nhow data access during and after the project will be managed\nhow to deal with sensitive information\nwhether informed consent is required and how the forms will be accessed and stored\n\nOn the 🔒 VU Intranet information is available on Security, data loss and reporting incidents. Legal experts also can help you if you have questions about working with personal data and/or if you have to perform a Data Protection Impact Assessment. On VU Amsterdam website you can find more information about 🔒 DPIAs at VU Amsterdam. The data steward for the Faculty of Behavioural and Movement Sciences has also created a guide about data encryption."
  },
  {
    "objectID": "guides/plan-and-design.html#gdpr-privacy",
    "href": "guides/plan-and-design.html#gdpr-privacy",
    "title": "How can you set up research data management from the start?",
    "section": "GDPR & Privacy",
    "text": "GDPR & Privacy\nIf you work with personal data in your research, you have to comply with the General Data Protection Regulation (GDPR). This will have implications for how you prepare your research. Please see the GDPR topic for more information about this legislation and the guide How can you comply with the GDPR? for step-wise instructions to set up your research in a GDPR-compliant manner."
  },
  {
    "objectID": "guides/plan-and-design.html#policies-regulations",
    "href": "guides/plan-and-design.html#policies-regulations",
    "title": "How can you set up research data management from the start?",
    "section": "Policies & Regulations",
    "text": "Policies & Regulations\n\nVU General Policies and Regulations\n\nResearch Data and Software Management Policy\nVU Amsterdam considers the careful handling of research data and software to be very important. The university has therefore formulated a Research Data and Software Management Policy which articulates how to handle research data and software. The policy lists the responsibilities regarding research data and software management for researchers, department heads, faculty boards and the university as a whole.\n\nVU Research Data and Software Management Policy (2024) in English and in Dutch\n\nSince the VU Amsterdam policy for Research Data and Software Management is formulated in general terms, faculties have worked out more detailed policies and guidelines for their own faculty. These faculty-specific guidelines can be found below.\n\nACTA RDM policy, Academisch Centrum Tandheelkunde Amsterdam (2020, in Dutch)\nBeta RDM policy, Faculty of Science (2022)\nFGB RDM policy, Faculty of Behavioural and Movement Sciences (2023)\nFaculty of Social Sciences and Humanities (FSG):\n\nSchool of Humanities RDM policy , Faculty of Humanities (2023)\nSchool of Religion and Theology RDM policy, Faculty of Religion and Theology (2024)\nSchool of Social Sciences RDM policy, Faculty of Social Sciences (2023)\n\nRCH RDM policy, Faculty of Law (2021)\nSBE RDM policy, School of Business and Economics (2023)\n\nFor RDM policies and guidelines at Amsterdam UMC, location VUmc, please get in touch with Research Data Management Support at Amsterdam UMC.\nIf you have questions about the VU-central Research Data and Software Management Policy, please contact the RDM Support Desk.\n\n\nDomain-specific guidelines and protocols\nSome faculties and departments have their own guidelines for RDM. You can find an overview of such guidelines below.\n\nAmsterdam Public Health Quality Handbook\nFGB: Code of Ethics for Research in the Social and Behavioural Sciences Involving Human Participants\n\n\n\n\nEthical Review\nIn cases where research involves human or animal participants, a research proposal may need to be reviewed by an ethics committee. VU Amsterdam and Amsterdam UMC (location VUmc), have several ethics committees, which are listed below. Please note that researchers at VU Amsterdam also have to go to the METc at VUmc if their research is subject to the WMO, which is not restricted to research at VUmc.\n\nEthics committees\n\nACTA: ACTA Ethics Review Board (ETC), Academisch Centrum Tandheelkunde Amsterdam\nBeta: Research ethics review committee Faculty of Science (BETHCIE), Faculty of Science\nFGB: 🔒 Scientific and Ethical Review Board (VCWE), Faculty of Behavioural and Movement Sciences\nFSG, Faculty of Social Sciences and Humanities:\n\nSGW: Ethische Toetsingscommissie Onderzoek (EtCO), School of Humanities\nSSW: 🔒 Research Ethics Review Committee (RERC), School of Social Sciences\n\nRCH: Ethics Committee, Faculty of Law\nSBE: Ethical Review Board (ERB), School of Business and Economics\nVUmc (Amsterdam UMC): Medical Ethical Review Committee (METc)\n\n\n\n\nAcademic Integrity\n\nNetherlands Code of Conduct for Research Integrity\nDutch scientists are required to comply with the Netherlands Code of Conduct for Research Integrity (VSNU, 2018). The principles of proper scientific and scholarly research, according to the Code of Conduct are:\n\nHonesty\nScrupulousness\nTransparency\nIndependence\nResponsibility\n\nThe principles of honesty and transparency state explicit guidelines for the way in which you treat your research data:\n\nHonesty: you should refrain from fabricating or falsifying data\nTransparency:\n\nYou should ensure that it is clear to others what data your research is based on, how the data were obtained, what the results are and how you got to these results\nAll steps in your research process must be verifiable (e.g. choice of research question, research design, methodology, sources used), so that it is clear to others how your research was conducted\n\n\nTo live up to these general principles, the Code of Conduct provides the following standards, which are addressed in a Data Management Plan (DMP), for good research practices related to data management:\n\nProvide a description of the way in which the collected research data are organised and classified, so that they can be verified and re-used (standard 3.2.10)\nMake research data public upon completion of your research project; if this is not possible, explain why (standards 3.2.11 and 3.4.45)\nDescribe the data you have collected and used in your research honestly, scrupulously and transparently (standard 3.3.23)\nManage your data carefully and store both the raw and processed versions for a period appropriate for your discipline (standard 3.3.24)\nContribute towards making data FAIR, where possible (standard 3.3.25)\nBe transparent about your methods and working procedures by using e.g. research protocols, logs, lab journals or reports to describe these processes (standard 3.4.35)\n\n\n\nAcademic integrity at VU Amsterdam\nTo protect academic integrity at VU Amsterdam and Amsterdam UMC (location VUmc) subscribe to the Netherlands Code of Conduct for Research Integrity. On the Academic Integrity page on the VU website, you can find more information about how these organisations implement the duties of care for institutions to uphold the principles of academic integrity.\n\nConfidential counsellors\nVU Amsterdam has a number of confidential counsellors who handle academic integrity issues.\n\n\nAcademic integrity complaints procedure\nVU Amsterdam and Amsterdam UMC, location VUmc employ a joint policy for the handling academic integrity complaints. This policy outlines the steps to be taken in the event of a complaint, the officers who play a role in this procedure, and what should be expected once a complaint has been lodged.\n\n\n\nRIOS: Center for Research Integrity and Open Science\nRIOS connects initiatives related to research integrity, research ethics, responsible research and innovation, open science, and research culture at VU Amsterdam and Amsterdam UMC. The mission of RIOS is to strengthen the position of VU Amsterdam and Amsterdam UMC regarding research integrity and open science.\n\n\n\nNWO Data Policy\nNWO aims to ensure that all the research it funds is openly accessible to everyone as part of it’s Open Science policy. Researchers are therefore expected to preserve the data resulting from their projects for at least ten years, unless legal provisions or discipline-specific guidelines dictate otherwise. As much as possible, research data should be made publicly available for re-use. As a minimum, NWO requires that the data underpinning research papers should be made available to other researchers at the time of the article’s publication, unless there are valid reasons not to do so.\nThe guiding principle here is ‘as open as possible, as closed as necessary.’ Due consideration is given to aspects such as privacy, public security, ethical limitations, property rights and commercial interests. In relation to research data, NWO recognizes that software (algorithms, scripts and code developed by researchers in the course of their work) may be necessary to access and interpret data. In such cases, the data management plan will be expected to address how information about such items will be made available alongside the data.\nMore information on Data Management is also available on the NWO website where a NWO Data Management Template is made available. The VU Data Management template in DMP Online is certified by both NWO and ZonMW and can also be used by VU researchers for projects funded by both organisations."
  },
  {
    "objectID": "guides/document-and-preserve.html",
    "href": "guides/document-and-preserve.html",
    "title": "How can you ensure research data is FAIR?",
    "section": "",
    "text": "This page discusses what the FAIR principles (Wilkinson et al. 2016) are, why they are important and how you can work in line with these principles at VU.\n\n\nThe FAIR principles were formulated in 2016 to guide researchers in increasing the Findability, Accessibility, Interoperability and Reusability of their data (see the publication in the journal Scientific Data and the summary of the principles). The goal is to ensure that scholarly data can be used as widely as possible – accelerating scientific discoveries and benefiting society in the process.\nA lot of good resources exist already that explain the FAIR principles very well:\n\nGO FAIR provides a clear overview of the FAIR principles\nThe Turing Way has a great information page about FAIR, containing a lot of references to other useful sources\nThe story A FAIRy tale explains all principles in an understable way\n\nThe FAIR principles were rapidly adopted by Dutch and European funding agencies. If you receive a research grant from NWO, ZonMw, or the European Commission, you will be asked to make your data FAIR.\n\n\n\nYou do not need to apply all FAIR principles at once to start benefiting from making your data FAIR. Applying even just some of the principles will increase the visibility and impact of your data, leading to:\n\nIncreased citations of the datasets themselves and your research\nImproved reproducibility of your research\nCompliance with funder and publisher requirements\n\nMaking your data FAIR will also make it possible for you to easily find, access and reuse your own data in the future. You may be the first and most important beneficiary of making your own data FAIR.\n\n\n\n\n\nA DMP is a living document in which you specify what kinds of data you will use in your project, and how you will process, store and archive them. Preparing a data management plan should be your first step in the process to make data FAIR. The DMP template will ask questions that enable you to systematically address the things that need to be done to make your data FAIR. Writing a DMP is also a requirement from funding agencies and some faculties at VU Amsterdam. At VU Amsterdam, you can use DMPonline to create and share DMPs.\n\n\n\nTo be findable, data need to be described with appropriate metadata. Metadata can include keywords, references to related papers, the researchers’ ORCID identifiers, and the codes for the grants that supported the research. You will need to provide such metadata when you are uploading data to a repository (see below). You increase findability by filling out as many metadata fields as possible and by providing rich descriptions in terminology that is common in your field.\nTo be reusable, data need to be accompanied by documentation describing how the data was created, structured, processed, and so on. It is good practice to integrate writing documentation during the research process. It will be easier and take less time compared to when you try to do this at the end. Having documentation on the research process will also help you to redo parts of your data cleaning actions or data analysis if necessary.\nIf you have questions about metadata and documentation, contact the RDM Support Desk and we will be happy to help you and to provide advice.\n\n\n\nIf you choose a repository that: assigns a persistent identifier to both the data and the metadata; attaches metadata to the data according to standard metadata schemas; releases data with a license; and provides access to the data and metadata via an open and standard communication protocol (such as http) – then your data will meet many, if not most, of the FAIR principles.\nVU Amsterdam provides three repositories which meets all of these conditions:\n\nDataverseNL\nYoda\nOpen Science Framework (OSF)\n\nCosts for using these repositories for datasets up to 500 GB are covered by the faculty. There are costs involved for you department or project if a datasets is larger than 500 GB. See the storage cost model for details.\n\n\n\n\nData do not need to be open to be FAIR. The FAIR principles allow for controlled access, which can be important for certain types of data, such as personal data, medical data, competitive company data. The guiding principle is always that data should be as “as open as possible, as closed as necessary”. If data cannot be openly shared, because they are too sensitive, then “the FAIR approach would be to make the metadata publicly available and provide information about the conditions for accessing the data itself.”"
  },
  {
    "objectID": "guides/document-and-preserve.html#fair-principles",
    "href": "guides/document-and-preserve.html#fair-principles",
    "title": "How can you ensure research data is FAIR?",
    "section": "",
    "text": "This page discusses what the FAIR principles (Wilkinson et al. 2016) are, why they are important and how you can work in line with these principles at VU.\n\n\nThe FAIR principles were formulated in 2016 to guide researchers in increasing the Findability, Accessibility, Interoperability and Reusability of their data (see the publication in the journal Scientific Data and the summary of the principles). The goal is to ensure that scholarly data can be used as widely as possible – accelerating scientific discoveries and benefiting society in the process.\nA lot of good resources exist already that explain the FAIR principles very well:\n\nGO FAIR provides a clear overview of the FAIR principles\nThe Turing Way has a great information page about FAIR, containing a lot of references to other useful sources\nThe story A FAIRy tale explains all principles in an understable way\n\nThe FAIR principles were rapidly adopted by Dutch and European funding agencies. If you receive a research grant from NWO, ZonMw, or the European Commission, you will be asked to make your data FAIR.\n\n\n\nYou do not need to apply all FAIR principles at once to start benefiting from making your data FAIR. Applying even just some of the principles will increase the visibility and impact of your data, leading to:\n\nIncreased citations of the datasets themselves and your research\nImproved reproducibility of your research\nCompliance with funder and publisher requirements\n\nMaking your data FAIR will also make it possible for you to easily find, access and reuse your own data in the future. You may be the first and most important beneficiary of making your own data FAIR.\n\n\n\n\n\nA DMP is a living document in which you specify what kinds of data you will use in your project, and how you will process, store and archive them. Preparing a data management plan should be your first step in the process to make data FAIR. The DMP template will ask questions that enable you to systematically address the things that need to be done to make your data FAIR. Writing a DMP is also a requirement from funding agencies and some faculties at VU Amsterdam. At VU Amsterdam, you can use DMPonline to create and share DMPs.\n\n\n\nTo be findable, data need to be described with appropriate metadata. Metadata can include keywords, references to related papers, the researchers’ ORCID identifiers, and the codes for the grants that supported the research. You will need to provide such metadata when you are uploading data to a repository (see below). You increase findability by filling out as many metadata fields as possible and by providing rich descriptions in terminology that is common in your field.\nTo be reusable, data need to be accompanied by documentation describing how the data was created, structured, processed, and so on. It is good practice to integrate writing documentation during the research process. It will be easier and take less time compared to when you try to do this at the end. Having documentation on the research process will also help you to redo parts of your data cleaning actions or data analysis if necessary.\nIf you have questions about metadata and documentation, contact the RDM Support Desk and we will be happy to help you and to provide advice.\n\n\n\nIf you choose a repository that: assigns a persistent identifier to both the data and the metadata; attaches metadata to the data according to standard metadata schemas; releases data with a license; and provides access to the data and metadata via an open and standard communication protocol (such as http) – then your data will meet many, if not most, of the FAIR principles.\nVU Amsterdam provides three repositories which meets all of these conditions:\n\nDataverseNL\nYoda\nOpen Science Framework (OSF)\n\nCosts for using these repositories for datasets up to 500 GB are covered by the faculty. There are costs involved for you department or project if a datasets is larger than 500 GB. See the storage cost model for details.\n\n\n\n\nData do not need to be open to be FAIR. The FAIR principles allow for controlled access, which can be important for certain types of data, such as personal data, medical data, competitive company data. The guiding principle is always that data should be as “as open as possible, as closed as necessary”. If data cannot be openly shared, because they are too sensitive, then “the FAIR approach would be to make the metadata publicly available and provide information about the conditions for accessing the data itself.”"
  },
  {
    "objectID": "guides/document-and-preserve.html#storing-vs.-archiving-data",
    "href": "guides/document-and-preserve.html#storing-vs.-archiving-data",
    "title": "How can you ensure research data is FAIR?",
    "section": "Storing vs. Archiving Data",
    "text": "Storing vs. Archiving Data\nThere is a difference between storing and archiving data. Storing refers to putting the data in a safe location while the research is ongoing. Because you are still working on the data, the data still change from time to time: they are cleaned, and analysed, and this analysis generates output. As the image below illustrates, storing could be like cooking a dish: you are cleaning and combining ingredients.\nArchiving, on the other hand, refers to putting the data in a safe place after the research is finished. The data are in a fixed state, they don’t change anymore. Archiving is done for verification purposes: so others can check that your research is sound. Or: it is done so that others can reuse the resulting dataset. There is also a difference between archiving and publishing, but in essence, archiving and publishing happen at a similar moment and for both, data do not change anymore.\n\n\n\nA Scriberia illustration showing storage on the left, in a kitchen space with storage making things available, and archiving on the right, in a museum where it is available for viewing.\n\n\nThis illustration is created by Scriberia with The Turing Way community. Used under a CC-BY 4.0 licence. DOI: 10.5281/zenodo.3332807\n\nSelecting Data for Archiving\nThere are various reasons to archive your data: replication, longitudinal research, data being unique or expensive to collect, re-usability and acceleration of research inside or outside your own discipline. It is VU policy to archive your data for (at least) 10 years after the last publication based on the dataset. Part of preparing your dataset for archiving is appraising and selecting your data.\n\nMake a selection before archiving your data\nDuring your research you may accumulate a lot of data, some of which will be eligible for archiving. It is impossible to preserve all data infinitely. Archiving all digital data leads to high costs for storage itself and for maintaining and managing this ever-growing volume of data and their metadata; it may also lead to decline in discoverability (see the website of the Digital Curation Centre). For those reasons, it is crucial that you make a selection.\n\n\nRemove redundant and sensitive data\nSelecting data means making choices about what to keep for the long term, and what data to archive securely and what data to publish openly. This means that you have to decide whether your dataset contains data that need to be removed or separated. Reasons to exclude data from publishing include (but are not limited to):\n\ndata are redundant\ndata concern temporary byproducts which are irrelevant for future use\ndata contain material that is sensitive, for example personal data in the sense of the GDPR, like consent forms, voice recordings, DNA data; state secrets; data that are sensitive to competition in a commercial sense. These data need to be separated from other data and archived securely\npreserving data for the long term is in breach of contractual arrangements with your consortium partners or other parties involved\n\nIn preparing your dataset for archiving, the first step is to determine which parts of your data are sensitive, which can then be separated from the other data. Redundant data can be removed altogether.\n\n\nDifferent forms of datasets for different purposes\nOnce you have separated the sensitive data from the rest of your dataset, you have to think about what to do with these sensitive materials. In some cases they may be destroyed, but you may also opt for archiving multiple datasets. For example, you may want to archive your dataset in more than one form depending on the purpose. For example:\n\nOne for reusability to share\nA second one that contains the sensitive data, and needs to be handled differently.\n\nFor the first, the non-sensitive data can be stored in an archive under restricted or open access conditions, so that you can share it and link it to publications. For the second, you need to make a separate selection, so the sensitive part can be stored safely in a secure archive (a so-called offline or dark archive). In the metadata of both archives you can create stable links between the two datasets using persistent identifiers.\n\n\nWhat to appraise for archiving\nThere are several factors that determine what data to select for archiving. For example, whether data are unique, expensive to reproduce, or if your funder requires that you make your data publicly available. This might also help you or your department to think about a standard policy or procedures for what needs to be kept, what is vital for reproducing research or reuse in future research projects.\nMore information on selecting data:\n\nTjalsma, H. & Rombouts, J. (2011). Selection of research data: Guidelines for appraising and selecting research data. Data Archiving and Networked Services (DANS).\nDigital Curation Centre (DCC): Whyte, A. & Wilson, A. (2010). How to appraise and select research data for curation. DCC How-to Guides. Edinburgh: Digital Curation Centre.\nResearch Data Netherlands: Data selection.\n\n\n\n\nData Set Packaging: Which Files should be Part of my Dataset?\nA dataset consists of the following documents:\n\nRaw or cleaned data (if the cleaned data has been archived, the provenance documentation is also required)\nProject documentation\nCodebook or protocol\nLogbook or lab journal (when available, dependent on the discipline)\nSoftware (& version) needed to open the files when no preferred formats for the data can be provided\n\nSee the topic Metadata for more information about documenting your data.\nDepending on the research project it may be that more than one dataset is stored in more than one repository. Make sure that each consortium partner that collects data also stores all necessary data that is required for transparency and verification. A Consortium Agreement and Data Management Plan will include information on who is responsible for archiving the data."
  },
  {
    "objectID": "guides/document-and-preserve.html#persistent-identifier",
    "href": "guides/document-and-preserve.html#persistent-identifier",
    "title": "How can you ensure research data is FAIR?",
    "section": "Persistent Identifier",
    "text": "Persistent Identifier\nA Persistent Identifier (PID) is a durable reference to a digital dataset, document, website or other object. In the context of research data and software, it is essentially a URL that will never break. By using a Persistent Identifier, you make sure that your dataset will be findable well into the future when it is registered online (for example at DataCite. Another advantage is that it makes a digital object citable.\n\nMultiple PID systems\nThere are multiple PID systems, each with its own particular properties. Examples of widely used PIDs in the research domain include the following.\n\nDOI: A Digital Object Identifier can be used to refer to research data, research software and publications.\nORCiD: An Open Researcher and Contributor ID is used to create a researcher profile with a unique identification number.\nROR: The Research Organization Registry is a global register with persistent identifiers for research institutes.\n\nSee the Persistent Identifier guide of Netwerk Digitaal Erfgoed for a more elaborate overview. Apart from widely used domain-agnostic PIDs, there is a wide range of domain-specific unique identifiers that can be used. If you are interested in domain-specific identifiers, it is useful to ask colleagues in your department or discipline.\n\n\nPersistent Identifiers for data and software in repositories\nPersistent Identifiers can be assigned to datasets and software upon their deposit in a repository. In many repositories, this is a DOI. Data repositories are entitled to generate Persistent Identifiers for data and software. This is one of the reasons why archiving and publishing data and software has to be done in a repository. After the process of uploading data or software to a repository, a Persistent Identifier will be generated. Upon publishing the data or software, the DOI is registered online (usually at DataCite when it concerns a dataset).\nSome repositories enable their users to reserve a Persistent Identifier before the publishing process has finished, so that you can include the Persistent Identifier in a publication before the data will be actually published, or to include the Persistent Identifier in a readme file. This is for example possible in Zenodo.\nThe repositories offered by VU Amsterdam, Yoda and DataverseNL provide DOIs for deposited datasets and software.\n\n\nCreating and using an ORCiD\nResearchers can use an ORCiD to identify their research output as their work. You can request an ORCiD yourself. Instructions for setting up an ORCiD and connecting it to your VU research profile in PURE are available in this ORCiD LibGuide. An ORCiD is often asked for when you submit a publication or upload data or software to a repository. You can use your ORCiD record to create a research profile as well.\n\n\nUsing a ROR\nResearchers can use the ROR for VU Amsterdam when filling metadata forms for their research output to show that their work has been created within their employment at VU Amsterdam."
  },
  {
    "objectID": "guides/document-and-preserve.html#data-documentation",
    "href": "guides/document-and-preserve.html#data-documentation",
    "title": "How can you ensure research data is FAIR?",
    "section": "Data Documentation",
    "text": "Data Documentation\nBy creating documentation about your research data you can make it easier for yourself or for others to manage, find, assess and use your data. The process of documenting means to describe your data and the methods by which they were collected, processed and analysed. The documentation or descriptions are also referred to as metadata, i.e. data about data. These metadata can take various forms and can describe data on different levels.\nAn example that is frequently used to illustrate the importance of metadata is the use of the label on a can of soup. The label tells you what kind of soup the can contains, what ingredients are used, who made it, when it expires and how you should prepare the soup for consumption.\nWhen you are documenting data, you should take into account that there are different kinds of metadata and that these metadata are governed by various standards. These include, but are not limited to:\n\nFAIR data principles: a set of principles to make data Findable, Accessible, Interoperable and Reusable.\nGuidelines for unstructured metadata: mostly research domain-specific guidelines on how to create READMEs or Codebooks to describe data.\nStandards for structured metadata: generic or research domain-specific standards to describe data.\n\nThe CESSDA has made very detailed guidance available for creating documentation and metadata for your data.\n\n\n\nA layered diagram with the FAIR principles as the outermost layer, followed by an inner layer for Metadata. Within Metadata there are two separate cores, one for unstructured and one for structured metadata. Unstructured metadata contains README and codebook; Structured metadata contains Generic and Specific.\n\n\n\nFAIR data principles\nThe FAIR data principles provide guidelines to improve the Findability, Accessibility, Interoperability, and Reuse of digital assets. The principles emphasise machine-actionability, i.e., the capacity of computational systems to find, access, interoperate, and reuse data with none or minimal human intervention.\nMore information can be found in the section about the FAIR data principles.\n\n\nUnstructured metadata\nMost data documentation is an example of unstructured metadata. Unstructured metadata are mainly intended to provide more detailed information about the data and is primarily readable for humans. The type of research and the nature of the data influence what kind of unstructured metadata is necessary. Unstructured metadata are attached to the data in a file. The format of the file is chosen by the researcher. More explanation about structured metadata can be found on the metadata page.\n\nREADME\nA README file provides information about data and is intended to ensure that data can be correctly interpreted, by yourself or by others. A README file is required whenever you are archiving or publishing data.\nExample of READMEs\n\nGuidelines for creating a README file – 4TU.ResearchData\nGuide to writing “readme”-style metatada - Cornell Data Services\nGuidelines for researchers of VU Amsterdam Faculty of Behavioural and Movement Sciences on what a README file should contain\n\n\n\nCodebook\nA Codebook is another way to describe the contents, structure and layout of the data. A well documented codebook is intended to be complete and self-explanatory and contains information about each variable in a data file. A codebook must be submitted along with the data.\nThere are several guides for creating a codebook available:\n\nCreating a codebook - Kent State University\nCreating a codebook - for researchers at VU Amsterdam Faculty for Behavioural and Movement Sciences\nCodebook - Amsterdam Public Health\nDDI-Codebook - Data Documentation Initiative Alliance"
  },
  {
    "objectID": "guides/document-and-preserve.html#metadata",
    "href": "guides/document-and-preserve.html#metadata",
    "title": "How can you ensure research data is FAIR?",
    "section": "Metadata",
    "text": "Metadata\nMetadata provide information about your data. Structured metadata are intended to provide this information in a standardised way. The structured metadata are readable for both humans and machines. It can be used by data catalogues, for example DataCite Commons.\nThe standardisation of metadata involves the following aspects:\n\nElements: rules about the fields that must be used to describe an object, for example the title, author and publicationDate.\nValues: rules about the values that must be used within specific elements. Controlled vocabularies, classifications and Persistent Identifiers are used to reduce ambiguity and ensure consistency, for example by using a term from a controlled vocabulary like the Medical Subject HEadings (MeSH) as a subject and an Persistent Identifier such as an ORCID to identify a person.\nFormats: rules about the formats used to exchange metadata, for example JSON or XML.\n\n\nMetadata standards\nMetadata standards allow for easier exchange of metadata and harvesting of the metadata by search engines. Many certified archives use a metadata standard for the descriptions. If you choose a data repository or registry, you should find out which metadata standard they use. At VU Amsterdam the following standards are used:\n\nYoda uses the DataCite metadata standard\nDataverseNL uses the Dublin Core metadata standard\nVU Amsterdam Research Information System PURE uses the CERIF metadata standard\n\nMany archives implement or make use of specific metadata standards. The UK Digital Curation Centre (DCC) provides an overview of metadata standards for different disciplines. The list is a great and useful resource in establishing and carrying out your research methodology.\n\n\nControlled Vocabularies & Classifications\nControlled vocabularies are lists of terms created by domain experts to refer to a specific phenomenon or event. Controlled vocabularies are intended to reduce ambiguity that is inherent in normal human languages where the same concept can be given different names and to ensure consistency. Controlled vocabularies are used in subject indexing schemes, subject headings, thesauri, taxonomies and other knowledge organisation systems. Some vocabularies are very internationally accepted and standardised and may even become an ISO standard or a regional standard/classification. Controlled vocabularies can be broad in scope or very limited to a specific field. When a Data Management Plan template includes a question on the used ontology (if any), what is usually meant is: is there a specific vocabulary or classification system used? The National Bioinformatics Infrastructure Sweden gives some more explanation about controlled vocabularies and ontologies. In short, an ontology does not only describe terms, but also indicates relationships between these terms.\nExamples of controlled vocabularies are:\n\nCDWA (Categories for the Description of Works of Art)\nGetty Thesaurus of Geographic names\nNUTS (Nomenclature of territorial units for statistics)\nMedical Subject HEadings (MeSH)\nThe Environment Ontology (EnvO)\n\nMany examples of vocabularies and classification systems can be found at the FAIRsharing.org website. It has a large list for multiple disciplines. If you are working on new concepts or new ideas and are using or creating your own ontology/terminology, be sure to include them as part of the metadata documentation in your dataset (for example as part of your codebook).\n\n\nMetadata levels\nFinally a distinction can be made on the level of description. Metadata can be about the data as a whole or about part of the data. It can depend on the research domain and the tools that are used on how many levels the data can be described. In repositories like Yoda and DataverseNL it is common practice to only create structured metadata on the level of the data as a whole. The Consortium of European Social Science Data Archives (CESSDA) explains this distinction for several types of data in their Data Management Expert Guide.\n\n\n\nFlowchart indicating a project with a Folder a and Folder b, where Folder a has File 1 and File 2. The project, Folder a, and File 1, have linked metadata to them.\n\n\n\n\nDataset registration\nWhen you want to make sure that your dataset is findable it is recommended that the elements of the description of your dataset are made according to a certain metadata standard that allows for easier exchange of metadata and harvesting of the metadata by search engines. Many certified archives use a metadata standard for the descriptions. If you choose a data repository or registry, you should find out which metadata standard they use. At VU Amsterdam the following standards are used:\n\nDataverseNL and DANS use the Dublin Core metadata standard\nVU Amsterdam Research Portal PURE uses the CERIF metadata standard\n\nMany archives implement or make use of specific metadata standards. The UK Digital Curation Centre (DCC) provides an overview of metadata standards for different disciplines. The list is a great and useful resource in establishing and carrying out your research methodology. Go to the overview of metadata standards. More important tips are available at Dataset & Publication."
  },
  {
    "objectID": "guides/document-and-preserve.html#data-licensing",
    "href": "guides/document-and-preserve.html#data-licensing",
    "title": "How can you ensure research data is FAIR?",
    "section": "Data Licensing",
    "text": "Data Licensing\n\nIntroduction\nA data licence agreement is a legal instrument that lets others know what they can and cannot do with a particular dataset (and any documentation, scripts and metadata that are published with the data - information about software licensing can be found on the software licensing page). It is important to consider what kind of limitations are relevant. Usually, at least the following questions are considered:\n\nCan people make copies or even distribute copies?\nDo others (and you) reusing the dataset need to acknowledge you as the author of the original dataset? (This is called Attribution.)\nDo others (and you) who reuse the dataset and/or make derivatives of the dataset need to share their work under a similar licence? (This is called Share-Alike.)\nCan others (and you) use your dataset commercially? (A restriction on commercial use is called Non-Commercial.)\nCan others (and you) create a new work based on the dataset? (This is called a Derivative.)\n\nThe considerations above are the ‘building blocks’ that Creative Commons licences use. There are also other considerations, and also other licences.\n\n\n\nAn image of open data, made up of public domain icons\n\n\n\n\nReusing existing data\nIf you wish to reuse data collected by others (this could be data you received from for example Statistics Netherlands or from a company, a dataset you have found in an online repository, commonly used databases for which VU Amsterdam has a licence, etc.), make sure that you read the licence or terms of use. Also make sure that you work with the data according to the licence or terms of use. This can mean different things depending on the licence, but common things to consider are for example:\n\ncite the data in an appropriate manner;\ndo not share the data beyond the project/purpose for which you received them;\nshare the outcome of your research based on the data under a similar licence;\nonly use them for scientific purposes (and not for commercial purposes, for example).\n\nIf you have questions about the legal context of using an existing dataset, you can contact the RDM Support Desk or the legal experts at IXA VU.\n\n\nLicensing data\nIf you want to make your data available for other (research) purposes, it is important to apply a licence to it. Without a licence, it is impossible for others to reuse your data without your explicit approval. When you deposit your data in a repository, the repository will usually ask you to select a standard licence, or to create and add a custom licence yourself. If you need help with drawing up licence agreements, you can contact the VU’s legal office.\n\nDataverseNL\nIn DataverseNL you can choose your terms of use when uploading data to the repository. The DataverseNL user guide explains how licensing works in the repository.\n\n\nYoda\nIf you publish your data in Yoda, there is guidance available on how to choose a licence and how to customise licences.\n\n\nOpen Science Framework (OSF)\nIn OSF, you can apply a standard licence to your materials or upload your own custom licence. The OSF user guide explains both options.\n\n\nExternal repositories\nSome data repositories require you to use a certain licence if you want to deposit your data with them. At Dryad, for example, all datasets are published under the terms of Creative Commons Zero to minimise legal barriers and to maximise the impact for research and education. Some funders may also require that you publish the data as open data. Open data are data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and share alike (Open Knowledge International definition).\n\n\n\nAdditional websites and tools:\n\nExplanation about copyrights and licences by a professor from Leiden University (English subtitles available)\nThe Guide to Creative Commons for Scholarly Publishing and Educational Resources by NWO, VSNU and the University and Royal Libraries\nDCC how-to guide on licensing research data, a guide that links to the Creative Commons website, where many terms are explained\nOpen Data Commons Public Domain Dedication and License (PDDL)\nEUDAT B2SHARE licence selection wizard, which Pawel Kamocki (et al.) released under an open source licence.1"
  },
  {
    "objectID": "guides/document-and-preserve.html#footnotes",
    "href": "guides/document-and-preserve.html#footnotes",
    "title": "How can you ensure research data is FAIR?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the source code, see https://github.com/ufal/public-license-selector/↩︎"
  },
  {
    "objectID": "guides/collect-and-store.html",
    "href": "guides/collect-and-store.html",
    "title": "How can you ensure data protection and security during collection, storage, and transfer?",
    "section": "",
    "text": "Data collection may consist of the re-use of existing data and/or the generation of new data.\nFor data to be considered valid and reliable, data collection should occur consistently and systematically throughout the course of the research project. Within disciplines, there are established methodologies, procedures and techniques that help researchers ensure high quality of collected data. In general, important aspects of data collection include:\n\nStandardisation: codebooks & protocols\nStructure / organisation of the data\nData quality assurance methods\nDocumentation & metadata\nStorage & protection\n\nSystematic data collection is essential for ensuring the reproducibility of research. When data is collected in a consistent and organized manner, it improves the quality and reliability of the research, making the data easier to share and reproduce by others. High-quality data also contributes to making data FAIR (Findable, Accessible, Interoperable, and Reusable), as well-organized and well-documented data is more likely to be reused effectively. The principles of making data FAIR are discussed in detail under the topic FAIR Principles.\n\nData Collection Tools\nThe tools being used in research to collect data are immensely diverse. For that reason, we will not provide an exhaustive overview here. What is important for data collection tools in relation to RDM is where such tools store the data that you collect and in which format. The storage location is particularly important when you are working with personal data. For example, the privacy legislation in the United States is very different from the European General Data Protection Regulation (GDPR). Hence, personal data collected in a Dutch research institute may not be stored on American servers. It is important to keep that in mind when you are contemplating which tool to use for your data collection.\nIf you are collecting personal data and you decide to use a tool for which no contract exists between VU Amsterdam and the provider of the software or tool, a service agreement and a processing agreement must be drawn up. Contact the 🔒 privacy champion of your faculty for more information and a model processing agreement.\n\nQuestionnaire tools\nThe Faculty of Behavioural and Movement Sciences has developed a document with tips for safe use of the questionnaire tools Qualtrics and Survalyzer. The document was made for FGB researchers specifically but can also be helpful for others. Consult this document if you need a questionnaire tool to collect your data.\n\n\n\nData Collection in Collaboration\nSome research projects involve the participation of multiple organisations or institutes and may include even cross-border co-operation. When data is collected by several organisations, a Data Management Plan should provide information on who is responsible for which part of the data collection and storage. It should also provide information on how specific data collections are related to which part(s) of the research goal(s). Describing this precisely will help you to determine if a consortium agreement or joint controller agreement is necessary. You see a general example of such a specification in the table below:\n\n\n\n\n\n\n\n\n\n\nData Stage\nDataset description\nResponsible organization for collection\nData origin\nData purpose\n\n\n\n\nRaw data\nCommunity level surveys\nVU Amsterdam\nAmsterdam, The Hague, Rotterdam\nIdentifying perceived problems, System responsiveness\n\n\nRaw data\nTrials & Focus Group Interviews\nLondon School of Hygiene and Tropical Medicine (LSHTM)\nGermany, Switzerland\nTrials to evaluate programs on . . ., Focus Group interviews to identify barriers to . . .\n\n\nRaw data\nPollution measurements using fish\nOceanographic Institute of Sweden\nCoastal waters, Northeast Spain\nEstablish pollution levels of plastic\n\n\n\n\n\nData Collection Protocols\nRegardless of the field of study or preference for defining data (quantitative, qualitative), accurate data collection is essential to maintaining the integrity (structure) of research. Both the selection of appropriate data collection instruments (existing, modified, or newly developed) and clearly delineated instructions for their correct use reduce the likelihood of errors.\nThere are two approaches for reducing and/or detecting errors in data which can help to preserve the integrity of your data and ensure scientific validity. These are:\n\nQuality assurance - activities that take place before data collection begins\nQuality control - activities that take place during and after data collection\n\nQuality assurance precedes data collection and its main focus is ‘prevention’ (i.e., forestalling problems with data collection). Prevention is the most cost-effective activity to ensure the integrity of data collection. This proactive measure is best demonstrated by the standardization of protocol developed in a comprehensive and detailed procedures manual for data collection.\nWhile quality control activities (detection/monitoring and action) occur during and after data collection, the details should be carefully documented in the procedures manual. A clearly defined communication structure is a necessary pre-condition for monitoring and tracking down errors. Quality control also identifies the required responses, or ‘actions’ necessary to correct faulty data collection practices and also minimise future occurrences.\nSome sources for protocols:\n\nHANDS Handbook for Adequate Natural Data Stewardship by the Federation of Dutch University Medical Centers (UMCs)\nProtocols.io - an open access repository of protocols\nSpringer Protocols - free and subscribed protocols collected by Springer.\n\n\n\nStorage During Research\nVU Amsterdam offers several options to store your research data. The choice for a specific option may depend on factors such as:\n\nDoes a project involve multiple organisations or departments?\nThe sensitivity of the data: does it involve personal data or copyrighted / commercial data?\nAre there any research partners with whom data need to be shared?\nAre any commercial parties involved?\nDoes the research project involve multiple locations (inside or maybe even outside the EU)?\nWill there be (lab) devices producing data that need to be stored as well?\nWhat will be the volume of the data?\nWill there be lots of interactions with the data (using software/tools)?\n\nStorage options may take several forms, for example:\n\nLocal storage on computers, networks or servers;\nCloud storage offered by VU Amsterdam;\nLocations where physical data samples are stored (fridges, lockers, etc.).\n\nResearchers, including PhD candidates, have multiple options that can be used, some of which are listed below. More information about these storage options is available behind their respective links. The Storage finder is a tool that will give you a number of storage options suitable for your research. For more individual guidance, please get in touch with the Research Data Management Support Desk for advice, particularly when you are working with commercial, personal or otherwise sensitive data, or when you have a complex IT setup.\n\n\nStandard services offered by VU Amsterdam\nVU IT offers several services for employees to store their files. Examples are:\n\n🔒 OneDrive: personal storage for all VU employees and part of the Microsoft 365 platform. OneDrive allows you to store files locally and in the Microsoft cloud, and share folders and documents with colleagues. Since this is personal storage, tied to someone’s personal VU account, we don’t usually recommend storing research data in OneDrive: if the account holder leaves VU Amsterdam, the account and all the data on it, disappear.\n🔒 Teams. Faculties, divisions and departments have their own Team - part of the Microsoft 365 platform - where they store shared documents and where they can interact and chat. Projects may also request a project team. But note that Teams is not always the best location to store your research data and has several limitations, especially when it comes to working with non-Microsoft file formats, large volumes of data, interacting with data, and collaborating with partners outside of VU Amsterdam. Contact the RDM Support Desk to find out more about the suitability of Teams for your project.\n\n\n\nResearch data-specific storage options\nThe options above are standard data storage options at VU Amsterdam to which all employees have access. But VU Amsterdam also offers storage specifically for research data. Some of them are hosted locally at VU Amsterdam, while others are SURF cloud services. When selecting a cloud-based service it is important to remember to check where the data will be hosted. If the research project involves sensitive data it may be necessary to choose cloud-based options that guarantee that the data will stay in the EEA or on servers based in the EEA.\n\n🔒 SciStor (short for ‘Storage for Scientists’): This is storage hosted by IT for Research (ITvO) and allows for inexpensive storage of large volumes of data. There are various levels of security possible and various ways to get access to the files. SciStor is only intended for ongoing research, not for archiving.\nYoda (short for Your Data) is a cloud storage at SURF and is suitable for storing large-scale and sensitive datasets. Yoda also supports collaborating on projects in and outside VU Amsterdam and adding contextual information (metadata) about your dataset as you go. Yoda is usually the best choice if your research data are very sensitive.\n🔒 Research Drive is a cloud storage at SURF for research projects and is suitable for collaboration in and outside VU Amsterdam, for storing sensitive data and large-scale research projects. You are able to request storage space in Research Drive via a 🔒 web form in the selfservice portal (VU employees only). Research Drive is the best choice if you need to manage access rights on a folder level. SURF has general information about Research Drive, and you can find tutorials on the wiki pages.\n\nThere are differences between Research Drive and Yoda and each one may support certain projects better than others. The storage finder can help you to get an idea of what would be the best choice for your project, but get in touch with the RDM Support Desk for more details. Costs for each of these storage options are detailed on the VU website, including details on how the costs are calculated and billed.\n\n\nSending research data to partners\nSome projects may require data sharing with partners. Although Research Drive and Yoda support sharing data all through the project, it may also be the case that some data only need to be sent to a partner once. There are some secure options to send data to research partners:\n\n🔒 Surf Filesender: cloud service that allows you to send files of 1 Terabyte to other researchers and encrypted files of up to 250 GB.\n🔒 Zivver: All employees of VU Amsterdam can use Zivver, the encryption programme that allows you to send email or data (sensitive or otherwise) securely by email. Attachments will also be encrypted and can be several Terabytes in size (max = 5 TB). Specific information on how to get and use Zivver are available on the selfservice portal. General explanations on how to use it are available at the Zivver website.\n\n\n\nWhat is Data Protection?\nProtection from what? From whom? When, and why? Before we talk about data protection, let us consider security first. More often than not, ‘security’ is regarded as a fixed state. In reality, security is an assessment of the level of protection against a certain threat, that you consider to deal with that threat adequately enough. Whether or not security is accurate depends on the value of the data and the quality of protective measures.\nThe question for you as a researcher is ‘when are the measures that you take secure enough?’. In order to answer this, please be aware that there are three entities that have an opinion about what is ‘secure enough’, namely: the law, the University, and you yourself as the data processor.\nThe University has a Security Baseline that sets a norm for levels of protection for every application it uses. The Baseline is based on international standards. For each of these applications, the University is considering for which means the security of these applications are adequate enough.\nThe legal requirements for the processing of personal data can be found in the section ‘GDPR and Privacy’ under Plan & Design There are additional laws and regulations as well. The assumption is that you are familiar with these, especially with laws regulating medical and criminal research.\nWhat you personally consider to be secure might be very different from what your colleagues, the Faculty or the University considers to be secure enough and the norms will vary with the variety of data that is being processed by different researchers and Faculties of VU Amsterdam. Very generally speaking, there are three points of protection to consider:\n\nProtection against data loss, for which you need a back up periodically.\nProtection against data leakage, for which you need to consider all storage places and their access points.\nProtection of data integrity, for which you need version control and synchronisation management.\n\nThe security of your protection measures depends on the threat you face. We often think of threats as active, and motivated by bad intentions. But most common forms of data loss are accidental and most leakage is caused by trusting others. In reality, devices just get lost or break down, people download malware by accident, and each one of us forgets to save a document at times or gets confused about which version was last updated.\nIn all cases, protection starts with oversight on where your data is stored and processed. If you forget that you temporarily stored it in a certain place, you have then lost oversight of where that data is. The opposite is also true: if you know where you data is, you have insight in the level of security of the space in which you store it. As you can see, protection begins with organising your work in a reliable manner and thinking through your steps.\nFor example, if you data is on your laptop and synchronised with your phone, then it is stored in two places. Perhaps this is enough back up, perhaps not. If you put both you devices in the same bag and you lose your bag, you have no backup. A backup to an online storage might be a good solution, but might also mean your data leaks via the internet of via the storage provider who sells the data and your behavioural data for profit. Most importantly, there is no absolute security. It is best if you consider your personal behaviour and then think of scenarios that are more or less likely to happen and what would impact you most. If you frequently work in public places you should make it a habit to lock your device each time you leave it. If you eat and drink behind your desk often, better work with a remote keyboard to protect your laptop from the unavoidable coffee shower. Do you save your respondents’ contact details on your personal phone? Then protect it with a pin.\nHere are some basic protection guidelines:\n\nData are very difficult to erase. You have probably never done it.\nDecide how to back up data and test it before you rely on it.\nDo not give others your log-in credentials. If you have done so and your family members use your work device, then change it.\nDo not use passwords twice, do not use your birthday, initials, streetname, hobby.\nEncryption sounds secure, but it fails completely without good password management.\n\n\n\nData Protection\nThere can be many reasons why the data of a project needs to be kept protected:\n\nSensitivity of the data collected\nProtection of the research data from competition\nCommercial reasons / Intellectual property\nEtc.\n\n\n\n\nAn image of a lock composed of code in a matrix green style.\n\n\nThere are also many levels of security that may be implemented, depending on the needs. Sometimes it will be enough to use a password-protected cloud-based server. In extreme cases encryption may be needed and also when data is transmitted between researchers or organisations. You should contact the RDM Support Desk to discuss available options, who may connect you to legal experts where sensitive data is concerned. Check the Data Storage topic for links to find out more on campus solutions and cloud-based options.\n\nSee also the Safe Data Transfer topic for more information on how to transport and transfer data.\n\nIt is important to protect your data during the entire data life cycle. To find out whether your data are secure during all stages of your research, think about your data flow: where do your data originate and where do they go to? If data need to be transported from one physical place to the other, or need to be transferred from one device to another, these actions should happen in a secure way.\n\nTransferring digital data\n\nOnline connection on campus\nIf data collection takes place through a certain measurement device (e.g. MRI scanner, EEG scanner, eye tracker), the data need to be transferred from the measurement device to the storage location that you will use during your research project. Make sure that this transfer takes place in a secure way and also make a plan for the data on the measurement device; find out whether they need to be destroyed or can remain there.\n\n\nOnline connection outside campus (with and without VUnetID)\nIf you are doing fieldwork outside the campus and you have reliable and secure internet access, it is a good idea to upload the data to a storage location that is regularly backed up and secure, in order to prevent data loss. If you have a VUnetID, you can for example use:\n\nResearch Drive to securely and easily store and share research data.\nSURFfilesender to send you data to a colleague or consortium partner, who can store your data in an appropriate place\n\nYou can find more information about each of these storage options in the Data Storage topic.\nIf you need to receive data from colleagues in your project who don’t have access to these tools (e.g. because they are students, don’t work for a Dutch educational institution, or have no VUnetID), Research Drive, Yoda, SURFfilesender and secure emailing with Zivver can also be used:\n\nResearch Drive: This cloud storage service provided by SURF enables researchers from VU and external researchers to manage files and folders in a shared storage location.\nSURFfilesender: as a SURFfilesender user, you can send a voucher to someone who doesn’t have access to this tool. This person can use this voucher to send documents to you. These files can be encrypted.\nYoda: This cloud storage service provided by SURF enables researchers from VU and external researchers to manage files and folders in a shared storage location.\n🔒 Zivver is an email plugin with which you can encrypt emails and attachments.\n\n\n\nOffline data outside campus\nIf you are doing fieldwork in an area with limited internet access, you might use a portable device to initially store your data during the phase of data collection, such as a USB drive or an external hard drive. These data can be transferred to a storage location that is connected to the internet (e.g. Research Drive, Yoda) later. Please make sure that the data on such portable devices are secured, by using encryption (and by transporting them safely by using a lockable briefcase or backpack).\n\n\n\nTransporting physical data\nIf physical objects need to be transported, you should check with the data manager at your department (if available) what options are available. Special briefcases that can be locked or secure backpacks may need to be used to keep informed consent forms or other sensitive data objects (USB drives etc.) secure during transport. A checklist may help to ensure all objects will be taken along.\n\n\nData transportation and transfer across borders\nSome countries have rules to control the movement of encryption technology that enter or exit their borders. If you need to travel with an encrypted laptop to secure your data, for example during fieldwork abroad, please keep this in mind. If you need to transfer data in and out of such countries, please get advice on encryption and secure transportation at the IT Service Desk.\n\n\nSupport\nIf you have general questions about how to protect your data when transporting or transferring them, you can contact the IT Service Desk. In case of complex situations for which you need tailored support, you can consult the IT Relationship Manager representing the research domain, who can request capacity at IT for setting up an information security plan. Such a plan is usually based on documents which need to be completed beforehand, like a Data Protection Impact Assessment and a Data Classification."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html",
    "href": "guides/policies-supporting-vision-open-science.html",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "",
    "text": "Vrije Universiteit Amsterdam is strongly committed to the accessibility of research output, namely publications, data and software. They are important to the visibility, verifiability and reusability of research. To turn accessible research output into reality, VU Amsterdam has developed a Research Data and Software Management Policy. This policy is based on a set of VU-internal, national and international policies, principles and regulations. This guide provides references and short explanations of these documents."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#research-data-and-software-management-policy",
    "href": "guides/policies-supporting-vision-open-science.html#research-data-and-software-management-policy",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Research Data and Software Management Policy",
    "text": "Research Data and Software Management Policy\nVU Amsterdam considers the careful handling of research data and software to be very important. The university has therefore formulated a Research Data and Software Management Policy which articulates how to handle research data and software. The policy lists the responsibilities regarding research data and software management for researchers, department heads, faculty boards and the university as a whole.\n\nVU Research Data and Software Management Policy (2024) in English and in Dutch\n\nSince the VU Amsterdam policy for Research Data and Software Management is formulated in general terms, faculties have worked out more detailed policies and guidelines for their own faculty. These faculty-specific guidelines can be found below.\n\nACTA RDM policy, Academisch Centrum Tandheelkunde Amsterdam (2020, in Dutch)\nBeta RDM policy, Faculty of Science (2022)\nFGB RDM policy, Faculty of Behavioural and Movement Sciences (2023)\nFaculty of Social Sciences and Humanities (FSG):\n\nSchool of Humanities RDM policy , Faculty of Humanities (2023)\nSchool of Religion and Theology RDM policy, Faculty of Religion and Theology (2024)\nSchool of Social Sciences RDM policy, Faculty of Social Sciences (2023)\n\nRCH RDM policy, Faculty of Law (2021)\nSBE RDM policy, School of Business and Economics (2023)\n\nFor RDM policies and guidelines at Amsterdam UMC, location VUmc, please get in touch with Research Data Management Support at Amsterdam UMC.\nIf you have questions about the VU-central Research Data and Software Management Policy, please contact the RDM Support Desk."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#policy-classification-of-research-data",
    "href": "guides/policies-supporting-vision-open-science.html#policy-classification-of-research-data",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Policy Classification of Research Data",
    "text": "Policy Classification of Research Data\nThe Policy Classification of Research Data addresses classification of research data in terms of availability, integrity and confidentiality, and how the classification process should be carried out. It is connected to the Research Data and Software Management Policy, because the latter states that data must be handled in a secure and reliable manner. The Research Data Classification Policy will determine what level of security measures are necessary to manage data securely."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#vu-strategy-2020-2025",
    "href": "guides/policies-supporting-vision-open-science.html#vu-strategy-2020-2025",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "VU Strategy 2020-2025",
    "text": "VU Strategy 2020-2025\nThe Research Data and Software Management Policy follows the VU Strategy, in which VU Amsterdam endorses Open Science and FAIR data (see Section 5.1). More information relating to the VU Strategy can be found on the Strategy page."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#netherlands-code-of-conduct-for-research-integrity",
    "href": "guides/policies-supporting-vision-open-science.html#netherlands-code-of-conduct-for-research-integrity",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Netherlands Code of Conduct for Research Integrity",
    "text": "Netherlands Code of Conduct for Research Integrity\nDutch scientists are required to comply with the Netherlands Code of Conduct for Research Integrity. More information about this code of conduct and procedures for violations of academic integrity at VU Amsterdam is available on the VU page about Academic Integrity."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#fair-principles",
    "href": "guides/policies-supporting-vision-open-science.html#fair-principles",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "FAIR Principles",
    "text": "FAIR Principles\nThe aim of the FAIR Principles is to guide researchers to make their data Findable, Accessible, Interoperable and Reusable."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#research-assessment-criteria",
    "href": "guides/policies-supporting-vision-open-science.html#research-assessment-criteria",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Research assessment criteria",
    "text": "Research assessment criteria\n\nStrategy Evaluation Protocol (SEP)\nIn the Netherlands, research institutes and departments are being evaluated by the Strategy Evaluation Protocol (SEP). One of the aspects that need to be addressed in every evaluation, is Open Science. The extent to which a research institute works openly, is evaluated based on:\n\nto which extent the research unit opens up its work to other researchers and societal stakeholders;\nwhether the research unit reuses data;\nhow it stores the research data according to the FAIR principles;\nhow it makes its research data, methods and materials available.\n\n\n\nSan Francisco Declaration on Research Assessment (DORA)\nThe San Francisco Declaration on Research Assessment (DORA) contains a list of recommendations to improve the way in which research output is assessed. What is relevant for the VU Research Data and Software Management Policy, is that DORA recommends to evaluate the value and impact of all research output, including research data and research software.\n\n\nCoalition for Advancing Research Assessment (CoARA)\nThe Coalition for Advancing Research Assessment (CoARA) states that all research output has to be included in research evaluations, including research data and research software. It also recommends to recognise and reward researchers who make their research output available to others at an early stage in their research, and to recognise and reward open collaboration."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#barcelona-declaration-on-open-research-information",
    "href": "guides/policies-supporting-vision-open-science.html#barcelona-declaration-on-open-research-information",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Barcelona Declaration on Open Research Information",
    "text": "Barcelona Declaration on Open Research Information\nThe Barcelona Declaration on Open Research Information aims to transform the way research information is used and produced. The declaration strives to make openness of information about the conduct and communication of research the new norm."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#legislation-and-regulations",
    "href": "guides/policies-supporting-vision-open-science.html#legislation-and-regulations",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Legislation and regulations",
    "text": "Legislation and regulations\nReseach activities must comply with all legislation and regulations where applicable, for example:\n\nGeneral Data Protection Regulation (GDPR) and Dutch Implementation Act for the GDPR (UAVG): This Regulation lays down rules relating to the protection of natural persons with regard to the processing of personal data. The UAVG contains describes implementation of the GDPR for the Netherlands. On the VU page Working with personal data, you can find more information about how VU Amsterdam protects personal data.\nMedical Research Involving Human Subjects Act (WMO): WMO is a legal framework for medical scientific research. Research is subject to the WMO if it (i) concerns medical scientific research and (ii) participants are subject to procedures or are required to follow rules of behaviour. If a study is subject to the WMO, it must undergo a review by an accredited Medical Research Ethics Committee (or the Central Committee on Research Involving Human Subjects). In the case of VU Amsterdam, such reviews need to be carried out by the METC Amterdam UMC. See also the page about Ethical Review.\nDutch Medical Treatment Contracts Act (in Dutch: Wet geneeskundige behandelingsovereenkomst, WGBO): The WGBO is a legal framework that regulates the relationship between patients and care providers and specifies the rights and duties of patients. You can read more about how the WGBO relates to the WMO on the website of the CCMO (Central Committee on Research Involving Human Subjects).\nCode of Conduct for Health Research: Code of Conduct provided by COREON (Committee on Regulation of Health Research), which contains a manual in Dutch for the responsible handling of (personal) data and human tissue in health research.\nExperiments on Animals Act: This legislation describes the purposes for which animal tests may be carried out. For more information about animal testing at VU Amsterdam, see the pages on the Animal Welfare Body of VU Amsterdam-VUmc and the Amsterdam Division for Laboratory Animal Sciences (ADLAS)."
  },
  {
    "objectID": "guides/comply-with-gdpr.html",
    "href": "guides/comply-with-gdpr.html",
    "title": "How can you comply with the GDPR?",
    "section": "",
    "text": "The General Data Protection Regulation (GDPR) is a European legislation that lays down rules relating to the protection of natural persons with regard to the processing of personal data. The Dutch Implementation Act for the GDPR (UAVG) describes the implementation of the GDPR for the Netherlands.\n\n\n\n\nPersonal data refers to any information relating to an identified or identifiable natural person (‘data subject’). See also the definition of ’personal data’ according to the official text of the GDPR.\nData processing refers to any action performed on data, such as collecting, storing, modifying, distributing, deleting data. See also the definition of ‘processing’ according the official text of the GDPR.\nDirect and indirect identification: Some identifiers enable you to identify an indiviual directly, such as name, day of birth and home address. Individuals can also be identifed indirectly. For example via:\n\na combination of information that uniquely singles out an individual (e.g. a male with breast cancer in a breast cancer registry, a pregnant individual over 50 etc.), this includes information in one record and information across different data files or datasets\nunique information or patterns that are specific to an individual (e.g. genomic data, a very specific occupation, such as the president of a large company, repeated physical measurements or movement patterns that create a unique profile of an individual or measurements that are extreme and could be linked to subjects such as high-level athletes)\ndata that are linked to directly identifying information through a random identification code or number\n\nPseudonymous data: Data that are indirectly identifiable are generally considered to be pseudonymous; this means that they are NOT anonymous and still qualify as personal data. Therefore, the GDPR applies to these data. This is for example the case when direct identifiers are removed from the research data and put into a key file (or what is usually called a subject identification log in medical research) with which the direct identifiers can be mapped to the research data through unique codes, so that reidentification is possible. These data are therefore considered to be pseudonymous data for the research institution and not anonymised data. LCRDM (National Coordination Point Research Data Management) has made a reference card that illustrates the difference between pseudonymous and anonymous data.\n\n\n\n\n\n\nWhere research requires the collection of personal data, the researcher has to follow the Privacy five-step plan to make sure to carry out the research in line with the GDPR.\n\n\n\nThe VSNU’s Code of Conduct for Research Integrity (Dutch, English, 2018) includes a reference to the GDPR and its Dutch implementation law UAVG. An updated Code of Conduct for Using Personal Data in Research which complies with GDPR is still work in progress.\n\n\n\n\nEach faculty has one or more Privacy Champions, who are the first point of contact for questions relating to privacy and the GDPR. The Privacy Champions can help you with completing a Data Protection Impact Assessment, registering your research in the record of processing activities, designing informed consent forms and other questions relating to the GDPR. The 🔒 list of Privacy Champions can be found on the VU website.\n\n\n\nOn the VU page Working with personal data, you can find more information about how VU Amsterdam protects personal data."
  },
  {
    "objectID": "guides/comply-with-gdpr.html#general-data-protection-regulation",
    "href": "guides/comply-with-gdpr.html#general-data-protection-regulation",
    "title": "How can you comply with the GDPR?",
    "section": "",
    "text": "The General Data Protection Regulation (GDPR) is a European legislation that lays down rules relating to the protection of natural persons with regard to the processing of personal data. The Dutch Implementation Act for the GDPR (UAVG) describes the implementation of the GDPR for the Netherlands.\n\n\n\n\nPersonal data refers to any information relating to an identified or identifiable natural person (‘data subject’). See also the definition of ’personal data’ according to the official text of the GDPR.\nData processing refers to any action performed on data, such as collecting, storing, modifying, distributing, deleting data. See also the definition of ‘processing’ according the official text of the GDPR.\nDirect and indirect identification: Some identifiers enable you to identify an indiviual directly, such as name, day of birth and home address. Individuals can also be identifed indirectly. For example via:\n\na combination of information that uniquely singles out an individual (e.g. a male with breast cancer in a breast cancer registry, a pregnant individual over 50 etc.), this includes information in one record and information across different data files or datasets\nunique information or patterns that are specific to an individual (e.g. genomic data, a very specific occupation, such as the president of a large company, repeated physical measurements or movement patterns that create a unique profile of an individual or measurements that are extreme and could be linked to subjects such as high-level athletes)\ndata that are linked to directly identifying information through a random identification code or number\n\nPseudonymous data: Data that are indirectly identifiable are generally considered to be pseudonymous; this means that they are NOT anonymous and still qualify as personal data. Therefore, the GDPR applies to these data. This is for example the case when direct identifiers are removed from the research data and put into a key file (or what is usually called a subject identification log in medical research) with which the direct identifiers can be mapped to the research data through unique codes, so that reidentification is possible. These data are therefore considered to be pseudonymous data for the research institution and not anonymised data. LCRDM (National Coordination Point Research Data Management) has made a reference card that illustrates the difference between pseudonymous and anonymous data.\n\n\n\n\n\n\nWhere research requires the collection of personal data, the researcher has to follow the Privacy five-step plan to make sure to carry out the research in line with the GDPR.\n\n\n\nThe VSNU’s Code of Conduct for Research Integrity (Dutch, English, 2018) includes a reference to the GDPR and its Dutch implementation law UAVG. An updated Code of Conduct for Using Personal Data in Research which complies with GDPR is still work in progress.\n\n\n\n\nEach faculty has one or more Privacy Champions, who are the first point of contact for questions relating to privacy and the GDPR. The Privacy Champions can help you with completing a Data Protection Impact Assessment, registering your research in the record of processing activities, designing informed consent forms and other questions relating to the GDPR. The 🔒 list of Privacy Champions can be found on the VU website.\n\n\n\nOn the VU page Working with personal data, you can find more information about how VU Amsterdam protects personal data."
  },
  {
    "objectID": "guides/comply-with-gdpr.html#complete-a-data-protection-impact-assessment-dpia",
    "href": "guides/comply-with-gdpr.html#complete-a-data-protection-impact-assessment-dpia",
    "title": "How can you comply with the GDPR?",
    "section": "Complete a Data Protection Impact Assessment (DPIA)",
    "text": "Complete a Data Protection Impact Assessment (DPIA)\nWhen scientific research includes the processing of personal data, conducting a Data Protection Impact Assessment (DPIA) may be a legal requirement under the GDPR. If it is not a legal requirement, conducting a DPIA is always a helpful exercise to make sure that you address all legal aspects that need to be addressed. It is the best way to GDPR-proof your research.\n\nWhat is a DPIA?\nA DPIA is an assessment to identify the risks of processing personal data. It consists of a number of questions on the basis of which you determine whether the processing of personal data in your research project is legitimate and which measures should be taken to make sure this processing takes place within the boundaries of the GDPR. A DPIA doesn’t deliver an automatic report at the end, but it rather makes you think about all relevant topics you need to address before starting the processing of personal data. The outcome of a DPIA should be used to determine appropriate measures to mitigate the identified risks, such as data minimisation (not collecting more data than necessary), pseudonymising data, selecting appropriate tools for data storage and data sharing.\n\n\nWhen is a DPIA required?\nA DPIA is required when the processing of personal data is likely to result in a “high risk” for the participants of your research project. This is for example most likely the case when scientific research includes the processing of special categories of personal data, such as data concerning health, religious or philosophical beliefs, political opinions or criminal convictions and offences (see Privacy in Research - 10 key rules for more information about special categories of personal data).\nThere are two DPIA lists which describe situations in which a DPIA is required:\n\nThe Dutch data protection authority (Autoriteit Persoonsgegevens) has published a list of 17 “high risk” situations in which a DPIA is mandatory.\nThe European data protection authorities have together published a list of 9 criteria which can be used to determine whether there is a “high risk”.\n\nYou should consult your 🔒 Privacy Champion to determine whether a PreDPIA is required in your situation.\n\n\nHow can I complete a DPIA?\nVU Amsterdam has a DPIA template based on a form provided by the Dutch Government (see the original template if you wish to have more background information, only available in Dutch).\nYou should request the template from your 🔒 Privacy Champion.\nPlease complete a DPIA at least before you start collecting personal data. In some cases, it might be useful to have a look at the DPIA template at the stage of writing a research proposal.\nIf you are not sure whether it is required to conduct a DPIA or if you need help completing a DPIA, please contact your faculty’s 🔒 Privacy Champion. If needed they can contact the legal specialists of Institutional and Legal Affairs."
  },
  {
    "objectID": "guides/comply-with-gdpr.html#agreements",
    "href": "guides/comply-with-gdpr.html#agreements",
    "title": "How can you comply with the GDPR?",
    "section": "Agreements",
    "text": "Agreements\nIf, in addition to the VU, another party is involved in data processing, in most cases an agreement must be set up to regulate the rights and obligations of all parties involved. This means that if you are collaborating with other universities, medical centres, companies, etcetera, an agreement has to be drawn up. This is also true if you would like to use software that stores personal data and for which VU Amsterdam doesn’t have an agreement yet. If these things apply to your research, please reach out to your faculty’s 🔒 Privacy Champion for support."
  },
  {
    "objectID": "guides/comply-with-gdpr.html#legal-ground",
    "href": "guides/comply-with-gdpr.html#legal-ground",
    "title": "How can you comply with the GDPR?",
    "section": "Legal ground",
    "text": "Legal ground\nPersonal data are only allowed to be processed with a suitable legal ground. For research, the most commonly used legal ground is informed consent. Please make sure that your consent procedure meets the requirements of the GDPR.\nAn important issue in informed consent forms, is the possible future (re-)use of the data. The Privacy Champion of the Faculty of Behavioural and Movement Sciences prepared a checklist for what to consider when creating an informed consent form. You should always ask your 🔒 Privacy Champion for advice when drawing up an informed consent form.\n\nReusing existing data\nIf you like to reuse existing data containing personal data, you need a legal ground as well. Since determining what is allowed to do with existing personal data (e.g. does the original consent cover reuse, should you ask for consent again) can be complex, you should always aks your 🔒 Privacy Champion for help in situations like this."
  },
  {
    "objectID": "guides/comply-with-gdpr.html#privacy-statement",
    "href": "guides/comply-with-gdpr.html#privacy-statement",
    "title": "How can you comply with the GDPR?",
    "section": "Privacy statement",
    "text": "Privacy statement\nThe GDPR requires us to be transparent about how we handle personal data. For scientific research you need to draw up a specific statement for your particular study. The GDPR imposes requirements on what must be included in a privacy statement. VU Amsterdam has a model privacy statement available in Dutch and English that meets these requirements. You can contact your faculty’s 🔒 Privacy Champion for this."
  },
  {
    "objectID": "guides/comply-with-gdpr.html#register-your-processing-activities",
    "href": "guides/comply-with-gdpr.html#register-your-processing-activities",
    "title": "How can you comply with the GDPR?",
    "section": "Register your processing activities",
    "text": "Register your processing activities\nIf your research is subject to the GDPR, then you need to register information on your research in a central VU registry. This central registry lists all personal data processing activities carried out at VU Amsterdam. The registry indicates why and how personal data are processed, and with whom they are shared. The registry helps VU Amsterdam demonstrate compliance with the GDPR and in the case of a data breach, the registry helps with monitoring and acting swiftly to inform all relevant stakeholders.\nFor research projects, VU Amsterdam registers data processing via DMPonline. You can create your registration by logging into DMPonline and following the following instructions:\n\nOn your dashboard, click on Create plan.\nEnter the title of your research project (you don’t have to select the check box for mock testing).\nSelect Vrije Universiteit Amsterdam as your primary research organisation.\nFor the question on primary funding organisation, select the check box on the right, saying that no funder is associated with your plan.\n\n\n\n\nScreenshot of a form for creating a data management plan, asking for the research project, where it is being done, who is funding it and what template you would like to use.\n\n\nOnce you have completed the steps above, you will see two VU templates. You can fill in the VU DMP template 2021 v1.4 if you need to write a DMP anyway; the information you include in this DMP template will be used for the registry. If you don’t need to write a (new) DMP, you can use the separate VU GDPR registration form for research v1.1. Your faculty’s 🔒 Privacy Champion can help you with your registration.\nIf your research is primarily led by Amsterdam UMC, location VUmc, your research will be registered using their own separate system.\n\nRegister before you start your data collection\nIf you use personal data in your research, you should register your data processing activities before you start data collection. If you are not sure whether your research data are subject to the GDPR, contact your faculty’s 🔒 Privacy Champion. Your privacy champion can also assist you if your research is already running, but has not yet been registered."
  },
  {
    "objectID": "guides/comply-with-gdpr.html#data-breach-incident-report",
    "href": "guides/comply-with-gdpr.html#data-breach-incident-report",
    "title": "How can you comply with the GDPR?",
    "section": "Data breach incident report",
    "text": "Data breach incident report\nAny data security breaches (particularly those that have, or are likely to have, serious adverse consequences to the protection of personal data) should be reported immediately to the IT Servicedesk. Read the 🔒 protocol reporting a data breach."
  },
  {
    "objectID": "guides/comply-with-gdpr.html#support",
    "href": "guides/comply-with-gdpr.html#support",
    "title": "How can you comply with the GDPR?",
    "section": "Support",
    "text": "Support\nThe Privacy five-step plan explains the steps you must take before you start a new research with personal data.\nOn the VU page Working with personal data, you can find more information about how VU Amsterdam protects personal data.\nFor all questions relating to privacy and the GDPR, please contact your faculty’s 🔒 Privacy Champion."
  },
  {
    "objectID": "editors-guide.html",
    "href": "editors-guide.html",
    "title": "Editor’s guide",
    "section": "",
    "text": "Welcome to the Editor’s guide to the Handbook! This page contains resources around how the editors work.\nThe current editors are:\nThey can be pinged on GitHub as a team by using @ubvu/editors as the tag."
  },
  {
    "objectID": "editors-guide.html#what-does-an-editor-do",
    "href": "editors-guide.html#what-does-an-editor-do",
    "title": "Editor’s guide",
    "section": "What does an editor do?",
    "text": "What does an editor do?\nEditors tie together all the strings in this VU Amsterdam community handbook. We keep a bird’s eye view to ensure that what you read makes sense. Editors also help ensure the style and quality of the different pages are similar. Editors also help keep the content relevant to the entirety of VU Amsterdam (faculty specific information is not within scope).\nEach editor commits themselves to providing timely reviews of topics, guides, or both.1 This commitment is for a limited time and can be renewed. We also welcome more editors at any time, given that we do not expect all editors to review everything.\nEditors also are responsible for managing time-sensitive merging of Pull Requests on GitHub. Sometimes, we know things have to change on a specific date. To do this, we can schedule PR merges by adding the relevant date in the opening comment of the Pull Request (example; editors can edit comments):\n/schedule YYYY-MM-DD\nAs we go on this journey together, we may assign more specific responsibilities as they emerge."
  },
  {
    "objectID": "editors-guide.html#quality-standards",
    "href": "editors-guide.html#quality-standards",
    "title": "Editor’s guide",
    "section": "Quality standards",
    "text": "Quality standards\nAs editors, we maintain a bunch of quality standards, both automated and not automated. If you are reading this as a contributor, you will greatly help us out by taking these into account.\nHere are some quality standards we maintain throughout the handbook:\n\nWriting must be primarily in active voice, both for consistent and engaging text across all pages\nAcronyms must be written in full at least once on the page where they are used\nAll changes to the handbook are made via pull requests. Each change needs approval from two editors.\n\nPull requests may not be merged if the QA automations fail\n\nLinks must be https://\nAll images must have alt text\nLinks must be descriptive (no “click here” links)\nNo writing in name of the handbook (for example, “we recommend repository X”)\nWhere possible, pages with a DOI must link through the DOI (for example, https://doi.org/10.4444/xxxx instead of the direct link https://nature.com/...)\n\nWe try to automate most of these rules, but this is not always possible or accurate enough.\n\nTopics\nFor topics we maintain an additional set of standards:\n\nTopics must be nouns or noun phrases\nTopics are self-contained and aim for brevity\nAll topics must be title capitalized (see also the helpful tool CapitalizeMyTitle.com)\nNo include statements are allowed in topics\n\nInclude statements must be prefaced with the relevant section heading, as the title of a topic is not reproduced.\n\nNo use of special Quarto code is allowed. Only use regular markdown in topics.\n\n\n\nGuides\nFor guides we maintain other standards:\n\nGuides must be phrased as questions that the reader will get answers to (for example, “how do I preserve data?”)"
  },
  {
    "objectID": "editors-guide.html#how-to-keep-an-overview-of-everything",
    "href": "editors-guide.html#how-to-keep-an-overview-of-everything",
    "title": "Editor’s guide",
    "section": "How to keep an overview of everything?",
    "text": "How to keep an overview of everything?\nWith so many issues and pull requests, it is easy to get lost as an editor. We have a project management board that can be helpful identifying what is going on at this time:\n\nTopics\nGuides"
  },
  {
    "objectID": "editors-guide.html#etiquette",
    "href": "editors-guide.html#etiquette",
    "title": "Editor’s guide",
    "section": "Etiquette",
    "text": "Etiquette\nAs editors, we may have to make tough calls at times. It is important for us to make people feel welcome and appreciated, even if their contribution is not immediately included. That being said, we reciprocate the consideration given to us. We operate under a generosity policy, and if reciprocated, we stay generous.\n\nGitHub etiquette\nAs editors, we also maintain a certain GitHub etiquette. It is necessary to make managing a project with so many moving pieces and contributors. Important is:\n\nNew topics or guides must be linked to the issue proposing it\nEach pull request should have a clear purpose and stick to it (for example, no editing a guide when proposing a topic)\n\nItem 2 also means changes should be branch specific, as pull requests are based off branches. It makes it much harder to review things if there are many different kinds of changes, as we editors will need to keep track of all of this.\nSimplicity is our friend. Simplicity helps us from making mistakes."
  },
  {
    "objectID": "editors-guide.html#protocols",
    "href": "editors-guide.html#protocols",
    "title": "Editor’s guide",
    "section": "Protocols",
    "text": "Protocols\n\nHackathon protocol\nWe sometimes run hackathons to create space to contribute. We run hackathons as follows:\nPreparation:\n\nHackathons are two hours long\nHackathons are run using Zoom\nEach hackathon has a theme (it helps focus people’s energy on something and can inspire participation)\nWe use a collaborative note taking document that requires no logging in, which is the central place to navigate the hackathon\nAssign a host\n\nDuring:\n\nOpen 10 breakout rooms in zoom, allowing participants to freely move around\nThe host…\n\n…Welcomes everyone with an icebreaker question\n…Shares the link to the note taking document when people join\n…Sets the stage for the hackathon when it starts\n…Announces a break at the halfway mark\n\nKeep track of all the issues and pull requests opened for the speed blog\n\nAfter:\n\nFinish up the speed blog for the hackathon within one week of the hackathon. It does not have to be perfect and is primarily to document that the hackathon happened and some of the things that were done."
  },
  {
    "objectID": "editors-guide.html#troubleshooting",
    "href": "editors-guide.html#troubleshooting",
    "title": "Editor’s guide",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nThere are some common mistakes that can happen. We keep track of some of the quirks we observed to help you troubleshoot independently:\n\nIs the filename .qmd exactly?\nIs the relative path from topic -&gt; topic ../topics/name.qmd?"
  },
  {
    "objectID": "editors-guide.html#footnotes",
    "href": "editors-guide.html#footnotes",
    "title": "Editor’s guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEach editor chooses which of these they want to focus on. Editors get auto-invited to review the changes. Timely means within a week.↩︎"
  },
  {
    "objectID": "technical-details.html",
    "href": "technical-details.html",
    "title": "Technical details",
    "section": "",
    "text": "This handbook is created with a variety of technical resources. This document outlines what technical resources are used to achieve different goals."
  },
  {
    "objectID": "technical-details.html#how-is-the-website-built",
    "href": "technical-details.html#how-is-the-website-built",
    "title": "Technical details",
    "section": "How is the website built?",
    "text": "How is the website built?\nWe use GitHub Actions to build the Quarto website. This automation runs every time something changes for the website – the automation itself can be found on GitHub.\nWe use GitHub to subsequently make the website available on https://rdm.vu.nl.\nPlease refer to the Quarto documentation for detailed instructions on how to use Quarto."
  },
  {
    "objectID": "technical-details.html#preview-deployments",
    "href": "technical-details.html#preview-deployments",
    "title": "Technical details",
    "section": "Preview deployments",
    "text": "Preview deployments\nWe use Netlify to automatically build previews of pull requests on GitHub. This is provided by Liberate Science GmbH, and is not critical to the operation of https://rdm.vu.nl. It does, however, help the editors manage changes to the handbook.\nIf this integration ever breaks, it can be fixed by one of the maintainers of the handbook repository. To fix this, link your GitHub repository through Netlify directly and it will automatically deploy any pull requests - https://app.netlify.com/start."
  },
  {
    "objectID": "technical-details.html#easy-github-contributor",
    "href": "technical-details.html#easy-github-contributor",
    "title": "Technical details",
    "section": "Easy GitHub contributor",
    "text": "Easy GitHub contributor\nThe easy GitHub contributor is a small integration to make it easier to start contributing to the handbook. This service is provided by Liberate Science GmbH through Netlify. It is supported until September 1st, 2024 – after which it is no longer maintained."
  },
  {
    "objectID": "technical-details.html#repository-structure-overview",
    "href": "technical-details.html#repository-structure-overview",
    "title": "Technical details",
    "section": "Repository structure overview",
    "text": "Repository structure overview\nUnderstanding the repository structure helps you locate and modify the right files:\n\nKey files and directories\n\nindex.qmd - Homepage content\n_quarto.yml - Main Quarto configuration file\n_variables.yml - Site-wide variables and settings\ncustom.scss - Custom styling\ncontributing.qmd - Contributing guidelines\neditors-guide.qmd - Editor documentation\n\n\n_quarto.yml\nThe _quarto.yml file is especially important, as it contains the metadata and information to structure the handbook. You can use this to find and update the navigation bar. The specifics of using _quarto.yml is documented very well by Quarto.\n\n\n\nContent organization\n\ntopics/ - Individual topic pages (e.g., data-management-plan.qmd, gdpr.qmd)\nguides/ - Step-by-step guides organized by research lifecycle\nblog/ - Blog posts and announcements\npublic/ - Static assets (images, PDFs, etc.)\n\n\n\nTechnical files\n\n_components/ - React components for interactive elements\n_extensions/ - Quarto extensions (e.g., qreacto for React integration)\n.github/workflows/ - GitHub Actions for automated building and deployment\n_site/ - Generated website files (auto-generated, don’t edit directly)\n\n\n\n\n\n\n\nExtra-detailed overview\n\n\n\n\n\n.\n├── .git/ - If present, contains the raw git history\n├── .github/ - GitHub files, including automations and templates\n├── .gitignore - Which files to ignore in git commits\n├── .markdownlint.json - Markdownlint rules and exceptions\n├── CITATION.cff - Citation File Format\n├── CNAME - GitHub Pages domain name\n├── LICENSE - CC0 information\n├── README.md - General readme\n├── _components/ - React components for `/`\n├── _extensions/ - Quarto extensions\n├── _quarto.yml - Quarto metadata\n├── _site/ - If present, the rendered version of the website\n├── _variables.yml - Quarto variables, available in all .qmd files\n├── about.qmd - About page\n├── blog/ - Blog posts, one per .qmd file\n├── blog.qmd - Blog overview page\n├── contributing.qmd - Contributor guide page\n├── custom.scss - Custom styling for VU Amsterdam\n├── editors-guide.qmd - Editor guide page\n├── guides/ - Individual guides, one per `.qmd` file\n├── guides.qmd - General guides page\n├── index.qmd - Homepage `/`\n├── manuals/ - Folder containing all manuals and subpages\n├── manuals.qmd - Manual overview page\n├── netlify.toml - Netlify (preview) deployment instructions\n├── package.json - Netlify plugin information\n├── public/ - Folder containing public assets (keep files small)\n├── references.bib - Reference library for use in the handbook\n├── technical-details.qmd - Technical details page\n├── topics/ - Each `.qmd` file is one topic\n├── topics.qmd - Topic overview page\n└── utils/ - Custom utilities for the website (generally do not touch)\n    └── include-files.lua - Utility to shift headings from included files"
  },
  {
    "objectID": "technical-details.html#about-quarto",
    "href": "technical-details.html#about-quarto",
    "title": "Technical details",
    "section": "About Quarto",
    "text": "About Quarto\nThis handbook is built using Quarto, a scientific and technical publishing system. Quarto allows you to create documents that combine text, code, and data. It supports multiple formats including websites, PDFs, and presentations.\n\nKey concepts\n\n.qmd files - Quarto markdown files that combine markdown text with executable code\nYAML front matter - Configuration at the top of files between --- markers\nShortcodes - Special syntax for advanced features (e.g., https://github.com/ubvu/open-handbook)\n\n\n\nUseful resources\n\nQuarto documentation\nQuarto guide for websites\nMarkdown basics"
  },
  {
    "objectID": "technical-details.html#common-errors-and-troubleshooting",
    "href": "technical-details.html#common-errors-and-troubleshooting",
    "title": "Technical details",
    "section": "Common errors and troubleshooting",
    "text": "Common errors and troubleshooting\n\nBuild errors\nError: “File not found” - Cause: Missing file reference or incorrect path - Solution: Check file paths in links and references - Can ignore in PR? No, this will break the build\nError: “YAML parsing error” - Cause: Invalid YAML syntax in front matter or _quarto.yml - Solution: Check YAML indentation and syntax - Can ignore in PR? No, this will prevent building\nError: “Duplicate anchor” - Cause: Multiple headings with the same text create duplicate IDs - Solution: Make heading text unique or use custom IDs - Can ignore in PR? Yes, but should be fixed for better navigation\n\n\nStyle issues\nInfo: “Missing alt text” - Cause: Images without alt text - Solution: Add descriptive alt text for accessibility - Can ignore in PR? Should be addressed for accessibility, but won’t break the build\n\n\nMarkdownlint errors\nMarkdownlint checks for consistent markdown formatting. This only runs if topics or guides are changed.\nCommon errors include:\nMD001: Heading levels should only increment by one level at a time - Cause: Skipping heading levels (e.g., H1 directly to H3) - Solution: Use proper heading hierarchy - Escape: Add &lt;!-- markdownlint-disable MD001 --&gt; before the heading\nMD033: Inline HTML - Cause: Using HTML tags in markdown - Solution: Use markdown syntax instead, or use HTML when necessary - Escape: Add &lt;!-- markdownlint-disable MD033 --&gt; around HTML sections - Can ignore in PR? Usually yes, HTML is sometimes needed for advanced formatting\nMD041: First line in file should be a top level heading - Cause: File doesn’t start with H1 heading - Solution: Add H1 heading or use YAML front matter - Escape: Add &lt;!-- markdownlint-disable MD041 --&gt; at the top - Can ignore in PR? Yes, especially for files with YAML front matter\nThe full set of rules can be found in the markdownlint documentation.\n\n\nHow to disable Markdownlint rules\nYou can disable specific rules in a document in several ways:\nFor a single line:\n&lt;!-- markdownlint-disable-next-line MD033 --&gt;\n&lt;div&gt;Some HTML content&lt;/div&gt;\nFor a section:\n&lt;!-- markdownlint-disable MD033 --&gt;\n&lt;div&gt;HTML content&lt;/div&gt;\n&lt;span&gt;More HTML&lt;/span&gt;\n&lt;!-- markdownlint-enable MD033 --&gt;\nFor an entire file:\n&lt;!-- markdownlint-disable MD013 MD033 --&gt;\nIn a .markdownlint.json config file:\n{\n  \"MD013\": false,\n  \"MD033\": false\n}\nPlease edit the existing .markdownlint.json file in case you want to ignore certain rules project-wide."
  },
  {
    "objectID": "guides.html",
    "href": "guides.html",
    "title": "Guides",
    "section": "",
    "text": "What is a guide?\n\n\n\nThese guides help you find answers to questions that come up while doing research. They help guide you through various topics at once.\nMissing a guide? You can submit questions you are dealing with using the Contribution portal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you archive and publish your data?\n\n\n\nPublish & Share\n\n\n\nAll data and software leading to a published result, must be archived and published.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you comply with the GDPR?\n\n\n\nPlan & Design\n\n\n\nPersonal data must be protected.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you discover and reuse existing research data?\n\n\n\nDiscover & Initiate\n\n\n\nThere is so much data out there, that we want to help you find your way more easily.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you ensure data protection and security during collection, storage, and transfer?\n\n\n\nCollect & Store\n\n\n\nLearn about how to secure research data at any stage.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you ensure data provenance and accurate data analysis?\n\n\n\nProcess & Analyse\n\n\n\nWhere data and results come from matters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you ensure research data is FAIR?\n\n\n\nDocument & Preserve\n\n\n\nMaking your data Findable, Accessible, Interopable, Reusable is more doable than you might think.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you publish FAIR software\n\n\n\nPublish & Share\n\n\n\nA step-wise guide to make your software Findable, Accesible, Interoperable and Reusable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you set up research data management from the start?\n\n\n\nPlan & Design\n\n\n\nA good plan is half the work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you use Open Science Framework (OSF) in your research project?\n\n\n\nCollect & Store\n\nProcess & Analyse\n\nPublish & Share\n\n\n\nOSF supports an open research life cycle.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat policies and regulations support VU’s vision on Open Science?\n\n\nAs open as possible, as closed as necessary.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat research data services and support are available for VU researchers?\n\n\nWho is who and resources that can help you along your research journey.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "topics/finding-existing-software.html",
    "href": "topics/finding-existing-software.html",
    "title": "Finding Existing Research Software",
    "section": "",
    "text": "Depending on your particular field of research, there may be research software available that can help you develop your research.\nThere is a lot of proprietary software which can be acquired through the VU. Proprietary software generally has strict constraints regarding further sharing and re-use of the software.\nOpen-source software allows you to use and build upon existing software available in a variety of programming languages and domains. Research software can be found through both generic and discipline-specific registries or catalogues.\nWhen re-using research software, you must comply to constraints imposed by the licence of that software. Technically, this means some familiarity is needed with the rules and regulations governing software copyright and intellectual property rights. Practically, you will need to be compatible with the licence’s terms and conditions.\nThe following scheme provides an overview of compatibility of commonly used software licences:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombine with ↓\n\n\n\n\n\n\n\n\n\n\nOriginal →\n\nCC0\nMIT\nBSD\nApache\nGPL, AGPL, LGPL\nProprietary\n\n\n\nCCO\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nMIT\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nBSD\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nApache\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nGPL, AGPL, LGPL\nYES\nYES\nYES\nNO\nYES\nNO\n\n\n\nProprietary\nYES\nYES\nYES\nClaused\nNO\nDepends on licence\n\n\n\nA more complete list of open source licences with terms and conditions is available on Choose A License.\nIXA can provide legal help with the re-use of software."
  },
  {
    "objectID": "topics/finding-existing-software.html#re-using-existing-software",
    "href": "topics/finding-existing-software.html#re-using-existing-software",
    "title": "Finding Existing Research Software",
    "section": "",
    "text": "Depending on your particular field of research, there may be research software available that can help you develop your research.\nThere is a lot of proprietary software which can be acquired through the VU. Proprietary software generally has strict constraints regarding further sharing and re-use of the software.\nOpen-source software allows you to use and build upon existing software available in a variety of programming languages and domains. Research software can be found through both generic and discipline-specific registries or catalogues.\nWhen re-using research software, you must comply to constraints imposed by the licence of that software. Technically, this means some familiarity is needed with the rules and regulations governing software copyright and intellectual property rights. Practically, you will need to be compatible with the licence’s terms and conditions.\nThe following scheme provides an overview of compatibility of commonly used software licences:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombine with ↓\n\n\n\n\n\n\n\n\n\n\nOriginal →\n\nCC0\nMIT\nBSD\nApache\nGPL, AGPL, LGPL\nProprietary\n\n\n\nCCO\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nMIT\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nBSD\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nApache\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nGPL, AGPL, LGPL\nYES\nYES\nYES\nNO\nYES\nNO\n\n\n\nProprietary\nYES\nYES\nYES\nClaused\nNO\nDepends on licence\n\n\n\nA more complete list of open source licences with terms and conditions is available on Choose A License.\nIXA can provide legal help with the re-use of software."
  },
  {
    "objectID": "topics/finding-existing-software.html#finding-existing-research-software",
    "href": "topics/finding-existing-software.html#finding-existing-research-software",
    "title": "Finding Existing Research Software",
    "section": "Finding Existing Research Software",
    "text": "Finding Existing Research Software\nThere is a large growth in the number of available open source research software. Many registries (also known as catalogues or “yellow pages”) are available to find existing research software. For example, PyPI (for python), CRAN (for R), Research Software Directory (generic).\nAn extensive list of research software registries is maintained by the eScience Center."
  },
  {
    "objectID": "topics/metadata.html",
    "href": "topics/metadata.html",
    "title": "Metadata",
    "section": "",
    "text": "Metadata provide information about your data. Structured metadata are intended to provide this information in a standardised way. The structured metadata are readable for both humans and machines. It can be used by data catalogues, for example DataCite Commons.\nThe standardisation of metadata involves the following aspects:"
  },
  {
    "objectID": "topics/metadata.html#metadata-standards",
    "href": "topics/metadata.html#metadata-standards",
    "title": "Metadata",
    "section": "Metadata standards",
    "text": "Metadata standards\nMetadata standards allow for easier exchange of metadata and harvesting of the metadata by search engines. Many certified archives use a metadata standard for the descriptions. If you choose a data repository or registry, you should find out which metadata standard they use. At VU Amsterdam the following standards are used:\n\nYoda uses the DataCite metadata standard\nDataverseNL uses the Dublin Core metadata standard\nVU Amsterdam Research Information System PURE uses the CERIF metadata standard\n\nMany archives implement or make use of specific metadata standards. The UK Digital Curation Centre (DCC) provides an overview of metadata standards for different disciplines. The list is a great and useful resource in establishing and carrying out your research methodology."
  },
  {
    "objectID": "topics/metadata.html#controlled-vocabularies-classifications",
    "href": "topics/metadata.html#controlled-vocabularies-classifications",
    "title": "Metadata",
    "section": "Controlled Vocabularies & Classifications",
    "text": "Controlled Vocabularies & Classifications\nControlled vocabularies are lists of terms created by domain experts to refer to a specific phenomenon or event. Controlled vocabularies are intended to reduce ambiguity that is inherent in normal human languages where the same concept can be given different names and to ensure consistency. Controlled vocabularies are used in subject indexing schemes, subject headings, thesauri, taxonomies and other knowledge organisation systems. Some vocabularies are very internationally accepted and standardised and may even become an ISO standard or a regional standard/classification. Controlled vocabularies can be broad in scope or very limited to a specific field. When a Data Management Plan template includes a question on the used ontology (if any), what is usually meant is: is there a specific vocabulary or classification system used? The National Bioinformatics Infrastructure Sweden gives some more explanation about controlled vocabularies and ontologies. In short, an ontology does not only describe terms, but also indicates relationships between these terms.\nExamples of controlled vocabularies are:\n\nCDWA (Categories for the Description of Works of Art)\nGetty Thesaurus of Geographic names\nNUTS (Nomenclature of territorial units for statistics)\nMedical Subject HEadings (MeSH)\nThe Environment Ontology (EnvO)\n\nMany examples of vocabularies and classification systems can be found at the FAIRsharing.org website. It has a large list for multiple disciplines. If you are working on new concepts or new ideas and are using or creating your own ontology/terminology, be sure to include them as part of the metadata documentation in your dataset (for example as part of your codebook)."
  },
  {
    "objectID": "topics/metadata.html#metadata-levels",
    "href": "topics/metadata.html#metadata-levels",
    "title": "Metadata",
    "section": "Metadata levels",
    "text": "Metadata levels\nFinally a distinction can be made on the level of description. Metadata can be about the data as a whole or about part of the data. It can depend on the research domain and the tools that are used on how many levels the data can be described. In repositories like Yoda and DataverseNL it is common practice to only create structured metadata on the level of the data as a whole. The Consortium of European Social Science Data Archives (CESSDA) explains this distinction for several types of data in their Data Management Expert Guide.\n\n\n\nFlowchart indicating a project with a Folder a and Folder b, where Folder a has File 1 and File 2. The project, Folder a, and File 1, have linked metadata to them."
  },
  {
    "objectID": "topics/metadata.html#dataset-registration",
    "href": "topics/metadata.html#dataset-registration",
    "title": "Metadata",
    "section": "Dataset registration",
    "text": "Dataset registration\nWhen you want to make sure that your dataset is findable it is recommended that the elements of the description of your dataset are made according to a certain metadata standard that allows for easier exchange of metadata and harvesting of the metadata by search engines. Many certified archives use a metadata standard for the descriptions. If you choose a data repository or registry, you should find out which metadata standard they use. At VU Amsterdam the following standards are used:\n\nDataverseNL and DANS use the Dublin Core metadata standard\nVU Amsterdam Research Portal PURE uses the CERIF metadata standard\n\nMany archives implement or make use of specific metadata standards. The UK Digital Curation Centre (DCC) provides an overview of metadata standards for different disciplines. The list is a great and useful resource in establishing and carrying out your research methodology. Go to the overview of metadata standards. More important tips are available at Dataset & Publication."
  },
  {
    "objectID": "topics/data-collection.html",
    "href": "topics/data-collection.html",
    "title": "Data Collection",
    "section": "",
    "text": "Data collection may consist of the re-use of existing data and/or the generation of new data.\nFor data to be considered valid and reliable, data collection should occur consistently and systematically throughout the course of the research project. Within disciplines, there are established methodologies, procedures and techniques that help researchers ensure high quality of collected data. In general, important aspects of data collection include:\nSystematic data collection is essential for ensuring the reproducibility of research. When data is collected in a consistent and organized manner, it improves the quality and reliability of the research, making the data easier to share and reproduce by others. High-quality data also contributes to making data FAIR (Findable, Accessible, Interoperable, and Reusable), as well-organized and well-documented data is more likely to be reused effectively. The principles of making data FAIR are discussed in detail under the topic FAIR Principles."
  },
  {
    "objectID": "topics/data-collection.html#data-collection-tools",
    "href": "topics/data-collection.html#data-collection-tools",
    "title": "Data Collection",
    "section": "Data Collection Tools",
    "text": "Data Collection Tools\nThe tools being used in research to collect data are immensely diverse. For that reason, we will not provide an exhaustive overview here. What is important for data collection tools in relation to RDM is where such tools store the data that you collect and in which format. The storage location is particularly important when you are working with personal data. For example, the privacy legislation in the United States is very different from the European General Data Protection Regulation (GDPR). Hence, personal data collected in a Dutch research institute may not be stored on American servers. It is important to keep that in mind when you are contemplating which tool to use for your data collection.\nIf you are collecting personal data and you decide to use a tool for which no contract exists between VU Amsterdam and the provider of the software or tool, a service agreement and a processing agreement must be drawn up. Contact the 🔒 privacy champion of your faculty for more information and a model processing agreement.\n\nQuestionnaire tools\nThe Faculty of Behavioural and Movement Sciences has developed a document with tips for safe use of the questionnaire tools Qualtrics and Survalyzer. The document was made for FGB researchers specifically but can also be helpful for others. Consult this document if you need a questionnaire tool to collect your data."
  },
  {
    "objectID": "topics/data-collection.html#data-collection-in-collaboration",
    "href": "topics/data-collection.html#data-collection-in-collaboration",
    "title": "Data Collection",
    "section": "Data Collection in Collaboration",
    "text": "Data Collection in Collaboration\nSome research projects involve the participation of multiple organisations or institutes and may include even cross-border co-operation. When data is collected by several organisations, a Data Management Plan should provide information on who is responsible for which part of the data collection and storage. It should also provide information on how specific data collections are related to which part(s) of the research goal(s). Describing this precisely will help you to determine if a consortium agreement or joint controller agreement is necessary. You see a general example of such a specification in the table below:\n\n\n\n\n\n\n\n\n\n\nData Stage\nDataset description\nResponsible organization for collection\nData origin\nData purpose\n\n\n\n\nRaw data\nCommunity level surveys\nVU Amsterdam\nAmsterdam, The Hague, Rotterdam\nIdentifying perceived problems, System responsiveness\n\n\nRaw data\nTrials & Focus Group Interviews\nLondon School of Hygiene and Tropical Medicine (LSHTM)\nGermany, Switzerland\nTrials to evaluate programs on . . ., Focus Group interviews to identify barriers to . . .\n\n\nRaw data\nPollution measurements using fish\nOceanographic Institute of Sweden\nCoastal waters, Northeast Spain\nEstablish pollution levels of plastic"
  },
  {
    "objectID": "topics/data-collection.html#data-collection-protocols",
    "href": "topics/data-collection.html#data-collection-protocols",
    "title": "Data Collection",
    "section": "Data Collection Protocols",
    "text": "Data Collection Protocols\nRegardless of the field of study or preference for defining data (quantitative, qualitative), accurate data collection is essential to maintaining the integrity (structure) of research. Both the selection of appropriate data collection instruments (existing, modified, or newly developed) and clearly delineated instructions for their correct use reduce the likelihood of errors.\nThere are two approaches for reducing and/or detecting errors in data which can help to preserve the integrity of your data and ensure scientific validity. These are:\n\nQuality assurance - activities that take place before data collection begins\nQuality control - activities that take place during and after data collection\n\nQuality assurance precedes data collection and its main focus is ‘prevention’ (i.e., forestalling problems with data collection). Prevention is the most cost-effective activity to ensure the integrity of data collection. This proactive measure is best demonstrated by the standardization of protocol developed in a comprehensive and detailed procedures manual for data collection.\nWhile quality control activities (detection/monitoring and action) occur during and after data collection, the details should be carefully documented in the procedures manual. A clearly defined communication structure is a necessary pre-condition for monitoring and tracking down errors. Quality control also identifies the required responses, or ‘actions’ necessary to correct faulty data collection practices and also minimise future occurrences.\nSome sources for protocols:\n\nHANDS Handbook for Adequate Natural Data Stewardship by the Federation of Dutch University Medical Centers (UMCs)\nProtocols.io - an open access repository of protocols\nSpringer Protocols - free and subscribed protocols collected by Springer."
  },
  {
    "objectID": "topics/scicloud.html",
    "href": "topics/scicloud.html",
    "title": "SciCloud",
    "section": "",
    "text": "IT for Research (ITvO) offers SciCloud, a service where server capacity can be purchased to support research applications. SciCloud virtual servers are easy to implement, easy to scale up and down and have competitive pricing based on agreed purchase. The virtual server can be placed in an external network, so services running on it can be made internet accessible. It can also run on an internal network for extra security and access to some VU services.\nSciCloud is based on the open source middleware OpenNebula (ONE) and offers a service that allows users to quickly start with a virtual server based on available templates, or to upload one of their own virtual images. This concept is known as Infrastructure as a Service (IaaS)."
  },
  {
    "objectID": "topics/scicloud.html#what-is-it",
    "href": "topics/scicloud.html#what-is-it",
    "title": "SciCloud",
    "section": "",
    "text": "IT for Research (ITvO) offers SciCloud, a service where server capacity can be purchased to support research applications. SciCloud virtual servers are easy to implement, easy to scale up and down and have competitive pricing based on agreed purchase. The virtual server can be placed in an external network, so services running on it can be made internet accessible. It can also run on an internal network for extra security and access to some VU services.\nSciCloud is based on the open source middleware OpenNebula (ONE) and offers a service that allows users to quickly start with a virtual server based on available templates, or to upload one of their own virtual images. This concept is known as Infrastructure as a Service (IaaS)."
  },
  {
    "objectID": "topics/scicloud.html#what-can-it-be-used-for",
    "href": "topics/scicloud.html#what-can-it-be-used-for",
    "title": "SciCloud",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nIn principle you can run any software you want on a SciCloud server. Linux OS is preferred, but a Windows server is also a possibility.\nTypical use cases are:\n\nRunning web applications and services that need to be publicly accessible 24/7, for example a website showcasing your research, a wiki, chatbot, etc.\nHosting a licensed server application for your research group, such as software for analysis, software needed to run lab equipment or elab journal software.\nThe Virtual Server can also be connected to SciStor for environments that need fast access to large amounts of data.\n\nNote that the SciCloud environment has no GPU, so it is not suitable for running graphical environments and machine learning."
  },
  {
    "objectID": "topics/scicloud.html#how-to-request-access",
    "href": "topics/scicloud.html#how-to-request-access",
    "title": "SciCloud",
    "section": "How to request access",
    "text": "How to request access\nVia a form on 🔒ServiceNow, go to: IT &gt; My work field &gt; Research &gt; SciCloud &gt; Order SciCloud capacity\nAfter you have requested a SciCloud virtual server, IT for Research will schedule an interview to discuss your wishes."
  },
  {
    "objectID": "topics/scicloud.html#are-there-costs-involved",
    "href": "topics/scicloud.html#are-there-costs-involved",
    "title": "SciCloud",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nConfigurations of a virtual server are based on standard “Building Blocks”, combinations of the following two options can be purchased:\n• Building Block 1: 1 CPU core with 2 GB RAM\n• Building Block 2: 1 CPU core with 4 GB RAM\nCosts are calculated as: €1 per CPU per month, €1 per GB memory per month, €0.40 per GB storage per year (minimum 20GB)"
  },
  {
    "objectID": "topics/scicloud.html#getting-started",
    "href": "topics/scicloud.html#getting-started",
    "title": "SciCloud",
    "section": "Getting started",
    "text": "Getting started\nThe IT for Research Team will set up the server(s) with the OS of your choice (Windows or Linux) and will set up a root account for you:\n\nFor access to a Linux server you will need to provide a personal SSH key protected with a passphrase. You will be able to access SSH from home.\nFor access to Windows servers use Remote Desktop Protocol (RDP), only via 🔒eduVPN institute access.\n\nRoot access to the server allows you to install all the software you need. Note that IT for Research can help you getting started and will automatically install OS security updates, but you are responsible for installing and maintaining software yourself.\nIt is possible to take snapshots or clones of the virtual server yourself. This allows you to go back to a previously created configuration, if necessary. In addition, ITvO makes daily backups with which a virtual machine can be restored for up to 30 days on request."
  },
  {
    "objectID": "topics/scicloud.html#contact",
    "href": "topics/scicloud.html#contact",
    "title": "SciCloud",
    "section": "Contact",
    "text": "Contact\nWondering if SciCloud fits your research needs? Please contact IT for Research"
  },
  {
    "objectID": "topics/data-protection.html",
    "href": "topics/data-protection.html",
    "title": "Data Protection",
    "section": "",
    "text": "Protection from what? From whom? When, and why? Before we talk about data protection, let us consider security first. More often than not, ‘security’ is regarded as a fixed state. In reality, security is an assessment of the level of protection against a certain threat, that you consider to deal with that threat adequately enough. Whether or not security is accurate depends on the value of the data and the quality of protective measures.\nThe question for you as a researcher is ‘when are the measures that you take secure enough?’. In order to answer this, please be aware that there are three entities that have an opinion about what is ‘secure enough’, namely: the law, the University, and you yourself as the data processor.\nThe University has a Security Baseline that sets a norm for levels of protection for every application it uses. The Baseline is based on international standards. For each of these applications, the University is considering for which means the security of these applications are adequate enough.\nThe legal requirements for the processing of personal data can be found in the section ‘GDPR and Privacy’ under Plan & Design There are additional laws and regulations as well. The assumption is that you are familiar with these, especially with laws regulating medical and criminal research.\nWhat you personally consider to be secure might be very different from what your colleagues, the Faculty or the University considers to be secure enough and the norms will vary with the variety of data that is being processed by different researchers and Faculties of VU Amsterdam. Very generally speaking, there are three points of protection to consider:\n\nProtection against data loss, for which you need a back up periodically.\nProtection against data leakage, for which you need to consider all storage places and their access points.\nProtection of data integrity, for which you need version control and synchronisation management.\n\nThe security of your protection measures depends on the threat you face. We often think of threats as active, and motivated by bad intentions. But most common forms of data loss are accidental and most leakage is caused by trusting others. In reality, devices just get lost or break down, people download malware by accident, and each one of us forgets to save a document at times or gets confused about which version was last updated.\nIn all cases, protection starts with oversight on where your data is stored and processed. If you forget that you temporarily stored it in a certain place, you have then lost oversight of where that data is. The opposite is also true: if you know where you data is, you have insight in the level of security of the space in which you store it. As you can see, protection begins with organising your work in a reliable manner and thinking through your steps.\nFor example, if you data is on your laptop and synchronised with your phone, then it is stored in two places. Perhaps this is enough back up, perhaps not. If you put both you devices in the same bag and you lose your bag, you have no backup. A backup to an online storage might be a good solution, but might also mean your data leaks via the internet of via the storage provider who sells the data and your behavioural data for profit. Most importantly, there is no absolute security. It is best if you consider your personal behaviour and then think of scenarios that are more or less likely to happen and what would impact you most. If you frequently work in public places you should make it a habit to lock your device each time you leave it. If you eat and drink behind your desk often, better work with a remote keyboard to protect your laptop from the unavoidable coffee shower. Do you save your respondents’ contact details on your personal phone? Then protect it with a pin.\nHere are some basic protection guidelines:\n\nData are very difficult to erase. You have probably never done it.\nDecide how to back up data and test it before you rely on it.\nDo not give others your log-in credentials. If you have done so and your family members use your work device, then change it.\nDo not use passwords twice, do not use your birthday, initials, streetname, hobby.\nEncryption sounds secure, but it fails completely without good password management."
  },
  {
    "objectID": "topics/data-protection.html#what-is-data-protection",
    "href": "topics/data-protection.html#what-is-data-protection",
    "title": "Data Protection",
    "section": "",
    "text": "Protection from what? From whom? When, and why? Before we talk about data protection, let us consider security first. More often than not, ‘security’ is regarded as a fixed state. In reality, security is an assessment of the level of protection against a certain threat, that you consider to deal with that threat adequately enough. Whether or not security is accurate depends on the value of the data and the quality of protective measures.\nThe question for you as a researcher is ‘when are the measures that you take secure enough?’. In order to answer this, please be aware that there are three entities that have an opinion about what is ‘secure enough’, namely: the law, the University, and you yourself as the data processor.\nThe University has a Security Baseline that sets a norm for levels of protection for every application it uses. The Baseline is based on international standards. For each of these applications, the University is considering for which means the security of these applications are adequate enough.\nThe legal requirements for the processing of personal data can be found in the section ‘GDPR and Privacy’ under Plan & Design There are additional laws and regulations as well. The assumption is that you are familiar with these, especially with laws regulating medical and criminal research.\nWhat you personally consider to be secure might be very different from what your colleagues, the Faculty or the University considers to be secure enough and the norms will vary with the variety of data that is being processed by different researchers and Faculties of VU Amsterdam. Very generally speaking, there are three points of protection to consider:\n\nProtection against data loss, for which you need a back up periodically.\nProtection against data leakage, for which you need to consider all storage places and their access points.\nProtection of data integrity, for which you need version control and synchronisation management.\n\nThe security of your protection measures depends on the threat you face. We often think of threats as active, and motivated by bad intentions. But most common forms of data loss are accidental and most leakage is caused by trusting others. In reality, devices just get lost or break down, people download malware by accident, and each one of us forgets to save a document at times or gets confused about which version was last updated.\nIn all cases, protection starts with oversight on where your data is stored and processed. If you forget that you temporarily stored it in a certain place, you have then lost oversight of where that data is. The opposite is also true: if you know where you data is, you have insight in the level of security of the space in which you store it. As you can see, protection begins with organising your work in a reliable manner and thinking through your steps.\nFor example, if you data is on your laptop and synchronised with your phone, then it is stored in two places. Perhaps this is enough back up, perhaps not. If you put both you devices in the same bag and you lose your bag, you have no backup. A backup to an online storage might be a good solution, but might also mean your data leaks via the internet of via the storage provider who sells the data and your behavioural data for profit. Most importantly, there is no absolute security. It is best if you consider your personal behaviour and then think of scenarios that are more or less likely to happen and what would impact you most. If you frequently work in public places you should make it a habit to lock your device each time you leave it. If you eat and drink behind your desk often, better work with a remote keyboard to protect your laptop from the unavoidable coffee shower. Do you save your respondents’ contact details on your personal phone? Then protect it with a pin.\nHere are some basic protection guidelines:\n\nData are very difficult to erase. You have probably never done it.\nDecide how to back up data and test it before you rely on it.\nDo not give others your log-in credentials. If you have done so and your family members use your work device, then change it.\nDo not use passwords twice, do not use your birthday, initials, streetname, hobby.\nEncryption sounds secure, but it fails completely without good password management."
  },
  {
    "objectID": "topics/data-protection.html#data-protection",
    "href": "topics/data-protection.html#data-protection",
    "title": "Data Protection",
    "section": "Data Protection",
    "text": "Data Protection\nThere can be many reasons why the data of a project needs to be kept protected:\n\nSensitivity of the data collected\nProtection of the research data from competition\nCommercial reasons / Intellectual property\nEtc.\n\n\n\n\nAn image of a lock composed of code in a matrix green style.\n\n\nThere are also many levels of security that may be implemented, depending on the needs. Sometimes it will be enough to use a password-protected cloud-based server. In extreme cases encryption may be needed and also when data is transmitted between researchers or organisations. You should contact the RDM Support Desk to discuss available options, who may connect you to legal experts where sensitive data is concerned. Check the Data Storage topic for links to find out more on campus solutions and cloud-based options.\n\n\n\n\n\n\nTip\n\n\n\nSee also the Safe Data Transfer topic for more information on how to transport and transfer data."
  },
  {
    "objectID": "topics/software-publishing.html",
    "href": "topics/software-publishing.html",
    "title": "Software Publishing",
    "section": "",
    "text": "When we mention software publishing at VU Amsterdam, we mean the following:\n\nMaking research data, associated metadata, accompanying documentation, and software code (where relevant) accessible in a repository in such a manner that they can be discovered on the Web and referred to in a unique and persistent way (Inspired by the definition in the CODATA Research Data Management Terminology).\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for publishing all research software that leads to a published result (either in an article or other narrative form) for scientific reuse, meaning that these materials can be discovered on the Web and referred to in a unique and persistent way. This means that the existence of software is announced and that basic information about this software (like title, creator, moment of publication, version, etc.) can be found online, but it doesn’t necessarily mean that others will be able to access and download the actual software. If software contains (or will reveal) confidential information, information to which intellectual properties apply, and/or personal data, an assessment must take place to determine whether the software can be made available for reuse and if so, under which conditions. A custom licence (‘restricted’ or ‘closed’) will indicate if conditional access can be granted, and if so, what the conditions are."
  },
  {
    "objectID": "topics/software-publishing.html#what-is-software-publishing",
    "href": "topics/software-publishing.html#what-is-software-publishing",
    "title": "Software Publishing",
    "section": "",
    "text": "When we mention software publishing at VU Amsterdam, we mean the following:\n\nMaking research data, associated metadata, accompanying documentation, and software code (where relevant) accessible in a repository in such a manner that they can be discovered on the Web and referred to in a unique and persistent way (Inspired by the definition in the CODATA Research Data Management Terminology).\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for publishing all research software that leads to a published result (either in an article or other narrative form) for scientific reuse, meaning that these materials can be discovered on the Web and referred to in a unique and persistent way. This means that the existence of software is announced and that basic information about this software (like title, creator, moment of publication, version, etc.) can be found online, but it doesn’t necessarily mean that others will be able to access and download the actual software. If software contains (or will reveal) confidential information, information to which intellectual properties apply, and/or personal data, an assessment must take place to determine whether the software can be made available for reuse and if so, under which conditions. A custom licence (‘restricted’ or ‘closed’) will indicate if conditional access can be granted, and if so, what the conditions are."
  },
  {
    "objectID": "topics/software-publishing.html#purpose",
    "href": "topics/software-publishing.html#purpose",
    "title": "Software Publishing",
    "section": "Purpose",
    "text": "Purpose\nPublishing software is crucial for the accessibility of research output. It helps to make VU Amsterdam’s research visible, verifiable and, where possible, reusable. These are important goals for VU Amsterdam, as they contribute to a transparent reseach practice and enable other researchers to build on work that has been done by VU researchers. Publishing software means that researchers make their software known to the world, even if they cannot be accessed by others directly, but only after granting conditional access. This enables other researchers to reuse the software, leading to more impact of research that is carried out at VU Amsterdam. It may also result in new collaborations and citations. Another advantage is that it makes the work of a researcher more visible, going beyond the visibility of a publication alone.\nPublication of research is not complete without the data used and the code written to clean and analyse it. Publishing data and software allows other researchers to use and build upon your work."
  },
  {
    "objectID": "topics/software-publishing.html#requirements",
    "href": "topics/software-publishing.html#requirements",
    "title": "Software Publishing",
    "section": "Requirements",
    "text": "Requirements\nAt VU Amsterdam, we strive to make our research software FAIR. Publishing software is a crucial step in making it findable. As explained in the definition above, publishing means that you make software discoverable on the internet. As a result, other researchers can find out about the existence of your code and consider whether it may be useful for them in their own research.\nA persistent identifier helps in making software findable, because it ensures that the persistent identifier always resolves to the correct digital object. Rich metadata also contribute to the findability of software. The more information you provide, the more likely it is that others will be able to find your software. It is beneficial to use terminology that is common in your discipline when filling out the metadata fields in a repository as well as key words in a key words or notes section of the metadata. Rich information about your software will also help other researchers determine whether your software is potentially relevant for them and is faster to assess than reading through the code itself.\nRepositories provided by VU Amsterdam (Yoda and DataverseNL) will generate a Persistent Identifier for your software and they will ask you to fill out metadata fields. In this way, they contribute to making your software findable. This will also be the case for external trusted repositories (such as Zenodo).\nWhen you publish your software, it is important to apply a licence to it. If you don’t do that, others will not be allowed to reuse your software. A licence is a legal instrument that tells others what they can and cannot do with your software and is therefore an important aspect of making software reusable.\nSince code can be written in any number of ways to solve a problem, the absolute minimum that should be published to ensure verification is a (working) copy of the code/workflow that uses the raw data to produce the end result you have presented in your research and a list of the dependencies and their versions."
  },
  {
    "objectID": "topics/software-publishing.html#how-does-software-publishing-work-in-practice",
    "href": "topics/software-publishing.html#how-does-software-publishing-work-in-practice",
    "title": "Software Publishing",
    "section": "How does software publishing work in practice?",
    "text": "How does software publishing work in practice?\nAs mentioned above, software publishing must happen through a repository. These can be provided by VU Amsterdam or third parties.\n\nVU Amsterdam:\n\nYoda\nDataverseNL\n\nExternal:\n\nZenodo\n\n\nOften, code can also be published through software developing platforms.\n\nVU Amsterdam:\n\nGitLab\n\nExternal:\n\nCodeberg\nGithub\n\n\nSome of these provide an integrated option to get a DOI for your software or have documentation on how to include one within their recommended workflow.\nNote that OSF can be used to publish code as well, but that you cannot assign a DOI to your software files specifically. You can assign a DOI at project level, but currently it is not possible in OSF to create an immutable copy of a file with its own DOI. For that reason, OSF is not the most suitable option for publishing software. If you do prefer to make your research output visible through OSF, you can consider having an additional copy of your code in the Yoda vault or connecting published software in DataverseNL to your OSF project, so that it can be viewed in OSF.\nDetailed workflows addressing publishing software can be found in the guide about making your software FAIR and the topic about archiving software."
  },
  {
    "objectID": "topics/software-publishing.html#how-does-this-help-you-in-your-research",
    "href": "topics/software-publishing.html#how-does-this-help-you-in-your-research",
    "title": "Software Publishing",
    "section": "How does this help you in your research?",
    "text": "How does this help you in your research?\nFormally published software is not always expected from research, but it can have many benefits. Publishing your software will not only allow for more citations, but it will also help you to reach broader audiences and provide more opportunities for collaboration both outside your field and institution. Although not always needed, publishing your software can help with grant applications and foster a community norm of sharing code in your field speeding up research by avoiding duplication."
  },
  {
    "objectID": "topics/data-backup.html",
    "href": "topics/data-backup.html",
    "title": "Data Backup",
    "section": "",
    "text": "Backing up your data is about ensuring your data are in at least two and ideally three independent places."
  },
  {
    "objectID": "topics/data-backup.html#why-backup",
    "href": "topics/data-backup.html#why-backup",
    "title": "Data Backup",
    "section": "Why backup?",
    "text": "Why backup?\nHard drives fail, computers get stolen or lost, or your data may accidentally get deleted. To avoid data loss, backing up your data regularly is essential. Ideally, you should have your data stored in at least two, but ideally three different locations. Most cloud-based tools will automatically handle backup for you, but they don’t protect you from your own mistakes. If you work with data that cannot be easily recreated or recalculated and ensure that it is sufficiently backed up with the 3-2-1 rule. This is especially important when migrating your data, such as when updating your operating system to a new major version, or when you get a new computer."
  },
  {
    "objectID": "topics/data-backup.html#rule",
    "href": "topics/data-backup.html#rule",
    "title": "Data Backup",
    "section": "3-2-1 Rule",
    "text": "3-2-1 Rule\nThe 3-2-1 rule states that you should have:\n\n3 Copies of your data\n2 Different mediums (2 different kinds of storage)\n1 Copy is kept off-site\n\nIdeally, this is automated so that you as a user do not have to manually do anything extra to manage your data. If possible, automate this backup as well with computer scheduling tools such as Task Scheduler (Windows) or Crontab (Linux).\nNote that the VU-supported storage solutions (SciStor, Research Drive and Yoda) have enough safeguards to satisfy the 3-2-1 rule. Storing your data on one of these platforms plus a working copy on your laptop, if needed, is sufficient."
  },
  {
    "objectID": "topics/data-backup.html#simple-synchronising-solutions",
    "href": "topics/data-backup.html#simple-synchronising-solutions",
    "title": "Data Backup",
    "section": "Simple Synchronising Solutions",
    "text": "Simple Synchronising Solutions\nThe VU provides access to multiple storage systems. You may use a mix of the different platforms. Some of these tools are able to automatically synchronise your data to the cloud: Teams, Onedrive and Research Drive. Check regularly if all the relevant data folders are indeed still synchronised. If you accidentally delete a file, you can restore your folder to a previous date - various systems will have different retention periods but it is usually around 1 month."
  },
  {
    "objectID": "topics/data-backup.html#data-rentention-for-vu-data-storage-platforms",
    "href": "topics/data-backup.html#data-rentention-for-vu-data-storage-platforms",
    "title": "Data Backup",
    "section": "Data rentention for VU data storage platforms",
    "text": "Data rentention for VU data storage platforms\n\nOneDrive: if you’re signed in with a work or school account, items in the recycle bin are automatically deleted after 93 days. The files can be restored to OneDrive before then, or you can permanently delete them from your OneDrive. Additionally, you can restore your OneDrive to a state from the previous 29 days. Finally, the university has an additional backup of data, which can be accessed in case of emergency. However, no rights can be derived for the emergency backup.\nSnellius: Not all of the filesystems on Snellius are backed up automatically, most notably the Project and Scratch spaces. Your home folder is backed up however. You can find more information on the Snellius website.\nSciStor: Depending on the agreements of your department, data may be backed up. Please check with your department cluster manager.\nResearch Drive: The Research Drive is backed up daily by SURF.\nYoda: Yoda is backed up daily by SURF."
  },
  {
    "objectID": "topics/data-backup.html#notes",
    "href": "topics/data-backup.html#notes",
    "title": "Data Backup",
    "section": "Notes",
    "text": "Notes\nMake sure the backup storage is suitable if your data are (privacy) sensitive. The Data Storage Finder can help you select the right tool. If you backup sensitive data to a USB drive make sure to encrypt it, for example with a tool like Cryptomator.\nUtrecht University Geo Data Team Services provide a detailed page on data backup including a discussion of data selection for backup.\nWhen your laptop and hard drive are in the same bag, the “backup” can easily get lost along with the primary data and there is thus no proper backup.\nThese are just some tips, please take responsibility over your data and make sure they are protected from loss but also from your own mistakes."
  },
  {
    "objectID": "topics/research-software.html",
    "href": "topics/research-software.html",
    "title": "Research Software",
    "section": "",
    "text": "Examples of how research software is integral to research; from Nieuwpoort en Katz\n\n\nThere is a broad definition of research software from the FAIR4RS working group:\n\n“Research Software includes source code files, algorithms, scripts, computational workflows and executables that were created during the research process or for a research purpose. Software components (e.g., operating systems, libraries, dependencies, packages, scripts, etc) that are used for research but were not created during or with a clear research intent should be considered software in research and not Research Software.”\n\nIt is important to note that not all software that is used in research is research software.\nFor example, a text editor that is used to write a paper is not research software. Nor is powerpoint, a web browser, or the software used to guide the telescope. Even tools like R or Python are not necessarily research software.\nThe code written in R or Python for an analysis would be research software, however. Just like a custom-made Excel macro that is used to analyse data. Or a custom-made web application that is used to collect data.\nResearch Software is mainly used in “Collecting” and “Processing & analyzing” steps. However, non-research software can also be used in these steps, and research software can also be used in other steps.\nMaterials adapted from the Netherlands eScience Center under CC-BY 4.0."
  },
  {
    "objectID": "topics/research-software.html#what-is-research-software",
    "href": "topics/research-software.html#what-is-research-software",
    "title": "Research Software",
    "section": "",
    "text": "Examples of how research software is integral to research; from Nieuwpoort en Katz\n\n\nThere is a broad definition of research software from the FAIR4RS working group:\n\n“Research Software includes source code files, algorithms, scripts, computational workflows and executables that were created during the research process or for a research purpose. Software components (e.g., operating systems, libraries, dependencies, packages, scripts, etc) that are used for research but were not created during or with a clear research intent should be considered software in research and not Research Software.”\n\nIt is important to note that not all software that is used in research is research software.\nFor example, a text editor that is used to write a paper is not research software. Nor is powerpoint, a web browser, or the software used to guide the telescope. Even tools like R or Python are not necessarily research software.\nThe code written in R or Python for an analysis would be research software, however. Just like a custom-made Excel macro that is used to analyse data. Or a custom-made web application that is used to collect data.\nResearch Software is mainly used in “Collecting” and “Processing & analyzing” steps. However, non-research software can also be used in these steps, and research software can also be used in other steps.\nMaterials adapted from the Netherlands eScience Center under CC-BY 4.0."
  },
  {
    "objectID": "topics/researchcloud.html",
    "href": "topics/researchcloud.html",
    "title": "SURF Research Cloud",
    "section": "",
    "text": "SURF Research Cloud is a portal where you easily build a virtual research environment. You can use preconfigured workspaces and datasets or add them yourself. Institutions, research communities and suppliers can contribute to Research Cloud’s functionality and catalogue by integrating their computing and data services.\nSURF Research Cloud is hosted at the SURF data centre in Amsterdam."
  },
  {
    "objectID": "topics/researchcloud.html#what-is-it",
    "href": "topics/researchcloud.html#what-is-it",
    "title": "SURF Research Cloud",
    "section": "",
    "text": "SURF Research Cloud is a portal where you easily build a virtual research environment. You can use preconfigured workspaces and datasets or add them yourself. Institutions, research communities and suppliers can contribute to Research Cloud’s functionality and catalogue by integrating their computing and data services.\nSURF Research Cloud is hosted at the SURF data centre in Amsterdam."
  },
  {
    "objectID": "topics/researchcloud.html#what-can-it-be-used-for",
    "href": "topics/researchcloud.html#what-can-it-be-used-for",
    "title": "SURF Research Cloud",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nSURF Research Cloud enables you to run 1 or more servers with applications that can be accessible over the internet.\n\nHosting web applications, these can be connected to SRAM for secure authentication. You can easily start more servers to increase availability and preformance.\nRunning a desktop environment with analysis tools, use your favourite desktop tools on an environment with more performance. Unlike for SciCloud, GPU resources are available. You can easily connect an environment to your data on Research Drive or Yoda.\nHosting a highly secure research environment where sensitive data cannot leave the VRE: SURF SANE."
  },
  {
    "objectID": "topics/researchcloud.html#are-there-costs-involved",
    "href": "topics/researchcloud.html#are-there-costs-involved",
    "title": "SURF Research Cloud",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nYou will need to apply for a wallet with credits, see How to request access below.\nIn 2025 the credit cost is:\n\n1.03 credits per CPU hour (only if the system is active).\n21 credits per GPU hour (only if the system is active).\nHDD storage 681 credits per TB per month, SSD storage 1525 credits per TB per month.\n\nSee the SURF services and rates document."
  },
  {
    "objectID": "topics/researchcloud.html#how-to-request-access",
    "href": "topics/researchcloud.html#how-to-request-access",
    "title": "SURF Research Cloud",
    "section": "How to request access",
    "text": "How to request access\nAll VU researchers can get access to SURF Research Cloud. To start building an environment in Research Cloud you need 2 things:\n\n1. An SRAM Collaboration connected to Research Cloud\n\nFirst apply for a new SRAM Collaboration (CO): log in to SRAM and click the “Request collaboration” button.\nThe SRAM admins at IT for Research (ITvO) will contact you to discuss your specific needs and help you to get started.\nOnce the Collaboration request is approved you can connect the Research Cloud Application to the new collaboration.\nInvite the colleagues that need to work in your VRE to your new CO.\n\n\n\n2. A Wallet with credits\nThere are 2 ways to obtain credits:\n\nApply for an NWO Small Compute Grant by following the links on the Small Compute applications page. In the request form select “SURF Research Cloud - HPC Cloud”.\nIf for whatever reason your application for this grant is denied, you could also claim credits from VU Amsterdam Research Capacity Computing Service contract with SURF contract. Please contact IT for Research for details on how to obtain these credits.\n\nOnce the request is granted you will have access to a wallet in Research Cloud and can start to build an environment."
  },
  {
    "objectID": "topics/researchcloud.html#getting-started",
    "href": "topics/researchcloud.html#getting-started",
    "title": "SURF Research Cloud",
    "section": "Getting started",
    "text": "Getting started\nDocumentation for Research Cloud can be found on the SURF User Knowledge Base.\nIT for Research can assist you in setting up a new Research Cloud environment."
  },
  {
    "objectID": "topics/researchcloud.html#contact",
    "href": "topics/researchcloud.html#contact",
    "title": "SURF Research Cloud",
    "section": "Contact",
    "text": "Contact\nWondering if SURF Research Cloud fits your research needs? Please contact IT for Research"
  },
  {
    "objectID": "topics/research-data-and-software-management-policy.html",
    "href": "topics/research-data-and-software-management-policy.html",
    "title": "Research Data and Software Management Policy",
    "section": "",
    "text": "VU Amsterdam considers the careful handling of research data and software to be very important. The university has therefore formulated a Research Data and Software Management Policy which articulates how to handle research data and software. The policy lists the responsibilities regarding research data and software management for researchers, department heads, faculty boards and the university as a whole.\n\nVU Research Data and Software Management Policy (2024) in English and in Dutch\n\nSince the VU Amsterdam policy for Research Data and Software Management is formulated in general terms, faculties have worked out more detailed policies and guidelines for their own faculty. These faculty-specific guidelines can be found below.\n\nACTA RDM policy, Academisch Centrum Tandheelkunde Amsterdam (2020, in Dutch)\nBeta RDM policy, Faculty of Science (2022)\nFGB RDM policy, Faculty of Behavioural and Movement Sciences (2023)\nFaculty of Social Sciences and Humanities (FSG):\n\nSchool of Humanities RDM policy , Faculty of Humanities (2023)\nSchool of Religion and Theology RDM policy, Faculty of Religion and Theology (2024)\nSchool of Social Sciences RDM policy, Faculty of Social Sciences (2023)\n\nRCH RDM policy, Faculty of Law (2021)\nSBE RDM policy, School of Business and Economics (2023)\n\nFor RDM policies and guidelines at Amsterdam UMC, location VUmc, please get in touch with Research Data Management Support at Amsterdam UMC.\nIf you have questions about the VU-central Research Data and Software Management Policy, please contact the RDM Support Desk."
  },
  {
    "objectID": "topics/research-data-management.html",
    "href": "topics/research-data-management.html",
    "title": "Research Data Management (RDM)",
    "section": "",
    "text": "RDM concerns the organisation, documentation, storage, archiving and sharing of digital and analogue data. Data management applies throughout the entire research data life cycle, which is visualised in the circle above. RDM aims to ensure reliable verification of results, and permits new and innovative research built on existing information. RDM is also part of the research process and is intended to make the research process as efficient as possible. The Research Support Handbook provides guidance on research data management planning, data storage and protection, data archiving, and other resources. The Data Management Plan provides information on how these activities will be carried out during the research project.\nGood data management will heighten the quality of your own research (data) as well as your institution’s scientific output, and it contributes significantly to your field as a whole.\nGood data management:\n\nPromotes the integrity of your research,\nIncreases the impact of your research,\nImproves the quality of your data,\nSupports future use of your research data, and\nComplies with internal and external regulations."
  },
  {
    "objectID": "topics/compute-hub.html",
    "href": "topics/compute-hub.html",
    "title": "VU Compute Hub",
    "section": "",
    "text": "The VU Compute Hub is a JupyterHub instance hosted by IT at VU Amsterdam. It allows you to run a number of common analysis tools on a server. The Hub is mainly aimed at providing environments for student courses, but is available for VU researchers as well."
  },
  {
    "objectID": "topics/compute-hub.html#what-is-it",
    "href": "topics/compute-hub.html#what-is-it",
    "title": "VU Compute Hub",
    "section": "",
    "text": "The VU Compute Hub is a JupyterHub instance hosted by IT at VU Amsterdam. It allows you to run a number of common analysis tools on a server. The Hub is mainly aimed at providing environments for student courses, but is available for VU researchers as well."
  },
  {
    "objectID": "topics/compute-hub.html#what-can-it-be-used-for",
    "href": "topics/compute-hub.html#what-can-it-be-used-for",
    "title": "VU Compute Hub",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nThe VU Compute Hub is a great environment to try if your analysis takes too much time on a laptop. It allows you to use the graphical tools you are familiar with in an environment with more compute power where you can leave your script running until it is finished.\nSince every VU researcher can just log in, the barrier to entry is very low.\nBe aware the service is mainly aimed at education. If your scripts use a lot of resources, it might be time for you to start using a High Performance Computing (HPC) environment: ADA at VU Amsterdam or the national supercomputer Snellius. Please contact IT for Research to discuss the best options.\n\nAvailable tools\nThe following applications are currently available: Jupyter Notebooks, MATLAB, STATA, R Studio and QGIS."
  },
  {
    "objectID": "topics/compute-hub.html#how-to-request-access",
    "href": "topics/compute-hub.html#how-to-request-access",
    "title": "VU Compute Hub",
    "section": "How to request access",
    "text": "How to request access\nYou do not need to request access. You can log in with your VU credentials."
  },
  {
    "objectID": "topics/compute-hub.html#are-there-costs-involved",
    "href": "topics/compute-hub.html#are-there-costs-involved",
    "title": "VU Compute Hub",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThere are no costs involved."
  },
  {
    "objectID": "topics/compute-hub.html#getting-started",
    "href": "topics/compute-hub.html#getting-started",
    "title": "VU Compute Hub",
    "section": "Getting started",
    "text": "Getting started\nYou can access the Linux Compute Services through VU JupyterHub in your web browser. The VU JupyterHub gives you access to familiar interfaces like Jupyter Notebooks, MATLAB and R Studio.\nIf you prefer using SSH, you can connect in the following way:\n\n$ ssh &lt;VUnetID&gt;@x.compute.vu.nl\n\n# from home or outside campus:\n$ ssh -J &lt;VUnetID&gt;@ssh.data.vu.nl &lt;VUnetID&gt;@x.compute.vu.nl\nReplace x with either 1, 2, or 3, depending on your choice."
  },
  {
    "objectID": "topics/compute-hub.html#contact",
    "href": "topics/compute-hub.html#contact",
    "title": "VU Compute Hub",
    "section": "Contact",
    "text": "Contact\nWondering if the VU Compute Hub fits your research needs? Please contact IT for Research.\nIf you run into any issues while using the Compute Servers please send a mail to the IT Service Desk mentioning “JupyterHub”."
  },
  {
    "objectID": "topics/selecting-data.html",
    "href": "topics/selecting-data.html",
    "title": "Storing vs. Archiving Data",
    "section": "",
    "text": "There is a difference between storing and archiving data. Storing refers to putting the data in a safe location while the research is ongoing. Because you are still working on the data, the data still change from time to time: they are cleaned, and analysed, and this analysis generates output. As the image below illustrates, storing could be like cooking a dish: you are cleaning and combining ingredients.\nArchiving, on the other hand, refers to putting the data in a safe place after the research is finished. The data are in a fixed state, they don’t change anymore. Archiving is done for verification purposes: so others can check that your research is sound. Or: it is done so that others can reuse the resulting dataset. There is also a difference between archiving and publishing, but in essence, archiving and publishing happen at a similar moment and for both, data do not change anymore.\nThis illustration is created by Scriberia with The Turing Way community. Used under a CC-BY 4.0 licence. DOI: 10.5281/zenodo.3332807"
  },
  {
    "objectID": "topics/selecting-data.html#selecting-data-for-archiving",
    "href": "topics/selecting-data.html#selecting-data-for-archiving",
    "title": "Storing vs. Archiving Data",
    "section": "Selecting Data for Archiving",
    "text": "Selecting Data for Archiving\nThere are various reasons to archive your data: replication, longitudinal research, data being unique or expensive to collect, re-usability and acceleration of research inside or outside your own discipline. It is VU policy to archive your data for (at least) 10 years after the last publication based on the dataset. Part of preparing your dataset for archiving is appraising and selecting your data.\n\nMake a selection before archiving your data\nDuring your research you may accumulate a lot of data, some of which will be eligible for archiving. It is impossible to preserve all data infinitely. Archiving all digital data leads to high costs for storage itself and for maintaining and managing this ever-growing volume of data and their metadata; it may also lead to decline in discoverability (see the website of the Digital Curation Centre). For those reasons, it is crucial that you make a selection.\n\n\nRemove redundant and sensitive data\nSelecting data means making choices about what to keep for the long term, and what data to archive securely and what data to publish openly. This means that you have to decide whether your dataset contains data that need to be removed or separated. Reasons to exclude data from publishing include (but are not limited to):\n\ndata are redundant\ndata concern temporary byproducts which are irrelevant for future use\ndata contain material that is sensitive, for example personal data in the sense of the GDPR, like consent forms, voice recordings, DNA data; state secrets; data that are sensitive to competition in a commercial sense. These data need to be separated from other data and archived securely\npreserving data for the long term is in breach of contractual arrangements with your consortium partners or other parties involved\n\nIn preparing your dataset for archiving, the first step is to determine which parts of your data are sensitive, which can then be separated from the other data. Redundant data can be removed altogether.\n\n\nDifferent forms of datasets for different purposes\nOnce you have separated the sensitive data from the rest of your dataset, you have to think about what to do with these sensitive materials. In some cases they may be destroyed, but you may also opt for archiving multiple datasets. For example, you may want to archive your dataset in more than one form depending on the purpose. For example:\n\nOne for reusability to share\nA second one that contains the sensitive data, and needs to be handled differently.\n\nFor the first, the non-sensitive data can be stored in an archive under restricted or open access conditions, so that you can share it and link it to publications. For the second, you need to make a separate selection, so the sensitive part can be stored safely in a secure archive (a so-called offline or dark archive). In the metadata of both archives you can create stable links between the two datasets using persistent identifiers.\n\n\nWhat to appraise for archiving\nThere are several factors that determine what data to select for archiving. For example, whether data are unique, expensive to reproduce, or if your funder requires that you make your data publicly available. This might also help you or your department to think about a standard policy or procedures for what needs to be kept, what is vital for reproducing research or reuse in future research projects.\nMore information on selecting data:\n\nTjalsma, H. & Rombouts, J. (2011). Selection of research data: Guidelines for appraising and selecting research data. Data Archiving and Networked Services (DANS).\nDigital Curation Centre (DCC): Whyte, A. & Wilson, A. (2010). How to appraise and select research data for curation. DCC How-to Guides. Edinburgh: Digital Curation Centre.\nResearch Data Netherlands: Data selection."
  },
  {
    "objectID": "topics/selecting-data.html#data-set-packaging-which-files-should-be-part-of-my-dataset",
    "href": "topics/selecting-data.html#data-set-packaging-which-files-should-be-part-of-my-dataset",
    "title": "Storing vs. Archiving Data",
    "section": "Data Set Packaging: Which Files should be Part of my Dataset?",
    "text": "Data Set Packaging: Which Files should be Part of my Dataset?\nA dataset consists of the following documents:\n\nRaw or cleaned data (if the cleaned data has been archived, the provenance documentation is also required)\nProject documentation\nCodebook or protocol\nLogbook or lab journal (when available, dependent on the discipline)\nSoftware (& version) needed to open the files when no preferred formats for the data can be provided\n\nSee the topic Metadata for more information about documenting your data.\nDepending on the research project it may be that more than one dataset is stored in more than one repository. Make sure that each consortium partner that collects data also stores all necessary data that is required for transparency and verification. A Consortium Agreement and Data Management Plan will include information on who is responsible for archiving the data."
  },
  {
    "objectID": "topics/data-documentation.html",
    "href": "topics/data-documentation.html",
    "title": "Data Documentation",
    "section": "",
    "text": "By creating documentation about your research data you can make it easier for yourself or for others to manage, find, assess and use your data. The process of documenting means to describe your data and the methods by which they were collected, processed and analysed. The documentation or descriptions are also referred to as metadata, i.e. data about data. These metadata can take various forms and can describe data on different levels.\nAn example that is frequently used to illustrate the importance of metadata is the use of the label on a can of soup. The label tells you what kind of soup the can contains, what ingredients are used, who made it, when it expires and how you should prepare the soup for consumption.\nWhen you are documenting data, you should take into account that there are different kinds of metadata and that these metadata are governed by various standards. These include, but are not limited to:\nThe CESSDA has made very detailed guidance available for creating documentation and metadata for your data."
  },
  {
    "objectID": "topics/data-documentation.html#fair-data-principles",
    "href": "topics/data-documentation.html#fair-data-principles",
    "title": "Data Documentation",
    "section": "FAIR data principles",
    "text": "FAIR data principles\nThe FAIR data principles provide guidelines to improve the Findability, Accessibility, Interoperability, and Reuse of digital assets. The principles emphasise machine-actionability, i.e., the capacity of computational systems to find, access, interoperate, and reuse data with none or minimal human intervention.\nMore information can be found in the section about the FAIR data principles."
  },
  {
    "objectID": "topics/data-documentation.html#unstructured-metadata",
    "href": "topics/data-documentation.html#unstructured-metadata",
    "title": "Data Documentation",
    "section": "Unstructured metadata",
    "text": "Unstructured metadata\nMost data documentation is an example of unstructured metadata. Unstructured metadata are mainly intended to provide more detailed information about the data and is primarily readable for humans. The type of research and the nature of the data influence what kind of unstructured metadata is necessary. Unstructured metadata are attached to the data in a file. The format of the file is chosen by the researcher. More explanation about structured metadata can be found on the metadata page.\n\nREADME\nA README file provides information about data and is intended to ensure that data can be correctly interpreted, by yourself or by others. A README file is required whenever you are archiving or publishing data.\nExample of READMEs\n\nGuidelines for creating a README file – 4TU.ResearchData\nGuide to writing “readme”-style metatada - Cornell Data Services\nGuidelines for researchers of VU Amsterdam Faculty of Behavioural and Movement Sciences on what a README file should contain\n\n\n\nCodebook\nA Codebook is another way to describe the contents, structure and layout of the data. A well documented codebook is intended to be complete and self-explanatory and contains information about each variable in a data file. A codebook must be submitted along with the data.\nThere are several guides for creating a codebook available:\n\nCreating a codebook - Kent State University\nCreating a codebook - for researchers at VU Amsterdam Faculty for Behavioural and Movement Sciences\nCodebook - Amsterdam Public Health\nDDI-Codebook - Data Documentation Initiative Alliance"
  },
  {
    "objectID": "topics/data-management-plan.html",
    "href": "topics/data-management-plan.html",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "A Data Management Plan (DMP) is a document outlining how research data will be handled throughout the research life cycle. A DMP is a structured way to address data collection, organization, storage, sharing, and preservation. It also outlines the measures taken to ensure data security and addresses how data will be preserved and made available for future use."
  },
  {
    "objectID": "topics/data-management-plan.html#what-is-a-dmp",
    "href": "topics/data-management-plan.html#what-is-a-dmp",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "A Data Management Plan (DMP) is a document outlining how research data will be handled throughout the research life cycle. A DMP is a structured way to address data collection, organization, storage, sharing, and preservation. It also outlines the measures taken to ensure data security and addresses how data will be preserved and made available for future use."
  },
  {
    "objectID": "topics/data-management-plan.html#dmponline",
    "href": "topics/data-management-plan.html#dmponline",
    "title": "Data Management Plan (DMP)",
    "section": "DMPonline",
    "text": "DMPonline\nVU Amsterdam offers the online tool DMPonline for writing Data Management Plans. DMPonline is a platform that offers a range of templates, ensuring that researchers can create DMPs to meet the standards of diverse funders and institutions associated with their projects. DMPonline makes it easy to work on a DMP together with colleagues, advisors, or other stakeholders. VU Amsterdam researchers can use the request feedback function of DMPonline to get their DMP reviewed by a faculty data steward or RDM Support Desk colleague.\nInstructions for selecting the right DMP template in DMPonline are available in the guide How can you set up research data management from the start?.\nIf you have questions about DMPonline, or encounter problems when using the tool, please get in touch with rdm@vu.nl."
  },
  {
    "objectID": "topics/data-management-plan.html#what-is-data",
    "href": "topics/data-management-plan.html#what-is-data",
    "title": "Data Management Plan (DMP)",
    "section": "What is data",
    "text": "What is data\nResearch data is any information that has been collected, observed, generated or created to validate original research findings. Examples of data could be interview recordings, experiment results, physical measurement, notes from focus group’s meetings, notes from fieldwork, observations captured in photographs, film or audio, text files extracted from a corpus, image of archival items or artworks, scraped websites, responses to survey questions. Algorithms, simulations, code, scripts and software are often also considered as research data. There is also physical data: (biological) samples, collections, artifacts etc.\nAdministrative documents, like informed consent forms and key files should be acknowledged as important elements of research data as well."
  },
  {
    "objectID": "topics/data-management-plan.html#data-assets",
    "href": "topics/data-management-plan.html#data-assets",
    "title": "Data Management Plan (DMP)",
    "section": "Data Assets",
    "text": "Data Assets\nAt VU Amsterdam, we sometimes use the term ‘Data Assets’. You can think of data assets as small ‘parcels’ of data that can change form or format throughout the research. For example, if you’re sending out surveys for your research, the survey responses are considered a data asset. If, in addition to the surveys, you’re also holding focus groups, the data collected from the focus group are also considered a data asset, separate from the survey results. Most projects will have more than one data asset per data stage. It is common to provide data assets based on the data stage such as raw, processed, or analysed. Raw Data refers to original data collected, Processed Data is data that has undergone some level of transformation or organisation. Processing involves cleaning, formatting, and structuring raw data to make them more understandable and suitable for analysis. Analysed Data usually results from statistical methods, detailed examination or interpretation.\nHere are some examples of data assets in research data management:\n\n\n\n\n\n\n\n\n\nData Stage\nDataset description\nType of data\nFormat\n\n\n\n\nRaw data\nInterviews\nAudio files\nMP3\n\n\n\nSpectographic analysis\nText files\nCSV\n\n\nProcessed data\nTranscription of interviews\nText files\nDocx\n\n\n\nData spreadsheet\nSPSS files\nSAV\n\n\nAnalysed data\nRegression graphic\nGraph\nPNG\n\n\n\nData table\nWord file\nDocx\n\n\nOther\nPoster presentation\nPowerpoint\nPPS\n\n\n\nProject Website\nHTML\n\n\n\n\nAnalysis code\nText files\nPython\n\n\n\nNote that these data assets also change in the different phases of the research! While the interview data are audio files in the raw stage, they are transcribed and become text files in the processed stage."
  },
  {
    "objectID": "topics/data-management-plan.html#dmp-elements",
    "href": "topics/data-management-plan.html#dmp-elements",
    "title": "Data Management Plan (DMP)",
    "section": "DMP Elements",
    "text": "DMP Elements\nVU Amsterdam DMP template consists of seven sections with questions. In DMPonline, there is guidance available for all sections, as well as example answers. When you are writing your DMP, you can consult this information directly in DMPonline. Below we provide references to information and support available for various RDM-related aspects.\n\nLegal and ethical requirements\n\nWorking with personal data\nIf you have questions about working with personal data in research, please get in touch with the Privacy Champion of your faculty. The 🔒 overview of Privacy Champions can be found on VU Amsterdam website. Make sure to contact your Privacy Champion in the following situations:\n\nIf you need to carry out a DPIA, or if you’re unsure if you need to do one\nIf you work with special category personal data, or otherwise very sensitive data\nIf you are collaborating with other parties\nIf you need software for which no licence is set up on behalf of VU Amsterdam\nIf you wish to reuse existing data containing personal data\n\nIt is impossible to provide an overview of tasks to be carried out to ensure compliance with the GDPR that fits all research projects. For that reason, it is important to contact your Privacy Champion. They will be able to identify what needs to be arranged to adhere to the GDPR.\n\n\nEthical Review\nIn cases where research involves human or animal participants, a research proposal may need to be reviewed by an ethics committee. VU Amsterdam and Amsterdam UMC (location VUmc), have several ethics committees, which are listed below. Please note that researchers at VU Amsterdam also have to go to the METc at VUmc if their research is subject to the WMO, which is not restricted to research at VUmc.\n\nEthics committees\n\nACTA: ACTA Ethics Review Board (ETC), Academisch Centrum Tandheelkunde Amsterdam\nBeta: Research ethics review committee Faculty of Science (BETHCIE), Faculty of Science\nFGB: 🔒 Scientific and Ethical Review Board (VCWE), Faculty of Behavioural and Movement Sciences\nFSG, Faculty of Social Sciences and Humanities:\n\nSGW: Ethische Toetsingscommissie Onderzoek (EtCO), School of Humanities\nSSW: 🔒 Research Ethics Review Committee (RERC), School of Social Sciences\n\nRCH: Ethics Committee, Faculty of Law\nSBE: Ethical Review Board (ERB), School of Business and Economics\nVUmc (Amsterdam UMC): Medical Ethical Review Committee (METc)\n\n\n\n\n\nStorage and backup during the research process\nAn overview of storage facilities at VU Amsterdam is available in the Data Storage Finder. You can use this as a starting point to navigate storage solutions.\nIf you have questions about data storage and backup, send an email to rdm@vu.nl.\n\n\nData archiving and publishing\nIf your research data contains personal data and you’re unsure about which data may be published, please contact your 🔒 Privacy Champion."
  },
  {
    "objectID": "topics/yoda.html",
    "href": "topics/yoda.html",
    "title": "Yoda",
    "section": "",
    "text": "Yoda is an application for institutions that supports Research Data Management (RDM) throughout the entire research cycle: from the safe and easy storage and sharing of data during the research process, to the sharing of data within research collaborations and ultimately to research data archiving and publication.\n\nYoda helps the researcher make their data “FAIR” by providing a solution that enables data discovery and sharing (i.e., findable, accessible). In addition, it facilitates the use of metadata, contributing to data interoperability and reusability. Yoda provides a platform for the implementation of standard workflows that can ensure metadata quality satisfying VU policy requirements for data archiving and publication. In addition, Yoda is built on iRODS so it accommodates both researchers with data heavy requirements, as well as those seeking an accessible, user-friendly solution.\nYoda presents researchers a comfortable, easy-to-use solution for securely storing, sharing and organising their research data that follows the internationally adopted FAIR data principles. Many research institutions and funding organisations (such as NWO and ZonMw) require researchers to make their data FAIR.\nProject space in Yoda is basically a folder with group based access rights. Access restrictions are only set on the top level, meaning you need one Project Space per research project.\nYoda is open source software developed and maintained by Utrecht University for the Yoda Consortium (VU, Wageningen University, Erasmus University, Amsterdam UMC, Utrecht University and SURF). Yoda is hosted by SURF in their Amsterdam datacentre."
  },
  {
    "objectID": "topics/yoda.html#what-is-it",
    "href": "topics/yoda.html#what-is-it",
    "title": "Yoda",
    "section": "",
    "text": "Yoda is an application for institutions that supports Research Data Management (RDM) throughout the entire research cycle: from the safe and easy storage and sharing of data during the research process, to the sharing of data within research collaborations and ultimately to research data archiving and publication.\n\nYoda helps the researcher make their data “FAIR” by providing a solution that enables data discovery and sharing (i.e., findable, accessible). In addition, it facilitates the use of metadata, contributing to data interoperability and reusability. Yoda provides a platform for the implementation of standard workflows that can ensure metadata quality satisfying VU policy requirements for data archiving and publication. In addition, Yoda is built on iRODS so it accommodates both researchers with data heavy requirements, as well as those seeking an accessible, user-friendly solution.\nYoda presents researchers a comfortable, easy-to-use solution for securely storing, sharing and organising their research data that follows the internationally adopted FAIR data principles. Many research institutions and funding organisations (such as NWO and ZonMw) require researchers to make their data FAIR.\nProject space in Yoda is basically a folder with group based access rights. Access restrictions are only set on the top level, meaning you need one Project Space per research project.\nYoda is open source software developed and maintained by Utrecht University for the Yoda Consortium (VU, Wageningen University, Erasmus University, Amsterdam UMC, Utrecht University and SURF). Yoda is hosted by SURF in their Amsterdam datacentre."
  },
  {
    "objectID": "topics/yoda.html#what-can-it-be-used-for",
    "href": "topics/yoda.html#what-can-it-be-used-for",
    "title": "Yoda",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nThe particular strength of Yoda lies in the fact that it is an all-in-one solution for managing your data during and after your project. It makes it easy to share and organise your data and add descriptive metadata at any moment. If (part of) your datasets needs to be published during or after your project, this can be done by a few simple steps within Yoda itself. There is no need to upload your data to another platform.\n\nData storage\nYoda is a Cloud storage solution that can be used for small to very large datasets. The underlying iRODS software ensures data integrity. Data in Yoda is backed up daily.\n\n\nData sharing\nOnce a new Yoda group has been created you can invite collaborators yourself. Researchers from national and international research institutes can login with their institutional account via SURF Research Access Management (SRAM). Collaborators from non-research institutes can create a free EduID NL account.\n\n\nSensitive data\nThe use of Multi-Factor Authentication (MFA) with SRAM and hosting at SURF ensure, among other things, Yoda is suitable for the storage and sharing of data that score High on confidentiality in a data classification (see the Policy Classification of Research Data and the Research Data Classification Tool). Please make sure to contact the RDM Support Desk to check if further measures are needed.\n\n\nMetadata\nAt any moment you can add descriptive metadata to a folder in Yoda via a web form. This means you can easily organize your data in such a way that it is not only ready for archiving and publishing but also findable for your collaborators.\n\n\nArchiving\nAt any moment you can submit a data folder with metadata for Archiving in the Yoda Vault. Data in the Vault is read-only and cannot be deleted. To help make sure the dataset is suitable for archiving a Yoda datamanager (usually a data manager from your department or a faculty data steward) will review your submission before final approval. Data in the Vault is directly accessible for your collaborators. Access for the Yoda datamanager role ensures the data remains accessible on the long term.\n\n\nPublishing metadata and data\nFrom the Yoda Vault you can submit the dataset for publication. A DOI will be generated and registered with DataCite together with the metadata. DataCite ensures your dataset becomes findable on the internet and citable.\nThe DOI link will lead to a landing page in Yoda showing the metadata. The dataset itself can be Open, allowing direct download, Restricted, meaning other researchers need to follow a data request procedure, or Closed, signalling the dataset is properly archived but not available for reuse.\n\n\nAutomated workflows\nSince Yoda is build on iRODS you could also build (automated) ingest and analysis workflows using iRODS Rules and Policies. Please contact IT for Research if you need assistance."
  },
  {
    "objectID": "topics/yoda.html#how-to-request-access",
    "href": "topics/yoda.html#how-to-request-access",
    "title": "Yoda",
    "section": "How to request access",
    "text": "How to request access\nRequesting space is done via a 🔒 request form on ServiceNow.Please note that because there can be costs involved (see below) you need to supply a budget code.\nOnce the project space has been created you can start to invite your collaborators yourself. Note that VU students must 🔒 connect a token to SURFsecureID to be able to log in.\n\nIntake procedure\nWhen you work with sensitive data we will always schedule a meeting with you to help you to safely work with your data.\nIn the form you can also indicate if you would like some help getting started with Yoda. We can either schedule a short 15 minute meeting to get you started or a longer meeting to have a closer look at your data and help you setting up a workflow."
  },
  {
    "objectID": "topics/yoda.html#are-there-costs-involved",
    "href": "topics/yoda.html#are-there-costs-involved",
    "title": "Yoda",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThe costs of storing data in Yoda are detailed on the 🔒 VU website."
  },
  {
    "objectID": "topics/yoda.html#getting-started",
    "href": "topics/yoda.html#getting-started",
    "title": "Yoda",
    "section": "Getting Started",
    "text": "Getting Started\nThe RDM Handbook has practical manuals for users starting with Yoda.\nMore information can be found on the SURF User Knowledge base.\nThe Yoda site of Utrecht University also contains useful information and is being redeveloped so it can also be used by VU Amsterdam and the other Consortium Partners."
  },
  {
    "objectID": "topics/yoda.html#contact",
    "href": "topics/yoda.html#contact",
    "title": "Yoda",
    "section": "Contact",
    "text": "Contact\nWondering if Yoda fits your research needs? Please contact the RDM support desk."
  },
  {
    "objectID": "topics/fair-principles.html",
    "href": "topics/fair-principles.html",
    "title": "FAIR Principles",
    "section": "",
    "text": "This page discusses what the FAIR principles (Wilkinson et al. 2016) are, why they are important and how you can work in line with these principles at VU."
  },
  {
    "objectID": "topics/fair-principles.html#what-are-the-fair-principles",
    "href": "topics/fair-principles.html#what-are-the-fair-principles",
    "title": "FAIR Principles",
    "section": "What are the FAIR principles?",
    "text": "What are the FAIR principles?\nThe FAIR principles were formulated in 2016 to guide researchers in increasing the Findability, Accessibility, Interoperability and Reusability of their data (see the publication in the journal Scientific Data and the summary of the principles). The goal is to ensure that scholarly data can be used as widely as possible – accelerating scientific discoveries and benefiting society in the process.\nA lot of good resources exist already that explain the FAIR principles very well:\n\nGO FAIR provides a clear overview of the FAIR principles\nThe Turing Way has a great information page about FAIR, containing a lot of references to other useful sources\nThe story A FAIRy tale explains all principles in an understable way\n\nThe FAIR principles were rapidly adopted by Dutch and European funding agencies. If you receive a research grant from NWO, ZonMw, or the European Commission, you will be asked to make your data FAIR."
  },
  {
    "objectID": "topics/fair-principles.html#how-can-you-benefit-from-working-in-line-with-the-fair-principles",
    "href": "topics/fair-principles.html#how-can-you-benefit-from-working-in-line-with-the-fair-principles",
    "title": "FAIR Principles",
    "section": "How can you benefit from working in line with the FAIR principles?",
    "text": "How can you benefit from working in line with the FAIR principles?\nYou do not need to apply all FAIR principles at once to start benefiting from making your data FAIR. Applying even just some of the principles will increase the visibility and impact of your data, leading to:\n\nIncreased citations of the datasets themselves and your research\nImproved reproducibility of your research\nCompliance with funder and publisher requirements\n\nMaking your data FAIR will also make it possible for you to easily find, access and reuse your own data in the future. You may be the first and most important beneficiary of making your own data FAIR."
  },
  {
    "objectID": "topics/fair-principles.html#making-data-fair-how-to-get-started-in-three-easy-steps",
    "href": "topics/fair-principles.html#making-data-fair-how-to-get-started-in-three-easy-steps",
    "title": "FAIR Principles",
    "section": "Making data FAIR – how to get started in three easy steps?",
    "text": "Making data FAIR – how to get started in three easy steps?\n\nStart with a data management plan\nA DMP is a living document in which you specify what kinds of data you will use in your project, and how you will process, store and archive them. Preparing a data management plan should be your first step in the process to make data FAIR. The DMP template will ask questions that enable you to systematically address the things that need to be done to make your data FAIR. Writing a DMP is also a requirement from funding agencies and some faculties at VU Amsterdam. At VU Amsterdam, you can use DMPonline to create and share DMPs.\n\n\nDescribe and document your data\nTo be findable, data need to be described with appropriate metadata. Metadata can include keywords, references to related papers, the researchers’ ORCID identifiers, and the codes for the grants that supported the research. You will need to provide such metadata when you are uploading data to a repository (see below). You increase findability by filling out as many metadata fields as possible and by providing rich descriptions in terminology that is common in your field.\nTo be reusable, data need to be accompanied by documentation describing how the data was created, structured, processed, and so on. It is good practice to integrate writing documentation during the research process. It will be easier and take less time compared to when you try to do this at the end. Having documentation on the research process will also help you to redo parts of your data cleaning actions or data analysis if necessary.\nIf you have questions about metadata and documentation, contact the RDM Support Desk and we will be happy to help you and to provide advice.\n\n\nMake your data available through a trustworthy repository\nIf you choose a repository that: assigns a persistent identifier to both the data and the metadata; attaches metadata to the data according to standard metadata schemas; releases data with a license; and provides access to the data and metadata via an open and standard communication protocol (such as http) – then your data will meet many, if not most, of the FAIR principles.\nVU Amsterdam provides three repositories which meets all of these conditions:\n\nDataverseNL\nYoda\nOpen Science Framework (OSF)\n\nCosts for using these repositories for datasets up to 500 GB are covered by the faculty. There are costs involved for you department or project if a datasets is larger than 500 GB. See the storage cost model for details."
  },
  {
    "objectID": "topics/fair-principles.html#what-if-i-cannot-share-my-data",
    "href": "topics/fair-principles.html#what-if-i-cannot-share-my-data",
    "title": "FAIR Principles",
    "section": "What if I cannot share my data?",
    "text": "What if I cannot share my data?\nData do not need to be open to be FAIR. The FAIR principles allow for controlled access, which can be important for certain types of data, such as personal data, medical data, competitive company data. The guiding principle is always that data should be as “as open as possible, as closed as necessary”. If data cannot be openly shared, because they are too sensitive, then “the FAIR approach would be to make the metadata publicly available and provide information about the conditions for accessing the data itself.”"
  },
  {
    "objectID": "topics/rdsm-terminology.html",
    "href": "topics/rdsm-terminology.html",
    "title": "Research Data and Software Management Terminology",
    "section": "",
    "text": "The VU maintains a list of terms (a.k.a. definitions) for words that are used regularly in Research Data and Software Management contexts. This terminology is important for insuring that everyone understands each other when discussing RDSM topics.\nThis terminology list will grow and update over time. If you have a suggestion for a new term, click on the “Edit this page” button on the top right of the screen, or suggest your new term via the Contribution Portal (see the “Contributing” tab in the top menu).\nAnother useful terminology list that incorporates many general RDSM and Open Science terms is the Glossary of The Turing Way. You can also consult this glossary if you come across a term that you don’t know that is not found in the list below.\n\n\nShort description, usually included in a publication, of where data or software associated with a publication are available and under which conditions these materials can be accessed. Also known as (Data) Access Statement.\n\n\n\nPrinciples for treating data about indigenous people in a responsible manner, addressing collective benefit (C), Authority to control (A), Responsibility (R) and Ethics (E).\n\n\n\n\n\nSafe and reliable storage of research data during the active research phase. Stored research data can be changed.\n\n\n\nCreation of a secure and immutable copy of research data, associated metadata, accompanying documentation, and software code (where relevant) with the intention to ensure (conditional) access for a predetermined, minimum, period of time.\n\n\n\nMaking research data, associated metadata, accompanying documentation, and software code (where relevant) accessible in a repository in such a manner that they can be discovered on the Web and referred to in a unique and persistent way.\n\n\n\n\nPrinciples for making research data Findable (F), Accessible (A), Interoperable (I) and Reusable (R).\n\n\n\nData that describe characteristics of other data. In the research context this concerns data that provide further information and context about research data. Metadata describe the data and the context in which they have been collected or created. See also Research data.\n\n\n\nIn short, and in the current context, a Persistent Identifier (PID) is essentially a URL that will never break. There are multiple PID systems, each with its own particular properties. Examples of widely used PIDs in the research domain include:\n\n\nA Digital Object Identifier can be used to refer to research data and research software. DOIs can be assigned to datasets and software upon their deposit in a repository.\n\n\n\nAn Open Researcher and Contributor ID is used to create a researcher profile with a unique identification number. Researchers can request an ORCiD themselves, with which they can identify their research output as their work.\n\n\n\nThe Research Organization Registry is a global register with persistent identifiers for research institutes. Researchers can use the ROR for VU Amsterdam when filling metadata forms for their research output to show that their work has been created within their employment at VU Amsterdam.\nSee the Persistent Identifier guide of Netwerk Digitaal Erfgoed for a more elaborate overview. Apart from widely used domain-agnostic PIDs, there is a wide range of domain-specific unique identifiers that can be used.\n\n\n\n\nInformation that is captured for the purpose of underpinning academic research. Depending on the discipline it may consist of, for example, text, images, sound, spreadsheets, databases, statistical data, geographic data, etc. When we refer to research data in this policy, we refer to the entirety of the data itself, this includes any associated metadata and documentation.\n\n\n\n“Research data management is an explicit process covering the creation and stewardship of research materials to enable their use for as long as they retain value.” 1\n\n\n\nThe research life cycle outlines the various stages and activities of a research project, from preparation to disseminating the results.\n\n\n\n“Research Software includes source code files, algorithms, scripts, computational workflows and executables that were created during the research process or for a research purpose. Software components (e.g., operating systems, libraries, dependencies, packages, scripts, etc.) that are used for research but were not created during or with a clear research intent should be considered software in research and not Research Software.” 2\n\n\n\nResearch software management (RSM) is a structured and strategic approach to handling the creation, utilisation, and preservation of software in the research process.\n\n\n\n“A trusted digital repository is one whose mission is to provide reliable, long-term access to managed digital resources to its designated community, now and in the future.” 3"
  },
  {
    "objectID": "topics/rdsm-terminology.html#what-is-rdsm-terminology",
    "href": "topics/rdsm-terminology.html#what-is-rdsm-terminology",
    "title": "Research Data and Software Management Terminology",
    "section": "",
    "text": "The VU maintains a list of terms (a.k.a. definitions) for words that are used regularly in Research Data and Software Management contexts. This terminology is important for insuring that everyone understands each other when discussing RDSM topics.\nThis terminology list will grow and update over time. If you have a suggestion for a new term, click on the “Edit this page” button on the top right of the screen, or suggest your new term via the Contribution Portal (see the “Contributing” tab in the top menu).\nAnother useful terminology list that incorporates many general RDSM and Open Science terms is the Glossary of The Turing Way. You can also consult this glossary if you come across a term that you don’t know that is not found in the list below.\n\n\nShort description, usually included in a publication, of where data or software associated with a publication are available and under which conditions these materials can be accessed. Also known as (Data) Access Statement.\n\n\n\nPrinciples for treating data about indigenous people in a responsible manner, addressing collective benefit (C), Authority to control (A), Responsibility (R) and Ethics (E).\n\n\n\n\n\nSafe and reliable storage of research data during the active research phase. Stored research data can be changed.\n\n\n\nCreation of a secure and immutable copy of research data, associated metadata, accompanying documentation, and software code (where relevant) with the intention to ensure (conditional) access for a predetermined, minimum, period of time.\n\n\n\nMaking research data, associated metadata, accompanying documentation, and software code (where relevant) accessible in a repository in such a manner that they can be discovered on the Web and referred to in a unique and persistent way.\n\n\n\n\nPrinciples for making research data Findable (F), Accessible (A), Interoperable (I) and Reusable (R).\n\n\n\nData that describe characteristics of other data. In the research context this concerns data that provide further information and context about research data. Metadata describe the data and the context in which they have been collected or created. See also Research data.\n\n\n\nIn short, and in the current context, a Persistent Identifier (PID) is essentially a URL that will never break. There are multiple PID systems, each with its own particular properties. Examples of widely used PIDs in the research domain include:\n\n\nA Digital Object Identifier can be used to refer to research data and research software. DOIs can be assigned to datasets and software upon their deposit in a repository.\n\n\n\nAn Open Researcher and Contributor ID is used to create a researcher profile with a unique identification number. Researchers can request an ORCiD themselves, with which they can identify their research output as their work.\n\n\n\nThe Research Organization Registry is a global register with persistent identifiers for research institutes. Researchers can use the ROR for VU Amsterdam when filling metadata forms for their research output to show that their work has been created within their employment at VU Amsterdam.\nSee the Persistent Identifier guide of Netwerk Digitaal Erfgoed for a more elaborate overview. Apart from widely used domain-agnostic PIDs, there is a wide range of domain-specific unique identifiers that can be used.\n\n\n\n\nInformation that is captured for the purpose of underpinning academic research. Depending on the discipline it may consist of, for example, text, images, sound, spreadsheets, databases, statistical data, geographic data, etc. When we refer to research data in this policy, we refer to the entirety of the data itself, this includes any associated metadata and documentation.\n\n\n\n“Research data management is an explicit process covering the creation and stewardship of research materials to enable their use for as long as they retain value.” 1\n\n\n\nThe research life cycle outlines the various stages and activities of a research project, from preparation to disseminating the results.\n\n\n\n“Research Software includes source code files, algorithms, scripts, computational workflows and executables that were created during the research process or for a research purpose. Software components (e.g., operating systems, libraries, dependencies, packages, scripts, etc.) that are used for research but were not created during or with a clear research intent should be considered software in research and not Research Software.” 2\n\n\n\nResearch software management (RSM) is a structured and strategic approach to handling the creation, utilisation, and preservation of software in the research process.\n\n\n\n“A trusted digital repository is one whose mission is to provide reliable, long-term access to managed digital resources to its designated community, now and in the future.” 3"
  },
  {
    "objectID": "topics/rdsm-terminology.html#footnotes",
    "href": "topics/rdsm-terminology.html#footnotes",
    "title": "Research Data and Software Management Terminology",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFrom the Digital Curation Center’s Glossary↩︎\nFrom the report Defining Research Software: a controversial discussion↩︎\nFrom the report Trusted Digital Repositories: Attributes and Responsibilities, p.5↩︎"
  },
  {
    "objectID": "topics/ethical-review.html",
    "href": "topics/ethical-review.html",
    "title": "Ethical Review",
    "section": "",
    "text": "In cases where research involves human or animal participants, a research proposal may need to be reviewed by an ethics committee. VU Amsterdam and Amsterdam UMC (location VUmc), have several ethics committees, which are listed below. Please note that researchers at VU Amsterdam also have to go to the METc at VUmc if their research is subject to the WMO, which is not restricted to research at VUmc."
  },
  {
    "objectID": "topics/ethical-review.html#ethics-committees",
    "href": "topics/ethical-review.html#ethics-committees",
    "title": "Ethical Review",
    "section": "Ethics committees",
    "text": "Ethics committees\n\nACTA: ACTA Ethics Review Board (ETC), Academisch Centrum Tandheelkunde Amsterdam\nBeta: Research ethics review committee Faculty of Science (BETHCIE), Faculty of Science\nFGB: 🔒 Scientific and Ethical Review Board (VCWE), Faculty of Behavioural and Movement Sciences\nFSG, Faculty of Social Sciences and Humanities:\n\nSGW: Ethische Toetsingscommissie Onderzoek (EtCO), School of Humanities\nSSW: 🔒 Research Ethics Review Committee (RERC), School of Social Sciences\n\nRCH: Ethics Committee, Faculty of Law\nSBE: Ethical Review Board (ERB), School of Business and Economics\nVUmc (Amsterdam UMC): Medical Ethical Review Committee (METc)"
  },
  {
    "objectID": "topics/gdpr.html",
    "href": "topics/gdpr.html",
    "title": "General Data Protection Regulation",
    "section": "",
    "text": "The General Data Protection Regulation (GDPR) is a European legislation that lays down rules relating to the protection of natural persons with regard to the processing of personal data. The Dutch Implementation Act for the GDPR (UAVG) describes the implementation of the GDPR for the Netherlands."
  },
  {
    "objectID": "topics/gdpr.html#introduction",
    "href": "topics/gdpr.html#introduction",
    "title": "General Data Protection Regulation",
    "section": "",
    "text": "The General Data Protection Regulation (GDPR) is a European legislation that lays down rules relating to the protection of natural persons with regard to the processing of personal data. The Dutch Implementation Act for the GDPR (UAVG) describes the implementation of the GDPR for the Netherlands."
  },
  {
    "objectID": "topics/gdpr.html#definitions",
    "href": "topics/gdpr.html#definitions",
    "title": "General Data Protection Regulation",
    "section": "Definitions",
    "text": "Definitions\n\nPersonal data refers to any information relating to an identified or identifiable natural person (‘data subject’). See also the definition of ’personal data’ according to the official text of the GDPR.\nData processing refers to any action performed on data, such as collecting, storing, modifying, distributing, deleting data. See also the definition of ‘processing’ according the official text of the GDPR.\nDirect and indirect identification: Some identifiers enable you to identify an indiviual directly, such as name, day of birth and home address. Individuals can also be identifed indirectly. For example via:\n\na combination of information that uniquely singles out an individual (e.g. a male with breast cancer in a breast cancer registry, a pregnant individual over 50 etc.), this includes information in one record and information across different data files or datasets\nunique information or patterns that are specific to an individual (e.g. genomic data, a very specific occupation, such as the president of a large company, repeated physical measurements or movement patterns that create a unique profile of an individual or measurements that are extreme and could be linked to subjects such as high-level athletes)\ndata that are linked to directly identifying information through a random identification code or number\n\nPseudonymous data: Data that are indirectly identifiable are generally considered to be pseudonymous; this means that they are NOT anonymous and still qualify as personal data. Therefore, the GDPR applies to these data. This is for example the case when direct identifiers are removed from the research data and put into a key file (or what is usually called a subject identification log in medical research) with which the direct identifiers can be mapped to the research data through unique codes, so that reidentification is possible. These data are therefore considered to be pseudonymous data for the research institution and not anonymised data. LCRDM (National Coordination Point Research Data Management) has made a reference card that illustrates the difference between pseudonymous and anonymous data."
  },
  {
    "objectID": "topics/gdpr.html#background-information",
    "href": "topics/gdpr.html#background-information",
    "title": "General Data Protection Regulation",
    "section": "Background information",
    "text": "Background information\n\nPrivacy in research - Privacy five-step plan\nWhere research requires the collection of personal data, the researcher has to follow the Privacy five-step plan to make sure to carry out the research in line with the GDPR.\n\n\nVSNU Code of Conduct for using personal data in research\nThe VSNU’s Code of Conduct for Research Integrity (Dutch, English, 2018) includes a reference to the GDPR and its Dutch implementation law UAVG. An updated Code of Conduct for Using Personal Data in Research which complies with GDPR is still work in progress."
  },
  {
    "objectID": "topics/gdpr.html#support-in-your-faculty-privacy-champions",
    "href": "topics/gdpr.html#support-in-your-faculty-privacy-champions",
    "title": "General Data Protection Regulation",
    "section": "Support in your faculty: Privacy Champions",
    "text": "Support in your faculty: Privacy Champions\nEach faculty has one or more Privacy Champions, who are the first point of contact for questions relating to privacy and the GDPR. The Privacy Champions can help you with completing a Data Protection Impact Assessment, registering your research in the record of processing activities, designing informed consent forms and other questions relating to the GDPR. The 🔒 list of Privacy Champions can be found on the VU website."
  },
  {
    "objectID": "topics/gdpr.html#more-information",
    "href": "topics/gdpr.html#more-information",
    "title": "General Data Protection Regulation",
    "section": "More information",
    "text": "More information\nOn the VU page Working with personal data, you can find more information about how VU Amsterdam protects personal data."
  },
  {
    "objectID": "topics/data-archiving.html",
    "href": "topics/data-archiving.html",
    "title": "Data Archiving",
    "section": "",
    "text": "When we mention data archiving at VU Amsterdam, we mean the following:\n\nCreation of a secure and immutable copy of research data, associated metadata, accompanying documentation, and software code (where relevant) with the intention to ensure (conditional) access for a predetermined, minimum, period of time.\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for archiving all research data and software that leads to a published result (either in an article or other narrative form) in a trusted repository for a period of at least ten years after this publication, unless legal requirements, discipline-specific guidelines or contractual arrangements dictate otherwise."
  },
  {
    "objectID": "topics/data-archiving.html#what-is-data-archiving",
    "href": "topics/data-archiving.html#what-is-data-archiving",
    "title": "Data Archiving",
    "section": "",
    "text": "When we mention data archiving at VU Amsterdam, we mean the following:\n\nCreation of a secure and immutable copy of research data, associated metadata, accompanying documentation, and software code (where relevant) with the intention to ensure (conditional) access for a predetermined, minimum, period of time.\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for archiving all research data and software that leads to a published result (either in an article or other narrative form) in a trusted repository for a period of at least ten years after this publication, unless legal requirements, discipline-specific guidelines or contractual arrangements dictate otherwise."
  },
  {
    "objectID": "topics/data-archiving.html#purpose",
    "href": "topics/data-archiving.html#purpose",
    "title": "Data Archiving",
    "section": "Purpose",
    "text": "Purpose\nData archiving is crucial for enabling verification of research data. Verification is important for a transparent research practice, a value VU Amsterdam is strongly committed to. Archiving your data ensures that data will be preserved for the long term and that data can be accessed if necessery, even when the Principal Investigator or other members of the research team are no longer available at VU Amsterdam."
  },
  {
    "objectID": "topics/data-archiving.html#requirements",
    "href": "topics/data-archiving.html#requirements",
    "title": "Data Archiving",
    "section": "Requirements",
    "text": "Requirements\nAt VU Amsterdam, we strive to make our research data FAIR. When datasets are archived in a repository provided by VU Amsterdam (Yoda or DataverseNL, the following requirements apply:\n\nthe data must be provided with Metadata according to the VU Minimal metadata guide;\nthe data and software must have a Persistent identifier (or Identifiers) to increase findability;\na licence must be applied to the data and software in order to indicate if it can be reused by others and if so, under which conditions.\n\nIf you use an external repository, these requirements are useful to keep in mind as well, because they make the data FAIR to a large extent, but in that case you will have to rely on the properties of the repository."
  },
  {
    "objectID": "topics/data-archiving.html#how-does-data-archiving-work-in-practice",
    "href": "topics/data-archiving.html#how-does-data-archiving-work-in-practice",
    "title": "Data Archiving",
    "section": "How does data archiving work in practice?",
    "text": "How does data archiving work in practice?\nAs mentioned above, data archiving must happen in a repository. This means that data storage solutions for during research, like Research Drive, are not suitable for data archiving. They don’t generate a Persistent Identifier and do not ask for metadata or a licence. Detailed workflows addressing archiving data can be found in the guides about making your data FAIR and archiving and publishing data."
  },
  {
    "objectID": "topics/data-storage.html",
    "href": "topics/data-storage.html",
    "title": "Data Storage",
    "section": "",
    "text": "VU Amsterdam offers several options to store your research data. The choice for a specific option may depend on factors such as:\n\nDoes a project involve multiple organisations or departments?\nThe sensitivity of the data: does it involve personal data or copyrighted / commercial data?\nAre there any research partners with whom data need to be shared?\nAre any commercial parties involved?\nDoes the research project involve multiple locations (inside or maybe even outside the EU)?\nWill there be (lab) devices producing data that need to be stored as well?\nWhat will be the volume of the data?\nWill there be lots of interactions with the data (using software/tools)?\n\nStorage options may take several forms, for example:\n\nLocal storage on computers, networks or servers;\nCloud storage offered by VU Amsterdam;\nLocations where physical data samples are stored (fridges, lockers, etc.).\n\nResearchers, including PhD candidates, have multiple options that can be used, some of which are listed below. More information about these storage options is available behind their respective links. The Storage finder is a tool that will give you a number of storage options suitable for your research. For more individual guidance, please get in touch with the Research Data Management Support Desk for advice, particularly when you are working with commercial, personal or otherwise sensitive data, or when you have a complex IT setup."
  },
  {
    "objectID": "topics/data-storage.html#storage-during-research",
    "href": "topics/data-storage.html#storage-during-research",
    "title": "Data Storage",
    "section": "",
    "text": "VU Amsterdam offers several options to store your research data. The choice for a specific option may depend on factors such as:\n\nDoes a project involve multiple organisations or departments?\nThe sensitivity of the data: does it involve personal data or copyrighted / commercial data?\nAre there any research partners with whom data need to be shared?\nAre any commercial parties involved?\nDoes the research project involve multiple locations (inside or maybe even outside the EU)?\nWill there be (lab) devices producing data that need to be stored as well?\nWhat will be the volume of the data?\nWill there be lots of interactions with the data (using software/tools)?\n\nStorage options may take several forms, for example:\n\nLocal storage on computers, networks or servers;\nCloud storage offered by VU Amsterdam;\nLocations where physical data samples are stored (fridges, lockers, etc.).\n\nResearchers, including PhD candidates, have multiple options that can be used, some of which are listed below. More information about these storage options is available behind their respective links. The Storage finder is a tool that will give you a number of storage options suitable for your research. For more individual guidance, please get in touch with the Research Data Management Support Desk for advice, particularly when you are working with commercial, personal or otherwise sensitive data, or when you have a complex IT setup."
  },
  {
    "objectID": "topics/data-storage.html#standard-services-offered-by-vu-amsterdam",
    "href": "topics/data-storage.html#standard-services-offered-by-vu-amsterdam",
    "title": "Data Storage",
    "section": "Standard services offered by VU Amsterdam",
    "text": "Standard services offered by VU Amsterdam\nVU IT offers several services for employees to store their files. Examples are:\n\n🔒 OneDrive: personal storage for all VU employees and part of the Microsoft 365 platform. OneDrive allows you to store files locally and in the Microsoft cloud, and share folders and documents with colleagues. Since this is personal storage, tied to someone’s personal VU account, we don’t usually recommend storing research data in OneDrive: if the account holder leaves VU Amsterdam, the account and all the data on it, disappear.\n🔒 Teams. Faculties, divisions and departments have their own Team - part of the Microsoft 365 platform - where they store shared documents and where they can interact and chat. Projects may also request a project team. But note that Teams is not always the best location to store your research data and has several limitations, especially when it comes to working with non-Microsoft file formats, large volumes of data, interacting with data, and collaborating with partners outside of VU Amsterdam. Contact the RDM Support Desk to find out more about the suitability of Teams for your project."
  },
  {
    "objectID": "topics/data-storage.html#research-data-specific-storage-options",
    "href": "topics/data-storage.html#research-data-specific-storage-options",
    "title": "Data Storage",
    "section": "Research data-specific storage options",
    "text": "Research data-specific storage options\nThe options above are standard data storage options at VU Amsterdam to which all employees have access. But VU Amsterdam also offers storage specifically for research data. Some of them are hosted locally at VU Amsterdam, while others are SURF cloud services. When selecting a cloud-based service it is important to remember to check where the data will be hosted. If the research project involves sensitive data it may be necessary to choose cloud-based options that guarantee that the data will stay in the EEA or on servers based in the EEA.\n\n🔒 SciStor (short for ‘Storage for Scientists’): This is storage hosted by IT for Research (ITvO) and allows for inexpensive storage of large volumes of data. There are various levels of security possible and various ways to get access to the files. SciStor is only intended for ongoing research, not for archiving.\nYoda (short for Your Data) is a cloud storage at SURF and is suitable for storing large-scale and sensitive datasets. Yoda also supports collaborating on projects in and outside VU Amsterdam and adding contextual information (metadata) about your dataset as you go. Yoda is usually the best choice if your research data are very sensitive.\n🔒 Research Drive is a cloud storage at SURF for research projects and is suitable for collaboration in and outside VU Amsterdam, for storing sensitive data and large-scale research projects. You are able to request storage space in Research Drive via a 🔒 web form in the selfservice portal (VU employees only). Research Drive is the best choice if you need to manage access rights on a folder level. SURF has general information about Research Drive, and you can find tutorials on the wiki pages.\n\nThere are differences between Research Drive and Yoda and each one may support certain projects better than others. The storage finder can help you to get an idea of what would be the best choice for your project, but get in touch with the RDM Support Desk for more details. Costs for each of these storage options are detailed on the VU website, including details on how the costs are calculated and billed."
  },
  {
    "objectID": "topics/data-storage.html#sending-research-data-to-partners",
    "href": "topics/data-storage.html#sending-research-data-to-partners",
    "title": "Data Storage",
    "section": "Sending research data to partners",
    "text": "Sending research data to partners\nSome projects may require data sharing with partners. Although Research Drive and Yoda support sharing data all through the project, it may also be the case that some data only need to be sent to a partner once. There are some secure options to send data to research partners:\n\n🔒 Surf Filesender: cloud service that allows you to send files of 1 Terabyte to other researchers and encrypted files of up to 250 GB.\n🔒 Zivver: All employees of VU Amsterdam can use Zivver, the encryption programme that allows you to send email or data (sensitive or otherwise) securely by email. Attachments will also be encrypted and can be several Terabytes in size (max = 5 TB). Specific information on how to get and use Zivver are available on the selfservice portal. General explanations on how to use it are available at the Zivver website."
  },
  {
    "objectID": "topics/finding-existing-data.html",
    "href": "topics/finding-existing-data.html",
    "title": "Finding Existing Data",
    "section": "",
    "text": "Anything that can be used for analysis can be considered “data(sets)”. Many national and international organisations provide access to large datasets free of charge: this is called Open Data.\nDatasets may contain different kinds of data files, e.g. raw or edited/cleaned data, and macro or micro data. Raw data refers to the data as they are primarily collected, and includes all data, even the missed or mismatched pieces in the data file. Edited or cleaned data refers to data that have been tidied up for analysis and publication. Macro data and statistics are results based on micro data units and provide a general overview of the micro data. Although datasets can contain data of varying type or aggregation level, and there may be overlap between these definitions, each element can contain very important information.\nWhen re-using research data, scientists must be familiar with the rules and regulations governing data copyright, intellectual property rights, and laws governing sensitive or personal information. SURF has compiled a report on the legal status of raw data including information on the types of consent required for the re-use of data. Your 🔒 Privacy Champion can answer questions about the use of personal data. IXA can provide legal help with the re-use of data.\nSee also the ZonMw explanation of different kinds of property rights in the Netherlands (text available in Dutch only)."
  },
  {
    "objectID": "topics/finding-existing-data.html#re-using-existing-data",
    "href": "topics/finding-existing-data.html#re-using-existing-data",
    "title": "Finding Existing Data",
    "section": "",
    "text": "Anything that can be used for analysis can be considered “data(sets)”. Many national and international organisations provide access to large datasets free of charge: this is called Open Data.\nDatasets may contain different kinds of data files, e.g. raw or edited/cleaned data, and macro or micro data. Raw data refers to the data as they are primarily collected, and includes all data, even the missed or mismatched pieces in the data file. Edited or cleaned data refers to data that have been tidied up for analysis and publication. Macro data and statistics are results based on micro data units and provide a general overview of the micro data. Although datasets can contain data of varying type or aggregation level, and there may be overlap between these definitions, each element can contain very important information.\nWhen re-using research data, scientists must be familiar with the rules and regulations governing data copyright, intellectual property rights, and laws governing sensitive or personal information. SURF has compiled a report on the legal status of raw data including information on the types of consent required for the re-use of data. Your 🔒 Privacy Champion can answer questions about the use of personal data. IXA can provide legal help with the re-use of data.\nSee also the ZonMw explanation of different kinds of property rights in the Netherlands (text available in Dutch only)."
  },
  {
    "objectID": "topics/finding-existing-data.html#sources-for-finding-existing-datasets",
    "href": "topics/finding-existing-data.html#sources-for-finding-existing-datasets",
    "title": "Finding Existing Data",
    "section": "Sources for Finding Existing Datasets",
    "text": "Sources for Finding Existing Datasets\nThe number of datasets that are available grows rapidly. Datasets are made available in many formats, by many people or organizations. Some datasets are raw files and some are specifically organised and formatted as databases that require a licence or subscription to use them. The library of VU Amsterdam has collected links to some of the data repositories used and has licensed several databases.\n\nPopular Free and Licensed Databases: These can be found with LibSearch Advanced.\n\nIf you need help finding & using free or licensed sources you can contact the Research Data Services Helpdesk. For students and personnel in the fields of economics, finance, or organisation science a separate LibGuide has been created to help them find and use/re-use data.\nYou can also start looking for data in these four places:\n\nThe literature. Research articles may point you to the data that they are based on. Sometimes, (part of) the data are added to the article as supplementary files, and sometimes the data are published separately in a data repository. In the latter case, the article usually provides a clear reference to the published dataset. Some datasets may even be specifically published in Data Journals.\nScientific data repositories. Data repositories are platforms used to access and archive research data. Universities often provide a repository for data archiving, but other platforms arranged by discipline or by country also exist. Some repositories are only accessible to consortium members, whereas others are free of charge. Many universities in the Netherlands use DataverseNL to archive datasets for the mid-term. Long-term archiving is provided by the national research data archives DANS and 4TU.Research Data. In Europe, B2SHARE and Zenodo are platforms used to access research data. Data repositories can be accessed by searching by topic or country using Re3data, a data repository registry. VU Amsterdam has its own research portal, PURE, where researchers register their datasets. You can find instructions on how to register your own dataset in PURE on the Dataset Registration page of this LibGuide.\nData search engines. Search engines allow you to quickly browse data sets and supplementary data files published by researchers. They cover data sets from many sources. This makes them useful for quick orientation on a topic. Example of a search engines are: DataCite, Google DataSet Search.\nData portals of (governmental) organisations. Organisations that regularly collect (statistical) data sometimes offer these data through their own portal. An example is Eurostat, which collects and disseminates statistics at the European level, by country and by theme. Some of these websites have been linked in the Finding data LibGuide."
  },
  {
    "objectID": "topics/finding-existing-data.html#data-sources-for-vu-researchers",
    "href": "topics/finding-existing-data.html#data-sources-for-vu-researchers",
    "title": "Finding Existing Data",
    "section": "Data Sources for VU Researchers",
    "text": "Data Sources for VU Researchers\nResearchers from VU Amsterdam have also developed some databases containing data collected during research. See here for some examples:\n\nNederlands Tweelingenregister (Netherlands Twin Register) The database contains data on twins and their families and was created to do research on the relationship between genetics and growth, development, personality, behaviour, diseases, mental health and all kinds of risks.\nGeoplaza VU - the portal for all matters related to GIS (Geographical Information Systems) and geodata at VU Amsterdam. It offers students and employers a platform to exchange, examine and download digital map material.\nDutch monasteries - database with information about Dutch monasteries of the Middle Ages.\nSlave owners in Amsterdam 1863 - the place of living of owners of slaves in Amsterdam in 1863, visualized in GeoPlaza.\nDeaths at the Borders Database - collection of official, state-produced evidence on people who died while attempting to reach southern EU countries from the Balkans, the Middle East, and North & West Africa, and whose bodies were found in or brought to Europe.\nDatasets published by VU Researchers can be found at the VU Research Portal."
  },
  {
    "objectID": "topics/pure.html",
    "href": "topics/pure.html",
    "title": "Pure (VU Research Information System)",
    "section": "",
    "text": "Pure is VU Amsterdam’s Current Research Information System (CRIS) that serves as the central repository for recording all research activities and outputs. All VU researchers can administer their research activities in the admin environment. Additionally the content and VU researchers are profiled on the VU research portal accessible on the public website. Pure serves both as an internal management tool and as a public-facing platform that increases the visibility and discoverability of VU research."
  },
  {
    "objectID": "topics/pure.html#what-is-it",
    "href": "topics/pure.html#what-is-it",
    "title": "Pure (VU Research Information System)",
    "section": "",
    "text": "Pure is VU Amsterdam’s Current Research Information System (CRIS) that serves as the central repository for recording all research activities and outputs. All VU researchers can administer their research activities in the admin environment. Additionally the content and VU researchers are profiled on the VU research portal accessible on the public website. Pure serves both as an internal management tool and as a public-facing platform that increases the visibility and discoverability of VU research."
  },
  {
    "objectID": "topics/pure.html#what-can-it-be-used-for",
    "href": "topics/pure.html#what-can-it-be-used-for",
    "title": "Pure (VU Research Information System)",
    "section": "What can it be used for?",
    "text": "What can it be used for?\n\nResearch output registration\nThe following record types can be registered in Pure:\n\nPublications: This can be (journal) articles, books, conference contributions, working papers, preprints, PhD theses1, patents, case notes and web publications.\nActivities: peer review, editorial work, participating in or organising an event, lectures, presentations, consultancy, PhD examinations, visiting external institutions, hosting external visitors and memberships of institutions based on academic expertise.\nDatasets: This can be raw research data or (curated) datasets related to publications or projects.\nSoftware: This can be scripts or fully-fledged software programmes.\nPrizes/Grants: This can be prizes given for research output or grants awarded for research proposals.\nPress/Media: This can be the participations in various media forms as an expert or public engagement activities to promote (future) research.\nProjects: This can be all forms of projects in scope and size2 with the ability to link all related research activities and output.\nCourses3: This can be the development of courses or the presentation of these courses.\n\n\n\nResearcher profiles\nVU Researchers can create and maintain comprehensive academic profiles by providing personal information, academic background and research focus and interests.\n\n\nReporting\nPure can be used to report on all the content registered. Pure reports are also used for the annual VU report, visitations and the Open Access monitor.\n\n\nCV generation:\nPure contains a tool to combine all the research activities and personal information into a CV document."
  },
  {
    "objectID": "topics/pure.html#how-to-request-access",
    "href": "topics/pure.html#how-to-request-access",
    "title": "Pure (VU Research Information System)",
    "section": "How to request access",
    "text": "How to request access\nAccess to Pure is automatically provided to all VU Amsterdam researchers and PhD candidates4."
  },
  {
    "objectID": "topics/pure.html#are-there-costs-involved",
    "href": "topics/pure.html#are-there-costs-involved",
    "title": "Pure (VU Research Information System)",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nNo, there are no additional costs for VU Amsterdam researchers to use Pure."
  },
  {
    "objectID": "topics/pure.html#getting-started",
    "href": "topics/pure.html#getting-started",
    "title": "Pure (VU Research Information System)",
    "section": "Getting started",
    "text": "Getting started\n\nAccessing Pure\nTo work within Pure go to the login page. You can log in using your VUnetID and password.\n\n\nSetting up your profile\nVU Amsterdam has created an online manual to set up your own profile in Pure. You can also link your ORCID profile to your PURE profile, which has as a benefit that publications registered in PURE are automatically added to your ORCID profile.\n\n\nAdding research outputs\nManuals are available for registering different types of research output:\n\nManual to register research publications in Pure\nInstructions for data registration in Pure\nInstructions for software registration in Pure\n\nNote that the Research Data and Software Management Policy states that archived and published data and software must be registered. In most cases, this is done automatically. Researchers are requested to check their registrations and evaluate if they are complete. If they have archived or published data or software that has not been included in their Pure profile, they need complete these registrations themselves, as explained in the instructions mentioned above."
  },
  {
    "objectID": "topics/pure.html#contact",
    "href": "topics/pure.html#contact",
    "title": "Pure (VU Research Information System)",
    "section": "Contact",
    "text": "Contact\nBelow, you can find the support services for Pure provided by the University Library.\n\nTraining and technical support\nThe VU Library’s Pure support team provides training and demonstrations on request.\nFor questions or personal support contact the VU Library’s Pure support team.\n\n\nPolicy and compliance questions\nContact your own department secretariat to learn about required research activity registration besides publications, datasets and software."
  },
  {
    "objectID": "topics/pure.html#footnotes",
    "href": "topics/pure.html#footnotes",
    "title": "Pure (VU Research Information System)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nVU-related PhD theses are registered in Hora Finita and when approved are automatically imported into Pure.↩︎\nProjects registered in the VU financial systems are automatically imported into Pure.↩︎\nAll the current courses are automatically imported into Pure.↩︎\nCertain VU functions can have a research component to their workload, but if this is not a standard requirement, a Pure account is not automatically created. Department heads can request a Pure account and profile to be created for specific VU employees who create research output.↩︎"
  },
  {
    "objectID": "manuals.html",
    "href": "manuals.html",
    "title": "Manuals",
    "section": "",
    "text": "What is a manual?\n\n\n\nA manual shows you how to accomplish a specific task in a tool. They are organized per tool. These pages are a quick way to get started with a tool.\nMissing a manual? You can submit suggestion using the Contribution portal.\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nYoda Manuals\n\n\nThis section explains how to get started with Yoda.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html",
    "title": "Using Cyberduck",
    "section": "",
    "text": "This page explains how to connect to the Yoda WebDAV interface using Cyberduck.\nCyberduck is desktop software for Microsoft Windows and Apple macOS that can be used to transfer files between your computer and Yoda. In this guide we will explain how to install Cyberduck, create a new connection (bookmark) to Yoda and end with some frequently asked questions and tips on using Cyberduck",
    "crumbs": [
      "Data Transfer",
      "Using Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#getting-cyberduck",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#getting-cyberduck",
    "title": "Using Cyberduck",
    "section": "Getting Cyberduck",
    "text": "Getting Cyberduck\nmacOS : Cyberduck can be installed from the VU software center or downloaded from the internet.\nMicrosoft Windows 10/11 : Download Cyberduck from https://cyberduck.io/download/ it is free and you do not need to register.\n\nRun the downloaded installer by double clicking on “Cyberduck-installer.exe” which you will find in your Download folder in explorer. Install Cyberduck with the default options, and once that is done launch Cyberduck from the start menu.",
    "crumbs": [
      "Data Transfer",
      "Using Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#configuring-cyberduck",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#configuring-cyberduck",
    "title": "Using Cyberduck",
    "section": "Configuring Cyberduck",
    "text": "Configuring Cyberduck\n\n\nCreate a new secure WebDAV (HTTPS) connection to Yoda (bookmark)\nFirst create a new bookmark by pressing the + button on the lower left side of the screen.\n\nYou will now see a new connection page:\n\nClick on the “FTP (File Transfer Protocol)” dropdown list and select a WebDAV (HTTPS) connection\n\nand you will see the WebDAV (HTTPS) connection page.\n\nFill in the following information in the appropriate blocks\nFirst generate a Data Access Password.\n\nServer: data.yoda.vu.nl\nUsername: your email address\nPassword: paste (CTRL-v) the data access password you created in the portal.\n\nCyberduck uses your home folder as a default directory to download files. This can be changed by clicking on “More Options” and choosing a new folder\n\nYou have successfully created a bookmark, close the editing window by clicking on the R X button on the top right of the edit window to return to the main Cyberduck screen.\n\n\nConnecting to Yoda\nThe main screen shows all the connections (bookmarks) you have defined. To connect, double click on the bookmark (in this case “data.yoda.vu.nl - WebDAV (HTTPS)”) and you will be connected.\n\nIf you did not fill in your password in the bookmark you will be asked to do so now. Please note, “Save password” is automatically selected by Cyberduck, you may decide to (un)check this option. Fill in your vunet-id password and click ” Login” to connect.\n\nIf your login unexpectedly fails, please check if your data access password is still valid.\nYou should now see your project directory in an explorer like window:",
    "crumbs": [
      "Data Transfer",
      "Using Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#working-with-yoda-folders-and-uploadingdownloading-files",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#working-with-yoda-folders-and-uploadingdownloading-files",
    "title": "Using Cyberduck",
    "section": "Working with Yoda folders and uploading/downloading files",
    "text": "Working with Yoda folders and uploading/downloading files\nClick on a &gt; to open a folder,\n\nor double click to open in the main window.\n\nUse the left, right and up arrows to navigate the directory tree and right click on the main window to create a new folder:\n\nAlternatively, drag-and-drop folders and files from Windows Explorer to your Yoda project folders:\n\nIn either case, once copying has started you should see the transfer window. Keep this open until the transfer is complete.\n\nAlternatively, the context menu (activate by right clicking on a Yoda project file/directory) has a number of options for uploading, downloading and synchronizing files and folders:",
    "crumbs": [
      "Data Transfer",
      "Using Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#some-things-to-consider-when-using-cyberduckwebdav",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#some-things-to-consider-when-using-cyberduckwebdav",
    "title": "Using Cyberduck",
    "section": "Some things to consider when using Cyberduck/webDAV",
    "text": "Some things to consider when using Cyberduck/webDAV\n\nTotal path and file length\nWhen using Cyberduck you need to make sure that your path lengths (directories + filename) are less than 255 characters long. When using webDAV this is also true on the server side (Yoda) this includes server name, project name and project folders. Be careful when copying deep directory structures and very long filenames to Yoda using Cyberduck and webDAV. Fortunately, Cyberduck will display an error message and not copy theile when either trying to copy a file with a too long source or destination path. This error is typically “access denied” (403 or 500) error and if you click “continue” Cyberduck simply skips that file and it is not transferred to Yoda.\nRecommendation. If you get “access denied errors” when transferring files with Cyberduck - Make a note of which files fail to copy. - Flatten the directory structure or shorten the filename. - Zip the “main” directory branch(es) that contain the long path names into individual ZIP archives.",
    "crumbs": [
      "Data Transfer",
      "Using Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#frequently-asked-questions",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck.html#frequently-asked-questions",
    "title": "Using Cyberduck",
    "section": "Frequently asked questions",
    "text": "Frequently asked questions\n\nQ1) When I try to delete a file, I get a “cannot delete &lt;filename&gt;” Cyberduck error.\n\nThis error message can appear when the file/folder is read-only. Read only access can be a result of:\n\nThe folder has been locked.\nYou have been given read-only access to the project folder\n\nAnswer: unlock the folder in the research portal or get project read/write access.\n\n\nQ2) I copy a file using Cyberduck, the transfer succeeds but I don’t see the file in the portal.\nThe folder you are copying to is marked as read only. Read only access can be a result of:\n\nThe folder has been locked in the Yoda portal\nYou have been given read-only access to the project folder\n\nAnswer: unlock the folder in the research portal or get project read/write access.\n\n\nQ3) I tried to delete a file but get an “Access denied” error message\nOne possibility is that the file has been corrupted during upload and is incorrectly registered in the iRODS database.\nAnswer: Contact your data manager or iRODS administrator to fix the problem.",
    "crumbs": [
      "Data Transfer",
      "Using Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_winscp.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_winscp.html",
    "title": "Using WinSCP",
    "section": "",
    "text": "This page explains how to use WinSCP software, on Windows, to access your data via the Yoda WebDAV interface.\nWindows users can use WinSCP to access their data via the Yoda WebDAV interface, as an alternative to the native WebDAV client.\nWinSCP is an easy-to-use filetransfer tool. It will show your local disk and the remote Yoda folders next to eachother so you can easily drag and drop files from one to the other.",
    "crumbs": [
      "Data Transfer",
      "Using WinSCP"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_winscp.html#installing-winscp",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_winscp.html#installing-winscp",
    "title": "Using WinSCP",
    "section": "Installing WinSCP",
    "text": "Installing WinSCP\nThe WinSCP install guide explains how to install WinSCP.",
    "crumbs": [
      "Data Transfer",
      "Using WinSCP"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_winscp.html#using-winscp",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_winscp.html#using-winscp",
    "title": "Using WinSCP",
    "section": "Using WinSCP",
    "text": "Using WinSCP\nStart WinSCP from the Desktop icon or the Start menu.\nIn the login window, ensure that the file protocol is set to “WebDAV” and encryption is set to “TLS/SSL implicit encryption”.\n\nEnter https://data.yoda.vu.nl/ in the Host name field. The port number should have its default value: 443.\n\nYou will be prompted for a name and password. User name is your email. Create a data access password and copy it to the Password field.",
    "crumbs": [
      "Data Transfer",
      "Using WinSCP"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html",
    "title": "Using Windows Explorer",
    "section": "",
    "text": "This page explains how to connect to your data via the Yoda WebDAV interface by assigning a drive letter on Windows.\nFor most users, Cyberduck is a better alternative. However, the Yoda team recommends using the native WebDAV client if you can’t install Cyberduck, for example if the security settings of your laptop prevent you from installing any new applications.",
    "crumbs": [
      "Data Transfer",
      "Using Windows Explorer"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html#mapping-network-drive",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html#mapping-network-drive",
    "title": "Using Windows Explorer",
    "section": "Mapping network drive",
    "text": "Mapping network drive\nOpen “This PC” from the Start menu\n\n\n\nThis PC\n\n\nOpen the Computer menu item and select “Map network drive”.\n\n\n\nMap network drive icon in This PC\n\n\nSelect a drive letter — any free letter is okay. Now enter https://data.yoda.vu.nl/ in the Folder field (see table below).\n\n\n\nfolder input field when mapping network drive\n\n\nEnsure the box “Connect using different credentials” is checked and click on the Finish button.\nYou will be prompted for a name and password. Name is your email address. Create a data access password and copy it to the Password field If you are working on your personal PC or laptop, tick the checkbox “Remember my credentials”.\n\n\n\ndialog for entering credentials when mapping network drive\n\n\nThe Explorer screen will show the folders you have access rights to. You can now drag and drop your files to upload or download them.",
    "crumbs": [
      "Data Transfer",
      "Using Windows Explorer"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html#increasing-maximum-file-size",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html#increasing-maximum-file-size",
    "title": "Using Windows Explorer",
    "section": "Increasing maximum file size",
    "text": "Increasing maximum file size\nBy default, the native WebDAV client on Windows 10 only works with files smaller than 50 MB.\nOn Windows 11 the limit is set to the maximum 4GB by default.\nYou can increase the limit on Windows 10 to 4 GB if you have a local administrator account: - Open the registry editor by pressing the start button, entering “regedit” and pressing the enter key. - If you are asked whether the registry editor should be allowed to change the system settings, confirm. - Navigate to key HKEY\\_LOCAL\\_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WebClient\\Parameters - Open the FileSizeLimitInBytes key\n\n\n\nFileSizeLimitInBytes registry key\n\n\n\nSet it to FFFFFFFF (hexadecimal)\n\n\n\n\nincreasing the file size limit\n\n\n\nClick on the “OK” button and close the registry editor\nRestart your computer",
    "crumbs": [
      "Data Transfer",
      "Using Windows Explorer"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html#increasing-the-number-of-files-shown-in-a-folder",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html#increasing-the-number-of-files-shown-in-a-folder",
    "title": "Using Windows Explorer",
    "section": "Increasing the number of files shown in a folder",
    "text": "Increasing the number of files shown in a folder\nBy default the native WebDAV client on Windows 10 & 11 will show a folder containing more than 1000 files as empty. If you need to work with larger folders you can increase this limit if you have a local administrator account:\n\nOpen the registry editor by pressing the start button, entering “regedit” and pressing the - enter key.\nIf you are asked whether the registry editor should be allowed to change the system settings, confirm.\nNavigate to key HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WebClient\\Parameters\nOpen the FileAttributesLimitInBytes key: \nIn the Value data box, type the value that you want to use, and then click OK. For example, if the Web folder contains 20,000 files, type 20000000 in the Value data box.",
    "crumbs": [
      "Data Transfer",
      "Using Windows Explorer"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html#updating-your-password-for-a-mapped-network-drive-on-windows",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_windowsexplorer.html#updating-your-password-for-a-mapped-network-drive-on-windows",
    "title": "Using Windows Explorer",
    "section": "Updating your password for a mapped network drive on Windows",
    "text": "Updating your password for a mapped network drive on Windows\nFirst open the credential manager by clicking on the start button and typing “Manage Windows Credentials”.\n\n\n\nstarting the Windows credential manager.\n\n\nSelect the address of your Yoda WebDAV interface in the list of generic credentials.\n\n\n\nselecting the credentials of the Yoda WebDAV interface in the credential manager\n\n\nChoose “Edit”. Edit your credentials and click on the “Save” button.\n\n\n\nediting the Yoda credentials in the credential manager\n\n\nRestart your computer and open the mapped network drive in “This PC”. You may have to reenter your username and new password once more.\n\n\n\ndialog for entering credentials when mapping network drive",
    "crumbs": [
      "Data Transfer",
      "Using Windows Explorer"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_dap.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_dap.html",
    "title": "Creating a Data Access Password",
    "section": "",
    "text": "This page explains how to set a Data Access Password to access data via the Yoda WebDAV and iRODS interfaces.\n\nClick on your username in the top right and click Data Access Password or go to https://portal.yoda.vu.nl/user/data_access:\n\n\n\n\nData Access Password menu\n\n\n - Enter a suitable label and click on “Generate new data access password”\n - The password is shown. Click Copy to copy it to the clipboard. After this you can use CTRL-v to paste it.\n\nData access passwords expire in 90 days, you can view the expiration time in the list. \nIf a password has expired, simply create a new one. Don’t forget to update the password in the WebDAV client.",
    "crumbs": [
      "Data Transfer",
      "Creating a Data Access Password"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_rclone.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_rclone.html",
    "title": "Using Rclone",
    "section": "",
    "text": "This page explains how to use Rclone software, on Windows, MacOS or Linux, to access your data via the Yoda WebDAV interface.\nRclone is a command-line program to manage files on cloud storage. It is a feature-rich alternative to cloud vendors’ web storage interfaces. Over 40 cloud storage products support rclone including S3 object stores, business & consumer file storage services, as well as standard transfer protocols.\nRclone is available for Linux, Mac and Windows, see https://rclone.org/downloads/\nYou can use rclone to access the Yoda drive using WebDAV.\nNote: if you are on Linux and comfortable with commandline tools, the iRODS icommands provide better performance.",
    "crumbs": [
      "Data Transfer",
      "Using Rclone"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_rclone.html#create-a-config",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_rclone.html#create-a-config",
    "title": "Using Rclone",
    "section": "Create a config",
    "text": "Create a config\nRclone always expects you to create a config first:\nrclone config\nYou will be led through a number of questions\nCurrent remotes:\n\nName                 Type\n====                 ====\n\ne) Edit existing remote\nn) New remote\nd) Delete remote\nr) Rename remote\nc) Copy remote\ns) Set configuration password\nq) Quit config\ne/n/d/r/c/s/q&gt; n\n\nEnter name for new remote.\nname&gt; yoda\nOption Storage.\nType of storage to configure.\nChoose a number from below, or type in your own value.\n\n...\n46 / WebDAV\n\\ (webdav)\n...\nStorage&gt; 46\nOption url.\nURL of http host to connect to.\nE.g. https://example.com.\nEnter a value.\nurl&gt; https://data.yoda.vu.nl\nOption vendor.\nName of the WebDAV site/service/software you are using.\nChoose a number from below, or type in your own value.\nPress Enter to leave empty.\n1 / Nextcloud\n\\ (nextcloud)\n2 / Owncloud\n\\ (owncloud)\n3 / Sharepoint Online, authenticated by Microsoft account\n\\ (sharepoint)\n4 / Sharepoint with NTLM authentication, usually self-hosted or on-premises\n\\ (sharepoint-ntlm)\n5 / Other site/service or software\n\\ (other)\nvendor&gt; 5\nOption user.\nUser name.\nIn case NTLM authentication is used, the username should be in the format 'Domain\\User'.\nEnter a value. Press Enter to leave empty.\nuser&gt; e.m.ployee@vu.nl\nOption pass.\nPassword.\nChoose an alternative below. Press Enter for the default (n).\ny) Yes, type in my own password\ng) Generate random password\nn) No, leave this optional password blank (default)\ny/g/n&gt; y\nEnter the password:\npassword:\nConfirm the password:\npassword:\nPassword is a Data Access Password generated in Yoda.\nOption bearer_token.\nBearer token instead of user/pass (e.g. a Macaroon).\nEnter a value. Press Enter to leave empty.\nbearer_token&gt;\n\nEdit advanced config?\ny) Yes\nn) No (default)\ny/n&gt; n\nOptions:\n- type: webdav\n- url: https://data.yoda.vu.nl\n- vendor: other\n- user: e.m.ployee@vu.nl\n- pass: *** ENCRYPTED ***\n  Keep this \"yoda\" remote?\n  y) Yes this is OK (default)\n  e) Edit this remote\n  d) Delete this remote\n  y/e/d&gt; y\n\n\nName                 Type\n====                 ====\nyoda                 webdav\n\ne) Edit existing remote\nn) New remote\nd) Delete remote\nr) Rename remote\ns) Set configuration password\nq) Quit config\ne/n/d/r/c/s/q&gt; q",
    "crumbs": [
      "Data Transfer",
      "Using Rclone"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_rclone.html#updating-the-data-access-password",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_rclone.html#updating-the-data-access-password",
    "title": "Using Rclone",
    "section": "Updating the Data Access Password",
    "text": "Updating the Data Access Password\nA Yoda Data Access Password is only valid for a set amount of time. Once it has expired you should generate a new one. Run rclone config, choose e) Edit existing remote and enter the new DAP in the password section:\n...\n\nOption pass.\nPassword.\nChoose an alternative below. Press Enter for the default (n).\ny) Yes, type in my own password\ng) Generate random password\nn) No, keep existing (default)\ny/g/n&gt; y",
    "crumbs": [
      "Data Transfer",
      "Using Rclone"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_rclone.html#mounting-on-windows",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_rclone.html#mounting-on-windows",
    "title": "Using Rclone",
    "section": "Mounting on Windows",
    "text": "Mounting on Windows\nPlease make sure to use --vfs-cache-mode, see (rlone docs)[https://rclone.org/commands/rclone_mount/#vfs-file-caching]\n.\\rclone --vfs-cache-mode full mount yoda:research-staff-ubvu-geoplaza/ y:\nWill mount the yoda config as drive Y.\nThe rclone documentation provides information on how to (automatically starting rclone)[https://rclone.org/install/#autostart-on-windows].",
    "crumbs": [
      "Data Transfer",
      "Using Rclone"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_windows.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_windows.html",
    "title": "Data access on Windows",
    "section": "",
    "text": "This page explains how to access your Yoda data via the WebDAV interface on Windows machines.\nThere are 2 basic ways to access the Yoda WebDAV interfacek from Windows. Using a tool to mount the Yoda Disk as a drive letter or file transfer tools. Which one works best depends on your workflow.\n\nFile transfer\nThere are numerous free file transfer tools. Using these tools you must download the files you want to work on to your computer and upload the changes. This way of working is more stable and robust.\n\nCyberduck is a free file transfer tool for Mac and Windows. Cyberduck is the preferred way to access the Yoda Disk. There is also a paid addon “Mountainduck” which adds functionality to access via a drive letter.\nWinSCP is an alternative free file transfer tool.\n\n\n\nDrive letter\nUsing these tools you can access the Yoda Disk via a drive letter.\n\nWebDrive is a VU-supported method to remotely access files and can also be used on “green” pc’s.\nDirectly in Windows Explorer. However, this has restrictions: a maximum file size of 4GB on Windows 11 and 50MB(!) on Windows 10 and a maximum of 1000 files per folder (Windows 10&11). Take care if you expect your dataset to exceed these limitations.\n\n\n\nCommandline\nIf you are familiar with commandline tools rclone is also a good option to access the Yoda via Webdav. It also provides the option to use a drive letter.",
    "crumbs": [
      "Data Transfer",
      "Data access on Windows"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html",
    "title": "Adding Metadata",
    "section": "",
    "text": "This page provides guidance on how to add metadata to your datasets in Yoda.",
    "crumbs": [
      "Yoda Portal",
      "Adding Metadata"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#metadata-in-yoda",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#metadata-in-yoda",
    "title": "Adding Metadata",
    "section": "Metadata in Yoda",
    "text": "Metadata in Yoda\nMetadata is “data about data”. Metadata serves multiple purposes in Yoda, the most important being:\n\nTo describe the contents of a dataset for a broad audience.\nTo inform the audience whether the data can be reused and if so, under what conditions.\nTo prescribe how the data should be cited and whom to acknowledge.\nTo inform digital archivists and IT staff about how long the data should be retained.\nTo facilitate finding the dataset in data catalogues.\n\nWe distinguish two types of metadata:\nStructured metadata consists of information that is standardized globally and used by data catalogs. Examples are the title of the data package, its creator, the retention period of the package, etc.\nWhen a data package is published, Yoda makes the structured metadata available for harvesting by data catalogs, such as DataCite.\nUnstructured metadata is intended to provide more detailed information about the data. This information can be in a README.TXT or other file that is included as part of the data package. The format of this file is chosen by the researcher. Users will need to open and inspect the data package to find this metadata. Unstructured metadata can include information about (for example) the experimental design, data transformation, sampling method, etc.",
    "crumbs": [
      "Yoda Portal",
      "Adding Metadata"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#adding-metadata-in-yoda",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#adding-metadata-in-yoda",
    "title": "Adding Metadata",
    "section": "Adding metadata in Yoda",
    "text": "Adding metadata in Yoda\nYoda facilitates adding both structured and unstructured metadata to your research data. Entering structured metadata is a prerequisite for archiving a data package. If a folder is published, its structured metadata will be published as well and can be harvested by data catalogs such as DataCite. Your published datasets can also be registered in Pure.\nIn order to add structured metadata to a folder, navigate to the folder in the Yoda portal and press the “Metadata” button.\n\n\n\nAdd-metadata\n\n\nOnce you have added metadata and clicked on the “Save” button, the metadata will be stored in a specific format in the folder. Yoda uses files named “yoda-metadata.json” for this purpose.\nUnstructured metadata can be added as a file to the dataset, for example in a “Readme.txt” or “Codebook.pdf” file.",
    "crumbs": [
      "Yoda Portal",
      "Adding Metadata"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#the-metadata-form",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#the-metadata-form",
    "title": "Adding Metadata",
    "section": "The metadata form",
    "text": "The metadata form\nBy default, the Yoda metadata form consists of approximately 30 fields. Please consult the metadata element list below for a detailed description of the elements.\nAll mandatory fields are marked with an asterisk.\n\n\n\nMandatory metadata\n\n\nSome metadata elements consist of multiple fields. For example, if you enter a person identifier, you should also specify the type of identifier. \nSome fields can have multiple values. In order to add a value, press the “+” sign next to the field.",
    "crumbs": [
      "Yoda Portal",
      "Adding Metadata"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#reusing-metadata",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#reusing-metadata",
    "title": "Adding Metadata",
    "section": "Reusing metadata",
    "text": "Reusing metadata\nStructured metadata is reusable. The metadata form includes a button “Clone from parent folder”. One way to use this feature is to create a project-level folder with several subfolders for data. Common metadata elements for the project can be entered in the project-level folder. This metadata can then be copied to the data folders and filled in further.\nYou can also copy the “yoda-metadata.json” file of a folder to another folder in order to copy its metadata.\nWhen you publish a folder, only the metadata on the level of that folder is published in data catalogs.\n\n\n\nFolderStructureMetadata",
    "crumbs": [
      "Yoda Portal",
      "Adding Metadata"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#properties-and-explanations",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata.html#properties-and-explanations",
    "title": "Adding Metadata",
    "section": "Properties and explanations",
    "text": "Properties and explanations\nM Mandatory\nR Recommended for optimal findability\nO Optional\n\n\n\nNo\nProperty\nObligation\nExplanation\nRemarks\n\n\n\n\n1\nTitle\nM\nA descriptive title for your data package, should not be longer than about 200 characters.\n\n\n\n2\nDescription\nM\nDescribe your data package, e.g. the subject, the sample size, methodology, etc. It is best to keep this description concise. More elaborate documentation should be added in a text file called README.\nThe text should be substantial and relevant to interpreting the content of the data package\n\n\n3\nDiscipline\nM\nThe (sub)discipline of the study.\nThe list contains a combination of research disciplines and subdisciplines. The standard used is the OECD FOS 2007. This field can have multiple values — use the plus sign to add more values.\n\n\n4\nVersion\nO\nVersion number of your data package. Useful if you need to publish an updated version of your data package later.\nYoda does not automatically assign version numbers to data packages. If you create multiple versions, you can register the version number yourself, according to your own versioning scheme.\n\n\n5\nLanguage of the data\nM\nThe primary language of your data package.\nThis element is thought of as a possible aid to assess the usability of a data package for a specific person. The standard used is ISO 639/1.\n\n\n6a\nCollection Process - Start Date\nR\nIndicate when you’ve started collecting the data for this data package.\nClicking on the field reveals a calendar you can use to pick the date.\n\n\n6b\nCollection Process - End Date\nM if 6a\nIndicate when you’ve finished collecting the data for this data package.\nClicking on the field reveals a calendar you can use to pick the date.\n\n\n7\nLocation(s) covered\nR\nIf your data is linked to particular locations provide place names.\nEnglish naming convention preferred. It is recommended to use the preferred spelling from the Getty Thesaurus of Geographic Names whenever possible. One location per line. This field can have multiple values — use the plus sign to add more values. Maximum length: 255 characters.\n\n\n8a\nPeriod Covered - Start period\nO\nAn indication of the start date of the period covered by your data package.\nClicking on the field reveals a calendar you can use to pick the date.\n\n\n8b\nPeriod Covered - End Period\nM if 8a\nAn indication of the end date of the period covered by your data package.\nClicking on the field reveals a calendar you can use to pick the date.\n\n\n9\nKeywords\nM\nFree text field for adding (searchable) keywords to your data package.\nYou can choose the keywords freely. It is best to add only one keyword per line. This field can have multiple values — use the plus sign to add more values. Maximum length: 255 characters.\n\n\n10a\nRelated Data package - Relation type\nR\nThe way in which the present data package (A) is related to another data package (B).\nIn this section you can enter a ‘related’ data package and the nature of that relation. For instance, you can indicate that the current data package (A) contains the raw data upon which the related data package (B) is based by selecting IsSourceOf in this field and entering the information of the other data package in the fields below. You can have multiple Related data packages — use the plus sign to add more values.\n\n\n10b\nRelated Data package - Title\nR If 10a\nTitle of the data package related to the present data package.\nThere is no automatic check whether title and persistent identifier match. Maximum length: 255 characters.\n\n\n10c\nRelated Data package – Identifier type\nM If 10d\nThe type of the persistent identifier of the related data package.\nExample: “DOI”.\n\n\n10d\nRelated Data package – Identifier\nR If 10a\nThe persistent identifier of the related data package.\nPlease fill in a resolvable URL. Example: “https://doi.org/10.48338/VU01-2LT5V4”.\n\n\n11\nRetention Period\nM\nThe minimal number of years the data will be kept in the archive. The default value is 10 years.\nIn this field you can only enter integers.\n\n\n12\nRetention Information\nO\nTo be used for remarks about the retention period.\nPlease provide a reason if you deviate from the default value of ten years. If you want to ensure that data is retained longer, then data management might request extra care for choosing sustainable file formats.\n\n\n13\nEmbargo enddate\nO\nIf the dataset has an embargo, on what date does the embargo end?\nThis functionality is not yet fully implemented. Please contact the data manager if you intend to publish a data package with an embargo.\n\n\n14\nData type\nM\nPlease indicate the type of the data.\nIf no type is selected Yoda will assume “Datapackage”.\n\n\n15\nData Classification\nM\nPlease indicate the classification of the data. Translation to VU Classifications: Public=Low, Basic=Medium, Sensitive=High, Critical=Very High.\nYou can find more information about data classification in the Research Support Handbook.\n\n\n16\nName of Collection\nO\nIf this data package is part of a larger (conceptual) collection of data packages, you can enter the collection name here.\nThe research group should ensure that all other data packages in the collection are archived with the same collection name. Maximum length: 255 characters.\n\n\n17a\nFunding information - Funder\nO\nThe name(s) of the organization(s) funding the research. If using this property also add the Award Number.\nExample: “Dutch Research Council”. It is recommended to use the preferred spelling from the Research Organization Registry (ROR). This field can have multiple values — use the plus sign to add more values. Maximum length: 255 characters.\n\n\n17b\nFunding information - Award number\nR if 17a\nThe grant number issued by the funding organization\n\n\n\n18\nRemarks\nO\nRemarks from the datamanager.\nRemarks serve only an administrative purpose and are not shown outside of the back-end of Yoda.\n\n\n19a\nCreator of Data package - Name\nM\nThe main researchers involved in producing the data, in priority order.\nA creator is explicitely listed as an author when the data package is cited. A creator is equivalent to a manuscript author. This field can have multiple values — use the plus sign to add more values. Maximum length: 255 characters.\n\n\n19b\nCreator of Data package – Affiliation name\nM\nThe organizational or institutional affiliation of the creator.\nExample: “Vrije Universiteit Amsterdam”. It is recommended to use the preferred spelling from the Research Organization Registry (ROR). The affiliation of the creator of a data package could be of importance when it is unclear who owns the data. In general the organization to which the creator was affiliated is regarded as the owner. Each creator can have multiple affiliations — use the plus sign to add more values. Most research institutes should be in the list and the ROR identifier will automatically filled. If the institution is not in the list, use the Find button, you can leave the ROR field empty in case the institute does not have a ROR. Maximum length: 255 characters.\n\n\n19c\nCreator of Data package – Affiliation identifier\nR\nThe organizational or institutional identifier of the creator.\nIt is recommended to use the resolvable URL from the Research Organization Registry (ROR). Example: “https://ror.org/008xxew50” for “Vrije Universiteit Amsterdam”.\n\n\n19d\nCreator of Data package – Persistent Identifier: Type\nM if 19e\nPlease indicate the type of persistent person identifier.\nE.g. Scopus Author ID, ORCID or ResearcherID. Multiple values are possible. If available, enter at least an ORCID.\n\n\n19e\nCreator of Data package – Persistent Identifier: Identifier\nR\nThe Persistent Identifier.\nIf you are not sure whether someone has a persistent identifier, you can check with the big three providers: Scopus Author ID, ORCID,ResearcherID. Each creator can have multiple persistent identifier — use the plus sign to add more values. Maximum length: 255 characters. Please fill in a resolvable URL. The pattern of an ORCID, ResearchID and ISNI is validated. There is no check if the name and identifier match.\n\n\n20a\nContributor to Data Package - Name\nR\nThe institution or person responsible for collecting, managing, distributing, or otherwise contributing to the development of the resource.For software, if there is an alternate entity that “holds, archives, publishes, prints, distributes, releases, issues, or produces” the code, use the contributor Type “hostingInstitution” for the code repository.\nContributors are not listed as creators when the data package is cited. Contributors are analogous to co-creators that would appear in the Acknowledgements-section of a manuscript. Multiple values possible — use the plus sign to add more values. Maximum length: 255 characters.\n\n\n20b\nContributor to Data Package - Type\nR if 20a\nEnter what type of contribution the registered person has had to this data package.\nSee the datacite documentation for explanation.\n\n\n20c\nContributor to Data Package - Affiliation name\nM if 20a\nThe organizational or institutional affiliation of the contributor.\nExample: “Vrije Universiteit Amsterdam”. The affiliation of the creator of a data package could be of importance when it is unclear who owns the data. In general the organization to which the creator was affiliated is regarded as the owner. Each creator can have multiple affiliations — use the plus sign to add more values. Most research institutes should be in the list and the ROR identifier will automatically filled. If the institution is not in the list, use the Find button, you can leave the ROR field empty in case the institute does not have a ROR. Maximum length: 255 characters.\n\n\n20d\nContributor to Data Package - Affiliation identifier\nR\nThe organizational or institutional identifier of the contributor.\nIt is recommended to use the resolvable URL from the Research Organization Registry (ROR). Example:“https://ror.org/008xxew50” for “Vrije Universiteit Amsterdam”.\n\n\n20e\nContributor to Data Package - Persistent Identifier: Type\nM if 20f\nPlease indicate the type of persistent person identifier.\nEach contributor can have multiple persistent identifiers — use the plus sign to add more values. Maximum length: 255 characters.\n\n\n20f\nContributor to Data Package - Persistent Identifier: Identifier\nR\nAn unique person identifier.\nEach contributor can have multiple identifiers — use the plus sign to add more values. Maximum length: 255 characters. Please fill in a resolvable URL. The pattern of an ORCID, ResearchID and ISNI is validated. There is no check if the name and identifier match.\n\n\n21\nLicense\nM\nThe license under which you offer the data package for use by third parties. The preferred value for open data is CC By 4.0.\nEvery package needs to be archived with a license — even when you’re not planning to publish the data or have it reused in any form. We offer a number of possible licenses in a drop-down list. If you do not know which license to choose, contact the data manager. At the moment of publishing a data package the relevant license text will be copied into the data package. If you opt for a custom license, you will need to store the custom license text in a file titled License.txt in the root folder. If the Data Package Access (22) is Restricted Access or Closed Access, you can only opt for a custom license, the VU has created custom templates for the License.txt file.\n\n\n22\nData Package Access\nM\nOnce archived, should your dataset be accessible to third parties?\nOpen Access means that the dataset is accessible to everyone. Restricted Access means that the dataset can only be obtained on request. Closed Access means that the dataset cannot be shared, in principle.",
    "crumbs": [
      "Yoda Portal",
      "Adding Metadata"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/index.html",
    "href": "manuals/yoda/yoda_portal/index.html",
    "title": "The Yoda Web Portal",
    "section": "",
    "text": "This page provides an overview of the Yoda functionality you can access through the Yoda Web Portal.",
    "crumbs": [
      "Yoda Portal"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/index.html#overview-of-the-yoda-web-portal",
    "href": "manuals/yoda/yoda_portal/index.html#overview-of-the-yoda-web-portal",
    "title": "The Yoda Web Portal",
    "section": "Overview of the Yoda Web Portal",
    "text": "Overview of the Yoda Web Portal\n\nGroup Manager\nYoda allows you to store your valuable research data in a secure way. The data is kept in data folders, which can only be accessed by members of the associated research Group.\nThe Group Manager can be used to view a list of research Groups and their members. People with a “group manager” role can add members to a research Group, remove them, and change their roles.\nSee: Managing groups, users and access rights\n\n\nYour data in the Yoda Portal\nEach group in Yoda has access to two main data folders:\n\nResearch (active data)\nThe main folder (“research-…”) contains current research data that researchers collaborate on. Data is kept in subfolders. The subfolders can be organized according to the needs of the research Group.\nYou can also drag-and-drop files to your research folder or download individual files.\nYou can Add metadata to a folder at any time to describe the dataset contained in that folder and its subfolders.\nWhen you know a (subset of) your data must be archived for the long term, the data in a subfolder can be submitted to the Yoda Vault so that it is kept for 10 years or longer.\n\n\nVault (archived data)\nThe folder named “vault-…” contains these deposited data packages. Data in the Vault cannot be deleted and the research Group has read access.\n\n\nPublishing archived data\nResearchers can opt to (but do not have to) publish any of the vault deposited data packages to make the metadata of a data package known to the research community at large.\nYoda adds a DOI persistent identifier to published data so that the data package can be cited and found in catalogs such as Datacite, Narcis, B2Find etcetera.\nIf (and only if) the data has been classified as “open” then the content itself can be downloaded by anyone from the internet. Otherwise, only the metadata description can be viewed.",
    "crumbs": [
      "Yoda Portal"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html",
    "title": "Archiving data",
    "section": "",
    "text": "This page provides guidance on using the archiving functionality of Yoda.\nIf you choose to archive a part of your data, Yoda will make a copy of the data to the archive (also known as “Vault”) of your project space, where it will be retained unchanged during its retention period (default 10 years).\nAfter archiving your data, you can optionally publish it, making your dataset findable on the internet. If you classify your data as open - freely retrievable, then the data itself can be downloaded anonymously by any third party.\nThis page contains information about how to create a data package, how to submit a data package to the vault, how the data package will be evaluated after submission, and how to manage archived data packages.",
    "crumbs": [
      "Yoda Portal",
      "Archiving data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html#creating-a-data-package",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html#creating-a-data-package",
    "title": "Archiving data",
    "section": "Creating a data package",
    "text": "Creating a data package\nThe data in your research data compartment is a set of files and folders.\nIf part of this data is to be archived, it is important that it has a logical folder structure, that it has appropriate metadata, and that it contains documentation which describes the data in more detail (such as a readme.txt file or codebook files). This ensures that other researchers will be able to understand the semantics of the data, the way in which it was collected or generated, and the conditions for (re)use.\n\nFile formats\nA best practice to keep your datasets re-usable is to store your data in open formats. DANS maintains a list of open file formats. If using only open file formats is not feasible, consider exporting each file in a vendor-specific format to an open file format, and storing the exported open format version along with the vendor-specific format version.\nYou can check in Yoda if you are in compliance with either the DANS Preferred formats or the 4TU Preferred formats by pressing the “Actions (Check for compliance with policy)” button.\n\n\n\nActions menu\n\n\nChoose a preferred fomat and the system will show you a list of filetypes in your data folder which are not compliant.\n\n\n\nCheck for DANS compliance",
    "crumbs": [
      "Yoda Portal",
      "Archiving data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html#submitting-a-data-package-to-the-vault",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html#submitting-a-data-package-to-the-vault",
    "title": "Archiving data",
    "section": "Submitting a data package to the Vault",
    "text": "Submitting a data package to the Vault\nIn order to submit a data package to the vault, you need to be either a group manager or a regular member of the group that contains the data.\nFirst, navigate to the folder you want to archive in the Yoda portal. Ensure that you are in the folder which you want to submit to the vault. Check that all mandatory metadata has been entered in the metadata form of the folder.\nNow press the “Actions (Submit)” button.\n\n\n\nSubmit\n\n\nIf any mandatory metadata is missing, the system will tell you what metadata still needs to be entered. If all required metadata is present, the system will lock the folder and its subfolders during the archiving process. This ensures that data in the folder can no longer be changed. Once the system has copied all data to the vault, the lock will be removed automatically.",
    "crumbs": [
      "Yoda Portal",
      "Archiving data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html#data-manager-assessment",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html#data-manager-assessment",
    "title": "Archiving data",
    "section": "Data manager assessment",
    "text": "Data manager assessment\nThe data manager will check that the data package is self-evident for other researchers, and will check for compliance with privacy rules and regulations.\nThe data manager can either approve the data package for archiving or suggest improvements.\nIf the status of your data package changes you will receive a notification in the portal. You can also choose to get notifications via email.",
    "crumbs": [
      "Yoda Portal",
      "Archiving data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html#managing-archived-data-packages",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_archiving.html#managing-archived-data-packages",
    "title": "Archiving data",
    "section": "Managing archived data packages",
    "text": "Managing archived data packages\nThe vault of your group becomes visible in the Yoda portal once it contains at least one data package. It has the same name as the research folder, except it starts with vault- (e.g. research-ub-test-project will have a Vault folder called vault-ub-test-project) . Everyone with access to your group research folder also has read-only access to the vault of your group.\n\n\n\nGo to Vault button\n\n\nIf the research folder has been deleted, you can request access to the archived data package via the data manager. If the data package has been published as Open Data it can be retrieved via data catalogs such as DataCite.\nYoda ensures there is always a datamanager assigned to a Vault who can access datasets even if the creators no longer have an account.",
    "crumbs": [
      "Yoda Portal",
      "Archiving data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_finding_restoring.html",
    "href": "manuals/yoda/yoda_portal/yoda_finding_restoring.html",
    "title": "Finding and restoring data",
    "section": "",
    "text": "This page explains the Search functionality of Yoda and how you can use it to restore older versions of a file.\nYou might want to search for data files or folders in your research group, especially when the amount of data you are working with is growing or when you have many different research groups of folders you work in. It is also possible to retrieve an earlier version (a revision) of a file, for example if you have accidently deleted a file. With the ‘search’ functionality in Yoda, you can do both.",
    "crumbs": [
      "Yoda Portal",
      "Finding and restoring data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#finding-files-and-folders",
    "href": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#finding-files-and-folders",
    "title": "Finding and restoring data",
    "section": "Finding files and folders",
    "text": "Finding files and folders\nFollow these steps to search for files or folders in Yoda.\n\nGo to the Yoda portal and sign in.\nClick on ‘Research’ in the menu (the grey bar).\n\nAbove the menu is the ‘quick search’ entry. This will search for matching file names.\n\nOnce the search is done you can refine or renew the search with more search options, with the search bar just below the menu.\nYou can select specific components in the drop-down menu to the left of the search bar.",
    "crumbs": [
      "Yoda Portal",
      "Finding and restoring data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#search-by-filename-search-by-folder",
    "href": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#search-by-filename-search-by-folder",
    "title": "Finding and restoring data",
    "section": "Search by filename / search by folder",
    "text": "Search by filename / search by folder\nIf you know (part of) the name of the file or folder you are looking for, use this as ‘Search term’.\nA search by name will find files and folders with the search term in its name. Typing a series of letters will reveal all files and (sub)folders containing that series in the name. For example, searching on “er” will result in finding:\n\n“er”\n“Er”\n“Ergonomics”\n“Folder A”",
    "crumbs": [
      "Yoda Portal",
      "Finding and restoring data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#search-by-metadata",
    "href": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#search-by-metadata",
    "title": "Finding and restoring data",
    "section": "Search by metadata",
    "text": "Search by metadata\nThe search by metadata will search in the contents of the fields in the metadata form. It reveals all fields containing your search term.\n\nAt first you will see the number of fields and hovering over it will show exactly which field contains the search term.",
    "crumbs": [
      "Yoda Portal",
      "Finding and restoring data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#search-by-status",
    "href": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#search-by-status",
    "title": "Finding and restoring data",
    "section": "Search by status",
    "text": "Search by status\nYou can also search by status in the vault.",
    "crumbs": [
      "Yoda Portal",
      "Finding and restoring data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#restoring-previous-file-versions",
    "href": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#restoring-previous-file-versions",
    "title": "Finding and restoring data",
    "section": "Restoring previous file versions",
    "text": "Restoring previous file versions\nPrevious file versions (revisions) are important if you need to go back to an earlier version of your work. Yoda provides you with a backup functionality of these earlier versions. This means you can restore files yourself.\nYoda saved a new revision of your data every time you save a file using the same name. Yoda does not overwrite the existing file, but creates a new revision while the older revision is stored in a hidden location. This then becomes a previous file version that you can restore if needed.\nAs time passes by, an increasing amount of the revisions will be deleted. This means that you can restore many revisions from the same day, less revisions from the last few days, even less revisions from a week back, etcetera. After 16 weeks, every revision older than 16 weeks is deleted.\nFollow these steps to restore older file versions:\n\nGo to the Yoda portal and sign in.\nClick on ‘Research’ in the menu (the black bar). There is a search bar just below the menu.\nSelect ‘Search revisions by name’.\nType the name of a file of which you want to restore a revision.\nClick on a file. You will now see the file versions in the search results.\nYou can save the file version you wish to restore in various ways:\n\n\nunder your own name in the same folder\nwith a different name\nin another folder within the research group\n\nNote that during your work a maximum of one revision per 60 seconds is made. Any changes within 60 seconds of the last revision will not form a new revision even though you saved it in the meantime.",
    "crumbs": [
      "Yoda Portal",
      "Finding and restoring data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#other-restore-options",
    "href": "manuals/yoda/yoda_portal/yoda_finding_restoring.html#other-restore-options",
    "title": "Finding and restoring data",
    "section": "Other restore options",
    "text": "Other restore options\nA daily backup is made of all data in the Yoda Research space. If you can’t restore the file via the revisions or if you need to restore an entire folder structure please contact the Research Support Desk at rdm@vu.nl for other restore options.",
    "crumbs": [
      "Yoda Portal",
      "Finding and restoring data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_group_manager.html",
    "href": "manuals/yoda/yoda_portal/yoda_group_manager.html",
    "title": "Managing Groups, Users and Access Rights",
    "section": "",
    "text": "This page explains how to use the Yoda Group Manager to manage the users who have access to the Group’s data.\nAll data in a Yoda Project is stored in 2 main data folders associated with a single access Group.\nThe name of such an access Group, also known as a research group, always starts with “research-”. Files in a research group are only visible and accessible to users who have been granted access to that group.\nUsers can have three different roles in a group:\nThese access rights are applied to the top-level and all subfolders and files of the Research Folder.",
    "crumbs": [
      "Yoda Portal",
      "Managing Groups, Users and Access Rights"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_group_manager.html#granting-access-to-a-group",
    "href": "manuals/yoda/yoda_portal/yoda_group_manager.html#granting-access-to-a-group",
    "title": "Managing Groups, Users and Access Rights",
    "section": "Granting access to a group",
    "text": "Granting access to a group\nIf you are the group manager of a group, you will be able to add users to the group in the following way:\n\nNavigate to the Yoda portal.\nLog in with your email address\nClick on the button on the top-right with your username.\n\n\n\n\nGroup manager\n\n\n\nIn the left pane of the Group Manager, select the group\nClick on the link “Click here to add a new user to the group”.\nEnter the email address of the user. The address must be entered entirely in lower case.\nIf the email address is new for Yoda you will have the option to create the user otherwise you add the existing user to this group.\n\n\n\n\nAdding user\n\n\nThe added user will receive an invitation to join the connected SRAM collaboration. Most users will be able to log in with their own institutional account, if their institute is not connected to SRAM they can create an eduID (NL) account.\nBy default, a new user will be a regular member of the group. If you want the user to be a member with read-only access or a group manager, see below for how to change users’ roles.",
    "crumbs": [
      "Yoda Portal",
      "Managing Groups, Users and Access Rights"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_group_manager.html#changing-the-role-of-a-user-in-a-group",
    "href": "manuals/yoda/yoda_portal/yoda_group_manager.html#changing-the-role-of-a-user-in-a-group",
    "title": "Managing Groups, Users and Access Rights",
    "section": "Changing the role of a user in a group",
    "text": "Changing the role of a user in a group\nIf you are the group manager of a group, you will be able to alter the role of other members.\nUsers can have three different roles in a group:\n\nMember with read-only access: is able to view or download files in the group.\nRegular member: can view, download, upload, modify or delete files and folders in the group.\nGroup manager: is able to grant and revoke access rights for the group. Can also view, download, upload, modify or delete files and folders in the group.\n\nIn order to change the role of a group member:\n\nNavigate to the Yoda portal.\nLog in\nClick on the button on the top-right with your username.\n\n\n\n\nGroup manager\n\n\n\nIn the left pane of the Group Manager, select the group.\nIn the right pane of the Group Manager, select the user.\nPress one of the buttons next to the “Change role” label to change the user’s role.\n\n\n\n\nSetting user rights\n\n\nNote that you can only change the role of the user after they have accepted the SRAM invitation.",
    "crumbs": [
      "Yoda Portal",
      "Managing Groups, Users and Access Rights"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_group_manager.html#revoking-access-to-a-group",
    "href": "manuals/yoda/yoda_portal/yoda_group_manager.html#revoking-access-to-a-group",
    "title": "Managing Groups, Users and Access Rights",
    "section": "Revoking access to a group",
    "text": "Revoking access to a group\nIf you are the group manager of a group, you will be able to revoke access to a group in the following way:\n\nNavigate to the Yoda portal.\nLog in\nClick on the button on the top-right with your username.\n\n![Group manager][Yoda portal](/public/manuals/yoda/gm-menu.png)\n\nIn the left pane of the Group Manager, select the group.\nIn the right pane of the Group Manager, select the user.\nClick on the red “Remove user” button.\n\n\n\n\nRemoving user\n\n\nNote that you can only remove a user after they have accepted the SRAM invitation.",
    "crumbs": [
      "Yoda Portal",
      "Managing Groups, Users and Access Rights"
    ]
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "You can contribute to the Research Support Handbook by making small edits, writing entirely new topics, or writing guides. All contributions are welcome and appreciated, small and large. There are two ways to contribute: via GitHub or by using the contribution portal. If you are in need of specific information, you can skip ahead using the table of contents."
  },
  {
    "objectID": "contributing.html#contributing-portal",
    "href": "contributing.html#contributing-portal",
    "title": "Contributing",
    "section": "Contributing portal",
    "text": "Contributing portal\nWe offer a portal to reduce the barriers to contribute to the Research Support Handbook. You only need an internet connection and articulate what you want us to include. No accounts necessary 😊\n\n\n\n\n\n\nNote\n\n\n\nOpen the contribution portal by clicking here or copy-pasting: https://ez-github-contributor.netlify.app/\n\n\nYou can report issues you find with the Research Support Handbook using the “Report a problem” tab. This is a way for you to share your feedback with us.\nYou can propose new topics or guides to the Research Support Handbook using the “Propose new page” tab. This will be considered for inclusion. Please mention whether it should be a topic or a guide. The text editor allows you to use rich text formatting.\n\n\n\n\n\n\nWarning\n\n\n\nThe portal does not save your work. Use the portal when you are ready to submit your work, but do not use it to manage your submissions.\n\n\n\n\n\nScreenshot of the contributor portal\n\n\nIf you want to be credited with contributing, please share your name. If you’d like to hear back about what was done with your feedback or proposal, please also provide a direct way to contact you. Once you have submitted the contribution, the editors will decide how to add your contribution to the handbook. Take a look at the Editor’s guide to learn more about what criteria they consider."
  },
  {
    "objectID": "contributing.html#contributing-via-github",
    "href": "contributing.html#contributing-via-github",
    "title": "Contributing",
    "section": "Contributing via GitHub",
    "text": "Contributing via GitHub\n\n\n\n\n\n\nNote\n\n\n\nFor the next steps you need a GitHub account to contribute. You can create one directly on GitHub.\n\n\n\nSuggesting edits\nThe easiest and quickest way to contribute to the book is make suggested edits. On each page you will find a button reading “Edit this page” (usually on the right).\n\n\n\nScreenshot of a handbook topic, with a red box on the right hand side of the page indicating where to find the “Edit this page” button\n\n\nWhen you click that, you will immediately be taken to GitHub to edit the text of that specific page. You may be prompted to create a fork (forking) in case these are your first edits.\n\n\n\nScreenshot of the GitHub file editor, with some changes made and the “Commit changes” button active\n\n\nOnce you made your edits, you are ready to commit (save) your changes and submit your pull request, requesting those changes to be included in the handbook.\n\n\nAdding a topic\nTo add a new topic, you need to create a new file ending in .qmd in the topics folder (e.g., topics/example.qmd). You can do this by visiting the handbook page on GitHub and clicking Add file -&gt; New file.\n\n\n\nScreenshot of GitHub highlighting where to find the “New file” button\n\n\nWhen you click this button you may be asked to fork the repository. This is not a problem so go ahead!\nThe topic itself needs to be written in Markdown. Every topic must be a noun/noun phrase and contain the title as such:\n---\ntitle: Example topic\n---\nSection headings are second level headings (e.g., ## Section). You can add all needed information as you want, but please mind that topics are supposed to short and self-contained for readers of the Research Support Handbook.\nAfter that, you are ready to submit your pull request! The reviewers will help you place the topic in the right place of the book.\n\n\nAdding a guide\nTo add a new guide, you need to create a new file ending in .qmd in the guides folder (e.g., guides/example.qmd). You can do this by visiting the handbook page on GitHub and clicking Add file -&gt; New file.\n\n\n\nScreenshot of GitHub highlighting where to find the “New file” button\n\n\nWhen you click this button you may be asked to fork the repository. This is not a problem so go ahead!\nEvery guide title must reflect the question the guide answers. Add the title by adding the following information at the top of your document:\n---\ntitle: How do I create a guide?\n---\nSection headings are second level headings (e.g., ## Section). The guide itself needs to be written in Markdown.\nYou can re-use topics literally in your guides. For each topic you want to include, you can either mention so on a line surrounded by whitespaces:\nINSERT TOPIC: DATA MANAGEMENT PLAN\nThis will tell the editorial team to include that topic there. Please be specific in naming the topic. You can also directly include the topic yourself directly using the following code:\n\n## Topic name\n\n    ```{.include shift-heading-level-by=2}\n    ../topics/replace-with-filename.qmd\n    ```\nYou need to count the heading level in your guide to identify your shift number. In this case, there are two ## so we shift by two. You can verify the filename directly, but it should correspond to each word separated by a minus sign (for example, data-management-plan.qmd).\nAfter that, you are ready to submit your pull request!\n\n\nEditing multiple files\nThere are situations in which you need to edit multiple files. If you carry out all edits in separate pull requests, this may be a long and repetitive task. Instead, you can change multiple files at once in a single pull request.\n\n\n\n\n\n\nNote\n\n\n\nIn case you want to edit multiple files in one go, here’s a video to help you along the way!\n\n\nVideo\nVideo describing the steps to use the GitHub editor to edit multiple files\n\n\n\n\n\n\nSubmit a pull request\nOnce you have made suggested changes, a pull request is the way for you to ask for your changes to be incorporated into the Research Support Handbook. The handbook editors will review what you wrote, ask some questions, and accept or decline your contributions.\nWe recommend keeping your suggested changes small or limited in scope, and explaining why you are suggesting these changes. It is more likely your changes are included when you are fixing a typo or adding a paragraph, and less likely if you are revising the entire handbook. It is also more likely they are included if you explain why you are suggesting the changes, rather than dropping by and making edits without any context.\nIf you are adding a new topic or guide, it is definitely recommended to open an issue first to see whether there is a need for it (and maybe you’ll find collaborators!).\nDuring the review process you may be asked to update your changes, or revisions may be added by the people maintaining the handbook. It is helpful if you keep an eye on your GitHub account to ensure timely responses to help the process along. By contributing, you become part of the process :blush:. Once you have submitted the contribution, the editors will decide how to add your contribution to the handbook. Take a look at the Editor’s guide to learn more about what criteria they consider.\n\n\nWriting text\nThe book is created using Markdown - you can get familiarized with the basic syntax on the Markdown website. The getting started quick items are:\n# Heading level 1\n## Heading level 2\n### Heading level 3\n\nYou simply write text as you are used to. To make something *italic*, **bold**, or ***bold and italic***.\n\n&gt; this is how you add quotes\n\n- or lists\n- that can go on\n- and on\nIf you want to add code, use references, create links, or footnotes - it is all possible. We will expand examples here based on your needs, so if you need help, let us know by reporting an issue!\n\nAdding relative links\nOften, you will want to link to other pages or sections in the Research Support Handbook. Instead of going to the website, and pasting the link from there (for example, https://ubvu.github.io/open-handbook/contributing.html), you can add what is called “relative links.”\nRelative links require three concepts:\n\nWorking directory: The folder in which the file you are editing is located\n./ = indicates the current folder\n../ = indicates the folder one level up\n\nThis Contributing guide is located in the “root” directory, and there is no upper folder. If we wanted to link to a topic, we would use ../topics/example-topic.qmd. This would create a relative link to the example file.\n\n\n\n\n\n\nNote\n\n\n\nRelative links link to the .qmd files, never to the .html pages. These only exist when the pages are rendered!\n\n\nIf we were editing a topic, and we wanted to link out to a guide, we would need to use ../guides/example-guide.qmd. This because we would be in the topic folder for that file, and need to navigate one level up (../) and then down into the guides folder. For topic to topic references, we do the same (../topics/example-topic.qmd). This ensures that the links work also when a topic is embedded into a guide directly.\n\nSection links\nWhenever we link to a specific guide or topic, you can also link to a specific section. This helps you point readers to what you want them to read, and helps them find the information they need.\nThe easiest way to find these section links is to navigate to the relevant page, and click on the link icon next to the heading. This will cause your URL to change.\n\n\n\nScreenshot indicating the link icon next to a heading, and the updated URL as a result\n\n\nYou add the #adding-a-guide (as applicable in your case) to the end of your relative link, and you will have created a relative section link! :blush:\nIf the section is on the same, you can drop the relative link altogether and keep only the part after the # (for example, #adding-a-guide).\n\n\n\n\nAdding images\nIn markdown, you can easily add images and alt text at the same time. We require alt text on all images, and if you are contributing an image, you can best describe its value in the text.\nYou add images by using:\n![Alt text](URL)\nIf you want the image to be hosted in the Research Support Handbook, use the following steps:\n\nAdd the image you want to the public/ folder\nMark the exact filename\nUse ../public/&lt;filename&gt; as the URL for the image (for example ../public/image.png)\n\n\n\nMore information about GitHub\nWe use GitHub to create this website automatically, and to manage all the incoming updates. You do not need to know how it works entirely, but we want to help you understand some things so you are not confused.\n\nRepository\nA repository on GitHub is like a folder on your computer. This can be many things, depending on what files it contains.\nWhen we mention a repository here, we mean that we want you to look at a specific folder. The repository for this website for example can be found on GitHub directly. You will always be contributing to a repository, in order to contribute to the handbook.\n\n\nForking\nA repository is owned by one or multiple people on GitHub. If you are not one of them, you can create a copy of the repository (folder) to make your edits in. This act of creating a copy is called “forking.”\nWhen you create a copy, you do not have to worry about accidentally removing or destroying the handbook. Your changes are not reflected in the website until you submit a pull request."
  },
  {
    "objectID": "contributing.html#adding-references",
    "href": "contributing.html#adding-references",
    "title": "Contributing",
    "section": "Adding references",
    "text": "Adding references\nIf you want to include references throughout the handbook, we recommend you do so in the following way.\n\nAdd the BibTex\nYou can find the relevant BibTeX information using a tool like the DOI to BibTeX converter. Counterintuitively, it also works on ISBNs for example.\nAfter you found the BibTeX information, you add it to the references.bib file (preferably all the way at the bottom). Example BibTeX information is:\n@ARTICLE{example-code,\n  title     = \"Example Title\",\n  author    = \"Author, Example\"\n  journal   = \"Example Journal\",\n  year      =  2042,\n  copyright = \"https://creativecommons.org/licenses/by/4.0\",\n  language  = \"en\"\n}\n\n\nAdd the citation\nTo add the citation to a page, you use [@example-code] or @example-code.\n@example-code will result in an in-text citation, like “Author (2042).”\n[@example-code] will result in a regular citation such as “(Author, 2042)”.\nFor more details on citations, see also the Quarto help page on citations."
  },
  {
    "objectID": "contributing.html#rendering-handbook-locally",
    "href": "contributing.html#rendering-handbook-locally",
    "title": "Contributing",
    "section": "Rendering handbook locally",
    "text": "Rendering handbook locally\nSometimes you may want to preview the changes you are making to the handbook. That is possible in most cases, but requires you to install some software. You need to install Quarto and assuming a successful installation, you then need to run the following code in your terminal1:\n# Clone the git repository\ngit clone https://github.com/ubvu/open-handbook\n# Go into the right folder\ncd  open-handbook\n# Render the handbook\nquarto render .\nThis will create a file called _site/index.html. You can now open the rendered website in your browser by running:\n# For Windows machines, use\nstart &lt;browser-name&gt; _site/index.html\n# For Mac machines, use\nopen _site/index.html\n# For Linux, it could depend on the exact Linux operating system, but you could try first\nxdg-open _site/index.html\nNote that you should not copy the &lt; and &gt;, they are written here to indicate where the browser name should come.\nYou can also make changes locally and push them to the github repo to open a new branch. The procedure for this in your terminal is as follows:\n# Navigate to the folder where the file you want to edit is located\ncd &lt;foldername&gt;\n# Open the file to edit\nnano &lt;filename&gt;\n# Edit the file and save by using `Control + O`. Exit nano by `Control + X`\n# Add the file to the staging area\ngit add &lt;filename&gt;\n# Commit the edits\ngit commit -m \"&lt;commit message&gt;\"\nOnce you are done editing, you can also render the page to check that all is well. If you have already used quarto render . once, you can simply re-render the page you were working on, using quarto render &lt;path/filename.qmd&gt;, e.g. quarto render ./topics/yoda.qmd, which is a lot quicker. Note that you should not copy the &lt; and &gt;, they are used here to indicate where to add file and folder names, or a suitable commit message.\nOnce you are happy with the result, you can push the new version back to the github repository online:\n# Push the edits to the remote (online) repository. You can only push to a new branch: the main branch is protected.\n# If you do not have editing rights to the handbook repository, you would be pushing to your fork.\ngit push origin main:&lt;new-branch-name&gt;\n# You may have to authenticate using your SSH key.\nNote that you should not copy the &lt; and &gt;, they are written here to indicate where file and folder names should be written. After doing this, your new branch is opened in the repository on GitHub and you can create a pull request.\nThis procedure requires some background knowledge on working (with git) in the command line. The resources below give more explanation:\n\nNavigating Files and Directories and Create a text file from the Carpentries’ Unix Shell lesson.\nCollaborating and Push local branches to a remote from the Carpentries’ Version Control with Git lesson.\n\nWe do not guarantee this will work immediately, but should cover most instances. If you are looking to contribute and want to render things locally, try this first, and if you run into any issues, let us know in an issue report. We’re happy to try our best if you share your error messages 😊"
  },
  {
    "objectID": "contributing.html#using-vs-code-to-contribute",
    "href": "contributing.html#using-vs-code-to-contribute",
    "title": "Contributing",
    "section": "Using VS Code to contribute",
    "text": "Using VS Code to contribute\nIf you are planning to make multiple contributions to the Handbook, working in the GitHub web interface can get cumbersome. In that case we suggest you use an IDE (Integrated Development Environment) to create and edit pages. An IDE is a text editor that has lots of extra functionalities for developers, such as integration with Git. VS Code is a widely used, free, IDE and it is very well suited to edit Markdown files and has integrated Git & GitHub support. This allows you to work on your edits on your laptop whenever you want, preview them using the Quarto client and Push your changes to GitHub. No special knowledge of the Git Commandline is necessary.\n\nInstall VS Code\nVS Code is available for Windows, Mac and Linux. Install it from https://code.visualstudio.com/Download.\nNote that VS Code is a Microsoft product, but the source code of VS Code is open source. The VS Code version you download from the above link is not, and it contains telemetry/tracking. A completely open source version without telemetry is available from https://vscodium.com, the functionality is the same.\n\n\nInstall the Quarto extension for VS Code\nInstall the Quarto Extension to make sure VS Code understands the Quarto format.\nNote that unfortunately the Preview functionality does not work very well with a project as large as the Handbook.\n\n\nMake sure Git is installed\n\nOpen VS Code and click on the Git icon on the left. If you do not have Git installed you can do so from here, the download button will lead you to https://git-scm.com/downloads, you do not need the GUI client.\n\n\n\n\nDownload Git\n\n\n - During the install you can set VS Code as default editor\n\n\n\nRecommended PATH option\n\n\n\nKeep defaults for the rest.\nOpen a command prompt to set your username and email address, without this you cannot push your changes to GitHub.\n\n\n\n\nSet git username and email\n\n\n\n\nCreate a root folder\nCreate a folder where your handbook copy and other code projects will be stored. For example on Windows C:\\users\\&lt;username&gt;\\VS Code.\nNote that it is not advisable to store code projects in a folder which is synced with OneDrive (such as the “Documents’ folder), OneDrive will have problems syncing the many small files that git uses. The same applies to SURFdrive and Research Drive. You will push changes to your code projects to github so there is no need to make extra backups.\n\n\nCreate a Fork of the Handbook\n\nGo to the Handbook repository on GitHub.\n\n - Click Fork button at the top right.\n - You end up with all the code in your personal account.\n\n\nClone your Fork\n\nGo to the Git Tab (or click File &gt; New window), there you will see the option to “Clone Repository”.\n\n\n\n\nClone Repository\n\n\n - You see the option “Clone from GitHub”.\n\nSign in to GitHub\n\n\n\nAllow GitHub sign in\n\n\n\nIf you have never signed in with Git before you will be asked to do so. Click Allow.\nThe GitHub Sign In page will be opened in the Browser. Login as usual.\n\n\n\nSelect the Fork you created earlier\n\nOnce you are signed in you can select from a list of repositories.\n\n - Select the Fork you created earlier.\n - Select your code root folder.\n\nA folder called open-handbook will be created in that folder and you can open it in VS Code.\n\n\n\n\nEditing\nNow you have a full copy of the Handbook on your laptop. Of course you are not working on the Handbook directly, but on your Fork.\nYou can make changes to the actual Handbook by making changes to your Fork and creating a Pull Request. The Pull Request will be opened in the ubvu open-handbook repository. The editors can then approve your request, perhaps after suggesting some changes, and your changes will be merged to rdm.vu.nl.\nThe handbook is a collaborative effort, multiple people will be making changes to multiple files at the same time. To prevent 2 or more contributors making changes to the same file you should keep the number of files you change in your Pull requests small, preferrably just one page at a time. The best way to do this is to start by creating a branch for the changes you want to make.\n\nCreate a branch\n\n\n\nCreate Branch\n\n\n - Provide a name for the branch. Keep it short and descriptive, this is mainly for yourself so you can easily remember what you created the branch for.\nVS Code will automatically switch to the branch. You can always see the branch you are working on in the bottom left of the Window.\n\n\n\nBranch name\n\n\nYou can click on the name there to switch the branch you are working on.\nRemember your changes are tied to the branch. If you would switch from the zenodo_topic branch to the main branch you will no longer see the changes you made to the Zenodo topic page. But if you have committed your changes they will be visible again once you switch back.\n\n\nEditing the page\nVS Code is basically just a text editor. Open the file you want to work on by double clicking or right click to create a new one in the “Explorer”.\n\n\n\n\n\n\nTip\n\n\n\nThe Quarto Extension includes a Visual Editor with which you can format Quarto pages without typing Markdown code.\n\n\n\nWork on your page and save your changes (Click File &gt; Save or use CTRL+S).\n\n\n\n\nChanges\n\n\n\nVS Code will show you the changes with respect to the branch. Now you can commit\n\n\n\nCommit changes\n\nClick on the Git icon on the left.\n\n- Set a short descriptive commit message, click the plus sign next to the files you want in your commit, and click commit.\n By double-clicking on a Modified file you will see a visual representation of your changes.\n\n\nPublish Branch\nNow you have committed your changes to the local git repository on your laptop. You will also need to publish the branch to github, so it gets updated as well.\n\n\n\nPublish Branch\n\n\n You will be able to view the branch on github.\nVS Code will now allow you to Sync (Push and Pull) your commits to the branch on GitHub.\n\n\nCreate a Pull request\nOnce you are happy with the changes you made you can submit a Pull request on GitHub.\n\n\nMore information\nThe VS Code documentation has a nice introduction to Git section with more useful tips.\nThe Quarto tutorial has more tips on using VS Code to edit Quarto pages.\n\n\nUsing the Visual editor\n\n\n\nVisual editor\n\n\n\nTo use the visual editor right-click anywhere in the document you are working on, or use CTRL+SHIFT+F4\n\n\n\n\nFormatting menu\n\n\n\nYou can now format text using a simple menu bar, instead of typing Markdown code."
  },
  {
    "objectID": "contributing.html#footnotes",
    "href": "contributing.html#footnotes",
    "title": "Contributing",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor Linux and Mac, this is usually called the terminal. For Windows machines, you would have to use the Git Bash↩︎"
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_publish.html",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_publish.html",
    "title": "Publishing data",
    "section": "",
    "text": "This page explains how to publish an archived dataset from the Yoda Vault.\nAfter a data package has been archived in the vault, it can optionally be submitted for publication.\nPublishing a data package has the following effects:\nThe VU Yoda repository page on DataCite Commons shows statistics of datasets currently published in VU Yoda.",
    "crumbs": [
      "Yoda Portal",
      "Publishing data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_publish.html#submitting-a-dataset-for-publication",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_publish.html#submitting-a-dataset-for-publication",
    "title": "Publishing data",
    "section": "Submitting a dataset for publication",
    "text": "Submitting a dataset for publication\nTo submit a data package for publication, navigate to the data package in the vault and press the “Submit for publication” button.\n\n\n\nSubmit for publication\n\n\nOnce you’ve submitted a data package for publication, the data manager of your Yoda community will be notified. The Data Manager will check that the data package meets various criteria for publication.\nIf the data manager encounters any issues, you will be contacted. Otherwise you’ll receive a notification that your data package has been published. This notification contains the DOI that has been assigned to your data package.\nNote: If needed a data manager can update metadata of a dataset after it has been published.",
    "crumbs": [
      "Yoda Portal",
      "Publishing data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_publish.html#long-term-accessibility",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_publish.html#long-term-accessibility",
    "title": "Publishing data",
    "section": "Long term accessibility",
    "text": "Long term accessibility\nYoda ensures there is always a datamanager assigned to a Vault who can access Restricted and Closed datasets even if the creators no longer have an account.",
    "crumbs": [
      "Yoda Portal",
      "Publishing data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_vault_publish.html#searching-for-unpublished-datassets",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_vault_publish.html#searching-for-unpublished-datassets",
    "title": "Publishing data",
    "section": "Searching for unpublished datassets",
    "text": "Searching for unpublished datassets\nYou can search for datasets that are archived but not (yet) published using the “Search by Status” function in the Yoda Portal. The list of data packages will include only the data packages of project groups of which you are a member. Click on a data package in the results list in order to view it.\n\n\n\nUnpublished data packages",
    "crumbs": [
      "Yoda Portal",
      "Publishing data"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata_license.html",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata_license.html",
    "title": "Selecting a license for your dataset",
    "section": "",
    "text": "This page provides guidance on how to choose a license for your archived and published datasets.\nWhen you archive your data, you can indicate the terms and conditions on how your data can be accessed and for what purposes it can be reused, or whether it can be reused at all. Here is some useful information on selecting and writing a license. We also offer options to get advice about selecting and creating your license, but you remain responsible for your eventual choice.\nMake sure the data does not contain sensitive information before making it publicly available through a CC-BY or other open license. You can check this through the Data Classification Tool and when uncertain by contacting the Privacy Champion of your faculty (in case of personal data) or Legal (Add ‘advice license ’ as the subject header in your mail).\nThere are several different licenses that can be selected for your dataset. These can be separated into three categories: Open, Restricted & Closed.",
    "crumbs": [
      "Yoda Portal",
      "Selecting a license for your dataset"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata_license.html#open",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata_license.html#open",
    "title": "Selecting a license for your dataset",
    "section": "Open",
    "text": "Open\nThis information applies when your data can be published openly, so that anyone can access them.\nThere are several standard Creative Commons licenses available to make your dataset directly accessible for other users. In general, these licenses are preferred as they allow easy re-use by others. Moreover, they are well known, which ensures that others quickly grasp how they may use your data. The variations of these licenses indicate the following aspects: author attribution requirement, commercial use, modification of the dataset and changing the license of any modified dataset. A useful decision tree can be found on the Creative Commons website.\nAnother open license is the Open Data Commons Open Database License (ODbL), which can be used specifically for databases.",
    "crumbs": [
      "Yoda Portal",
      "Selecting a license for your dataset"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata_license.html#restricted",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata_license.html#restricted",
    "title": "Selecting a license for your dataset",
    "section": "Restricted",
    "text": "Restricted\nWhen your data can be reused for new research, but not through an open license, it is important to state with whom the data can be shared and under which conditions and for what purposes the data can be used. The reasons for choosing a restricted license may vary from field to field but often apply to human subject data and data that was provided by a company but only under specific conditions. Another reason for choosing a restricted license is a personal preference.\n\nInstruction on using the VU Restricted license\n\nDownload the VU Restricted license template.\nCheck which conditions and requirements apply to the reuse of the data based on VU RDM guidelines, laws regarding use of data (GDPR, Intellectual Property legislation, etc.), requirements from funders or collaboration parties and conditions mentioned in the informed consent form signed by participants.\nAlter the template by indicating the potential usage purposes of the data and/or any regional restrictions. If you wish to receive advice on creating your license you can contact the Privacy Champion of your faculty (in case of personal data) or Legal (Add ‘advice custom license data management ’ as the subject header in your mail).\n\n\n\n\nEdit restricted license text\n\n\n\nSave the document as txt file: License.txt.\nUpload the file to your root data folder in Yoda.\nWhen creating a data package for archiving select Data Package Access “Restricted” and set License to “Custom” in the Metadata form and make sure the license is included.",
    "crumbs": [
      "Yoda Portal",
      "Selecting a license for your dataset"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_workflow_metadata_license.html#closed",
    "href": "manuals/yoda/yoda_portal/yoda_workflow_metadata_license.html#closed",
    "title": "Selecting a license for your dataset",
    "section": "Closed",
    "text": "Closed\nUnder certain circumstances, it becomes undesirable, inadvisable or even illegal to reuse your data new research. The provider of the data may prohibit sharing the data or the signed informed consent form may forbid sharing the data with third parties. In this situation you can use the VU Closed license template. The VU always retains the right to access the dataset for verification purposes.\n\nInstruction on using the VU Closed license\n\nDownload the VU Closed license template template.\nAlter the template to include the reason for not being accessible by third parties.\n\n\n\n\nEdit closed license text\n\n\n\nSave the document as txt file: License.txt.\nUpload the file to your root data folder in Yoda.\nWhen creating a data package for archiving select Data Package Access “Closed” and set License to “Custom” in the Metadata form and make sure the license is included.",
    "crumbs": [
      "Yoda Portal",
      "Selecting a license for your dataset"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_notifications.html",
    "href": "manuals/yoda/yoda_portal/yoda_notifications.html",
    "title": "Notifications",
    "section": "",
    "text": "This page explains how to view notifications.\nYoda uses a notification system to notify you when the status of a data package that was submitted for archiving or publishing changes.\nIf you have unread notifications a Bell sign will be shown next to your email address on the top right button.\nClick on the button and then “Notifications” to view them.",
    "crumbs": [
      "Yoda Portal",
      "Notifications"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_notifications.html#email-notifications",
    "href": "manuals/yoda/yoda_portal/yoda_notifications.html#email-notifications",
    "title": "Notifications",
    "section": "Email notifications",
    "text": "Email notifications\nClick on Settings in the above menu to configure email notifications.\n\n\n\nsettings menu",
    "crumbs": [
      "Yoda Portal",
      "Notifications"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_access.html",
    "href": "manuals/yoda/yoda_portal/yoda_access.html",
    "title": "Invitations and logging in",
    "section": "",
    "text": "This page explains how to accept a Yoda SRAM invitation and how to log in.",
    "crumbs": [
      "Yoda Portal",
      "Invitations and logging in"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_access.html#invitation-to-yoda-collaboration",
    "href": "manuals/yoda/yoda_portal/yoda_access.html#invitation-to-yoda-collaboration",
    "title": "Invitations and logging in",
    "section": "Invitation to Yoda collaboration",
    "text": "Invitation to Yoda collaboration\nAfter you are added to a Yoda group by the admin or a colleague you will receive an invitation to join a Yoda “collaboration” in SRAM (SURF Research Access Management). The “join” link in the invitation will lead you to SRAM.\n\nIf you have not logged in to SRAM before with your browser you will see the following screen where you can search for your institute:\n\n\n\n\nSRAM login page\n\n\n\nClick on the name to be redirected to your familiar institutional login page.\nIf your institute is not in this list or if you are not affiliated with a research or education organisation please choose eduID (NL). If you do not yet have an eduID you can create one for free, the system will lead you through the process. More information on eduID here: https://www.eduid.nl/\n\n\n\n\nSRAM login with eduID\n\n\n\nWhen logged in you will be shown a welcome screen in SRAM, click proceed to accept the invitation.\nNow click the “Open” button to go to the Yoda portal.",
    "crumbs": [
      "Yoda Portal",
      "Invitations and logging in"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_portal/yoda_access.html#logging-in-to-the-yoda-portal.",
    "href": "manuals/yoda/yoda_portal/yoda_access.html#logging-in-to-the-yoda-portal.",
    "title": "Invitations and logging in",
    "section": "Logging in to the Yoda portal.",
    "text": "Logging in to the Yoda portal.\nGo to https://portal.yoda.vu.nl/\nLog in using the “Sign in” button. You will be prompted for your email address. Your user name is your primary email address (in lowercase) from your institution or the email address associated with your eduID.\n\n\n\nPortal login\n\n\nClick Next. You will be forwarded to the familiar login page of your institute or eduID.\nVU users: note that instead of the TiQR app you should now use the more user-friendly Azure MFA. Switch by following this instruction manual on the VU SharePoint.\nVU Students might need to visit the Service Desk to enable MFA via SURFsecureID for their student.vu.nl account if they have not done so before. The procedure is explained in this document on the VU services portal.",
    "crumbs": [
      "Yoda Portal",
      "Invitations and logging in"
    ]
  },
  {
    "objectID": "manuals/yoda/index.html",
    "href": "manuals/yoda/index.html",
    "title": "Yoda Manuals",
    "section": "",
    "text": "Tip\n\n\n\nThe Yoda Topic page explains how to request storage space in Yoda for your project.\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\nThe Yoda Web Portal\n\n\n\n\n\n\n\n\n\n\n\n\nInvitations and logging in\n\n\n\n\n\n\n\n\n\n\n\n\nFinding and restoring data\n\n\n\n\n\n\n\n\n\n\n\n\nManaging Groups, Users and Access Rights\n\n\n\n\n\n\n\n\n\n\n\n\nNotifications\n\n\n\n\n\n\n\n\n\n\n\n\nAdding Metadata\n\n\n\n\n\n\n\n\n\n\n\n\nSelecting a license for your dataset\n\n\n\n\n\n\n\n\n\n\n\n\nArchiving data\n\n\n\n\n\n\n\n\n\n\n\n\nPublishing data\n\n\n\n\n\n\n\n\n\n\n\n\nData Transfer overview\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a Data Access Password\n\n\n\n\n\n\n\n\n\n\n\n\nData access on Linux\n\n\n\n\n\n\n\n\n\n\n\n\nData access on MacOS\n\n\n\n\n\n\n\n\n\n\n\n\nData access on Windows\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Cyberduck\n\n\n\n\n\n\n\n\n\n\n\n\nEncrypting your data using Cryptomator and Cyberduck\n\n\n\n\n\n\n\n\n\n\n\n\nUsing icommands\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Rclone\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Webdrive\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Windows Explorer\n\n\n\n\n\n\n\n\n\n\n\n\nUsing WinSCP\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Yoda Manuals"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_webdrive.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_webdrive.html",
    "title": "Using Webdrive",
    "section": "",
    "text": "This page explains how to use WebDrive software, on Windows, to access your data via the Yoda WebDAV interface.\nWindows users can use WebDrive to access their data, as an alternative to the native WebDAV client. With WebDrive the Yoda WebDAV interface can be connected via as a drive in Windows Explorer.\nAs a VU user you can download a licensed version of WebDrive from download.vu.nl.\nNote that you should always disable caching in WebDrive!",
    "crumbs": [
      "Data Transfer",
      "Using Webdrive"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_webdrive.html#using-webdrive",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_webdrive.html#using-webdrive",
    "title": "Using Webdrive",
    "section": "Using WebDrive",
    "text": "Using WebDrive\nStart Webdrive from the Desktop icon or the Start menu.\n\nIn the initial Window click new.\n\nChoose Secure WebDAV and click Next.\n\nEnter https://data.yoda.vu.nl/ in the Url/Address field.\nEnter the Username (an emailaddress). Create a data access password and copy it to the Password field.\nYou can click Test Connection to see if the credentials are correct.\nClick Next\n\nChoose a Drive letter and Connect Now.\n\nYou should now see the Yoda Disk in your Windows Explorer.",
    "crumbs": [
      "Data Transfer",
      "Using Webdrive"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_webdrive.html#disable-the-cache",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_webdrive.html#disable-the-cache",
    "title": "Using Webdrive",
    "section": "Disable the cache",
    "text": "Disable the cache\nBy default WebDrive enables a caching mechanism and suggests this as a way to enable syncing and working offline.\nThis functionality is not implemented very well and you should always disable this to prevent data loss.\n\n\nRight click on “data.yoda.vu.nl” in the server list\n\n\n\nSet Cache Mode to None and Cache Limit to 0.",
    "crumbs": [
      "Data Transfer",
      "Using Webdrive"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html",
    "title": "Data access on Linux",
    "section": "",
    "text": "This page explains how to access your Yoda data via the WebDAV interface on Linux.",
    "crumbs": [
      "Data Transfer",
      "Data access on Linux"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#installing-the-package",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#installing-the-package",
    "title": "Data access on Linux",
    "section": "Installing the package",
    "text": "Installing the package\nInstall the davfs2 package.\nFor Debian/Ubuntu:\nsudo apt -y install davfs2\n\nConfirm that unprivileged users should be able to mount davfs2 volumes (“Yes”). \n\nFor RedHat/CentOS/Fedora:\nsudo yum -y install epel-release\nsudo yum -y install davfs2",
    "crumbs": [
      "Data Transfer",
      "Data access on Linux"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#configuring-group-membership",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#configuring-group-membership",
    "title": "Data access on Linux",
    "section": "Configuring group membership",
    "text": "Configuring group membership\nLook up your user name, uid and gid using the id command.\nAdd your user account to the davfs2 group: sudo usermod -aG davfs2 user (replace “user” with your user name).\nClose the terminal window and open a new one to activate the group change.",
    "crumbs": [
      "Data Transfer",
      "Data access on Linux"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#configuring-davfs2",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#configuring-davfs2",
    "title": "Data access on Linux",
    "section": "Configuring Davfs2",
    "text": "Configuring Davfs2\nOpen the davfs2 configfile in a text editor (e.g. sudo vi /etc/davfs2/davfs2.conf). Ensure parameter delay_upload is set to 0 (zero). This limits the risk of data loss from a failure to flush data after large file transfers.\nOpen the /etc/fstab file in a text editor (e.g. sudo vi /etc/fstab) and add a configuration line for Yoda:\nhttps://data.yoda.vu.nl  /mnt davfs user,auto,uid=1000,gid=1000 0 0\nAnd adjust the parameters as needed: - If you’d like to mount the Yoda in a different location, replace /mnt with a different local directory. - Replace the uid and gid parameters with your uid and gid, as shown by the id command. - If you don’t want Yoda to be mounted automatically after your system starts, remove “auto,” from the options.\nFirst set a Data Access Password.\nNow use a text editor to create a secrets file, which contains your Yoda WebDAV URL, Yoda user name and password, separated by spaces. If you are an employee or student at Vrije Universiteit, your user name is your VU email address (in lowercase) and your password is your Data Access Password. External users have usually received their user name via email, along with a link to set their password. Example of a secrets file:\nhttps://data.yoda.vu.nl xxx@vu.nl  myDataAccessPassword\nYou need to escape any backslashes and double quotes in your password with a backslash (e.g. use \\\\ instead of \\).\nInstall this secrets file as the global davfs2 secrets file:\nsudo install -m 0600 -o root -g root secrets /etc/davfs2/secrets\nrm secrets",
    "crumbs": [
      "Data Transfer",
      "Data access on Linux"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#mounting-the-yoda-webdav-interface",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#mounting-the-yoda-webdav-interface",
    "title": "Data access on Linux",
    "section": "Mounting the Yoda WebDAV interface",
    "text": "Mounting the Yoda WebDAV interface\nThe disk should be mounted automatically after a reboot if you have configured the auto option in /etc/fstab.\nTo manually mount the Yoda WebDAV interface: - On Debian/Ubuntu: mount /mnt - On RedHat/CentOS/Fedora: sudo mount /mnt (you can ignore any warnings about writing to the mtab file)",
    "crumbs": [
      "Data Transfer",
      "Data access on Linux"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#acknowledgements",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_linux.html#acknowledgements",
    "title": "Data access on Linux",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThanks to Joost de Graaf for his contributions to this guide.",
    "crumbs": [
      "Data Transfer",
      "Data access on Linux"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_macos.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_macos.html",
    "title": "Data access on MacOS",
    "section": "",
    "text": "This page explains how to access your Yoda data via the WebDAV interface on MacOS.\nThere are 2 basic ways to access Yoda data from a Mac: Mounting the Yoda WebDAV interface in finder or via file transfer tools, in which case we recommend Cyberduck. Which one works best depends on your workflow.",
    "crumbs": [
      "Data Transfer",
      "Data access on MacOS"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_macos.html#using-cyberduck",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_macos.html#using-cyberduck",
    "title": "Data access on MacOS",
    "section": "Using Cyberduck",
    "text": "Using Cyberduck\nFirst fownload Cyberduck from the VU software center or from the Cyberduck website.\nThen configure Cyberduck using the Information on configuring Cyberduck.",
    "crumbs": [
      "Data Transfer",
      "Data access on MacOS"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_data_macos.html#mounting-the-yoda-webdav-in-finder",
    "href": "manuals/yoda/yoda_data_transfer/yoda_data_macos.html#mounting-the-yoda-webdav-in-finder",
    "title": "Data access on MacOS",
    "section": "Mounting the Yoda WebDAV in Finder",
    "text": "Mounting the Yoda WebDAV in Finder\nYou can open the Yoda WebDAV interface using the Finder app. By default, the Finder icon is shown in the bottom left corner of your screen, in the Dock. Click on this icon.\n\n\n\nFinder icon\n\n\nIf you don’t see the Finder icon, you can alternatively start Finder by pressing the command key and the space bar, then typing “finder” and pressing enter.\nNow press the command key and the “K” key to connect to the Yoda server. You should now see this dialog:\n\n\n\nConnect to server dialog\n\n\nEnter https://data.yoda.vu.nl/ as server address.\nThe Finder app will show a confirmation dialog, similar to the one below. The address shown in the dialog should be the address you entered in the previous dialog.\n\n\n\nConnect to server confirmation dialog\n\n\nPress the Connect button.\n\n\n\nConnect to server confirmation dialog\n\n\nYou should now see a credentials dialog. The “Connect as” setting should be set to “Registered user”. “Name” should be your email address. Create a Data Access Password and copy it to the Password field. Tick the checkbox “Remember this password in my keychain”. Click on the connect button.\nYou should now have a new Yoda location in Finder. Its name is the network address you entered before. You may have to scroll down in finder in order to see it.\n\n\n\nConnect to server credentials dialog",
    "crumbs": [
      "Data Transfer",
      "Data access on MacOS"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/index.html",
    "href": "manuals/yoda/yoda_data_transfer/index.html",
    "title": "Data Transfer overview",
    "section": "",
    "text": "This page provides an overview of the 3 main ways to transfder data to and from Yoda:\n\nVia the Yoda Portal, upload via Drag & Drop, download inviduals files.\n\nThis method works fine if you need to upload small amounts of data.\n\nFor transferring larger amounts of data (tens of GB) it is better to use the WebDAV interface.\n\nThere are several methods to access Yoda data via WebDAV, they depend on the Operating System you are using:\n\nAccessing Yoda data on Windows\nMacOS\nLinux\n\nNote that performance of WebDAV is limited, especially when transferring a large amount of files.\n\nFor transferring large amounts of date (&gt;100GB) consider using direct access to iRODS.\n\nA direct iRODS connection offers better performance by enabling multi-threaded transfers and the option to compare checksums.\nPower users who are comfortable with command line tools can use the iRODS icommands to interact with the iRODS backend of Yoda directly.\nLast updated: ?meta:date",
    "crumbs": [
      "Data Transfer"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck_cryptometer.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck_cryptometer.html",
    "title": "Encrypting your data using Cryptomator and Cyberduck",
    "section": "",
    "text": "This page explains how to connect to use Cyberduck together with Cryptomator to encrypt data stored on Yoda.\nTo work with privacy sensitive data you might be required to encrypt the data you store on Yoda. An easy way to do this is to use Cyberduck (or MountainDuck) together with the free tool Cryptomator.\nCryptomator is available for Windows, MacOS and Linux.\nNote this workflow means local copies of the files on your laptop are not in the encrypted vault. To make sure local files are also safely encrypted you should enable Bitlocker, this should be the case on all VU laptops.",
    "crumbs": [
      "Data Transfer",
      "Encrypting your data using Cryptomator and Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck_cryptometer.html#using-cryptomator",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck_cryptometer.html#using-cryptomator",
    "title": "Encrypting your data using Cryptomator and Cyberduck",
    "section": "Using Cryptomator",
    "text": "Using Cryptomator\nFirst connect to the Yoda WebDAV interface using Cyberduck.",
    "crumbs": [
      "Data Transfer",
      "Encrypting your data using Cryptomator and Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck_cryptometer.html#install-cryptomator",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck_cryptometer.html#install-cryptomator",
    "title": "Encrypting your data using Cryptomator and Cyberduck",
    "section": "Install Cryptomator",
    "text": "Install Cryptomator\nDownload and install from the Cryptomator site.",
    "crumbs": [
      "Data Transfer",
      "Encrypting your data using Cryptomator and Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck_cryptometer.html#create-a-new-cryptomator-vault",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_cyberduck_cryptometer.html#create-a-new-cryptomator-vault",
    "title": "Encrypting your data using Cryptomator and Cyberduck",
    "section": "Create a new Cryptomator vault",
    "text": "Create a new Cryptomator vault\nRight click in Cyberduck and choose “New Encrypted Vault”  Give the folder a name and set a passphrase.\n The vault will look like a normal folder in Cyberduck\n\n\n\nCryptomator folder\n\n\nWhen you doubleclick the new folder you will be asked for the passphrase. \nEnter the correct passphrase and the folder will be opened as normal. You can now work with the vault as with a normal folder.\nIf you cancel the passphrase prompt you will only see the Cryptomator files in the folder. Adding or deleting files could corrupt your data!\nIf you are not prompted for the passphrase click refresh first.",
    "crumbs": [
      "Data Transfer",
      "Encrypting your data using Cryptomator and Cyberduck"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_icommands.html",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_icommands.html",
    "title": "Using icommands",
    "section": "",
    "text": "This page explains how to install the iRODS icommands on a Linux OS (native and using WSL2 on Windows).\nSince Yoda is based on iRODS technology, it is possible to transfer data to and from Yoda using the iRODS communication protocol. This protocol can be used to transfer large amounts of data in an efficient way.\nYou will need to install client software that supports the iRODS protocol on your PC. This page explains how to install and configure the iRODS iCommands. These command line tools are the standard implementation of an iRODS protocol client.",
    "crumbs": [
      "Data Transfer",
      "Using icommands"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_icommands.html#installing-irods-icommands",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_icommands.html#installing-irods-icommands",
    "title": "Using icommands",
    "section": "Installing iRODS iCommands",
    "text": "Installing iRODS iCommands\nNative iRODS iCommands packages are available for CentOS and Ubuntu.\nWindows 10/11 users can run the iCommands in the Windows Subsystem for Linux, we recommend WSL 2. There is no officially supported icommands installation for Mac OSX. You could try https://learning.cyverse.org/ds/icommands/#icommands-installation-for-mac-os-x or install the icommands inside a Linux VM.\n\nInstalling iCommands on CentOS\nOnly the newest version 4.3.0 is supported on CentOS 8, but this should not be a problem:\nsudo yum -y install wget epel-release yum-plugin-versionlock\nsudo rpm --import https://packages.irods.org/irods-signing-key.asc\nwget -qO - https://packages.irods.org/renci-irods.yum.repo | sudo tee /etc/yum.repos.d/renci-irods.yum.repo\nsudo yum -y install irods-runtime-4.3.0 irods-icommands-4.3.0\nsudo yum versionlock irods-runtime irods-icommands\n\n\nInstalling iCommands on Ubuntu\nThe following should work to install the icommands 4.3.0 on Ubuntu 22 or 24.\nwget -qO - https://packages.irods.org/irods-signing-key.asc | sudo apt-key add -\necho \"deb [arch=amd64] https://packages.irods.org/apt/ $(lsb_release -sc) main\" | sudo tee /etc/apt/sources.list.d/renci-irods.list\nsudo apt-get update\nsudo apt install irods-runtime irods-icommands",
    "crumbs": [
      "Data Transfer",
      "Using icommands"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_icommands.html#configuration",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_icommands.html#configuration",
    "title": "Using icommands",
    "section": "Configuration",
    "text": "Configuration\nThe iCommands need to be configured to connect to the right Yoda environment.\nPlease copy and paste this configuration into your ~/.irods/irods_environment.json configuration file.\nYou will need to change the example user name to your Yoda user name.\n{\n    \"irods_host\": \"portal.yoda.vu.nl\",\n    \"irods_port\": 1247,\n    \"irods_home\": \"/vu/home\",\n    \"irods_user_name\": \"xxx@vu.nl\",\n    \"irods_zone_name\": \"vu\",\n    \"irods_authentication_scheme\": \"pam\",\n    \"irods_encryption_algorithm\": \"AES-256-CBC\",\n    \"irods_encryption_key_size\": 32,\n    \"irods_encryption_num_hash_rounds\": 16,\n    \"irods_encryption_salt_size\": 8,\n    \"irods_client_server_negotiation\": \"request_server_negotiation\"\n}",
    "crumbs": [
      "Data Transfer",
      "Using icommands"
    ]
  },
  {
    "objectID": "manuals/yoda/yoda_data_transfer/yoda_using_icommands.html#getting-started-with-icommands",
    "href": "manuals/yoda/yoda_data_transfer/yoda_using_icommands.html#getting-started-with-icommands",
    "title": "Using icommands",
    "section": "Getting started with iCommands",
    "text": "Getting started with iCommands\nAfter installing and configuring the iCommands, you should be able to log in on the Yoda environment using the iinit command. Note that VU users need to set a Data Access Password.\nSections 5.3, 5.4 and 5.5 of the iRODS beginner training contain some examples of how to use the iCommands to transfer and manage files. The iCommands manual",
    "crumbs": [
      "Data Transfer",
      "Using icommands"
    ]
  },
  {
    "objectID": "topics/safe-data-transfer.html",
    "href": "topics/safe-data-transfer.html",
    "title": "Safe Data Transportation and Transfer",
    "section": "",
    "text": "It is important to protect your data during the entire data life cycle. To find out whether your data are secure during all stages of your research, think about your data flow: where do your data originate and where do they go to? If data need to be transported from one physical place to the other, or need to be transferred from one device to another, these actions should happen in a secure way.\n\nTransferring digital data\n\nOnline connection on campus\nIf data collection takes place through a certain measurement device (e.g. MRI scanner, EEG scanner, eye tracker), the data need to be transferred from the measurement device to the storage location that you will use during your research project. Make sure that this transfer takes place in a secure way and also make a plan for the data on the measurement device; find out whether they need to be destroyed or can remain there.\n\n\nOnline connection outside campus (with and without VUnetID)\nIf you are doing fieldwork outside the campus and you have reliable and secure internet access, it is a good idea to upload the data to a storage location that is regularly backed up and secure, in order to prevent data loss. If you have a VUnetID, you can for example use:\n\nResearch Drive to securely and easily store and share research data.\nSURFfilesender to send you data to a colleague or consortium partner, who can store your data in an appropriate place\n\nYou can find more information about each of these storage options in the Data Storage topic.\nIf you need to receive data from colleagues in your project who don’t have access to these tools (e.g. because they are students, don’t work for a Dutch educational institution, or have no VUnetID), Research Drive, Yoda, SURFfilesender and secure emailing with Zivver can also be used:\n\nResearch Drive: This cloud storage service provided by SURF enables researchers from VU and external researchers to manage files and folders in a shared storage location.\nSURFfilesender: as a SURFfilesender user, you can send a voucher to someone who doesn’t have access to this tool. This person can use this voucher to send documents to you. These files can be encrypted.\nYoda: This cloud storage service provided by SURF enables researchers from VU and external researchers to manage files and folders in a shared storage location.\n🔒 Zivver is an email plugin with which you can encrypt emails and attachments.\n\n\n\nOffline data outside campus\nIf you are doing fieldwork in an area with limited internet access, you might use a portable device to initially store your data during the phase of data collection, such as a USB drive or an external hard drive. These data can be transferred to a storage location that is connected to the internet (e.g. Research Drive, Yoda) later. Please make sure that the data on such portable devices are secured, by using encryption (and by transporting them safely by using a lockable briefcase or backpack).\n\n\n\nTransporting physical data\nIf physical objects need to be transported, you should check with the data manager at your department (if available) what options are available. Special briefcases that can be locked or secure backpacks may need to be used to keep informed consent forms or other sensitive data objects (USB drives etc.) secure during transport. A checklist may help to ensure all objects will be taken along.\n\n\nData transportation and transfer across borders\nSome countries have rules to control the movement of encryption technology that enter or exit their borders. If you need to travel with an encrypted laptop to secure your data, for example during fieldwork abroad, please keep this in mind. If you need to transfer data in and out of such countries, please get advice on encryption and secure transportation at the IT Service Desk.\n\n\nSupport\nIf you have general questions about how to protect your data when transporting or transferring them, you can contact the IT Service Desk. In case of complex situations for which you need tailored support, you can consult the IT Relationship Manager representing the research domain, who can request capacity at IT for setting up an information security plan. Such a plan is usually based on documents which need to be completed beforehand, like a Data Protection Impact Assessment and a Data Classification."
  },
  {
    "objectID": "topics/data-registration.html",
    "href": "topics/data-registration.html",
    "title": "Data Registration in PURE",
    "section": "",
    "text": "Just like your publications, data that you have collected for your research constitutes research output, too. Therefore you are required to record your data in PURE.1 Your data can be of interest to others, which can in turn lead to new collaboration opportunities. Data recorded in PURE also appear in reports that are used for research evaluations. Even if access to your data is closed, you are required to register your data in PURE. It is a record of the research, data collection and analysis that you have carried out.\n\n\n\nIt increases the visibility and findability of your data\nIt contributes to re-use and transparency\nIt boosts your collaboration opportunities\nIt counts towards research evaluations and assessments\n\n\n\n\n\n\n\nAn image of PURE, indicating where to add a new dataset\n\n\n\nLog into the VU PURE using your VU credentials\nClick on the “+” (plus) icon next to selecting “Datasets/Software” in the overview\nYou can fill in the form using the following manuals and read more about the various metadata in use (generic and subject specific):\n\ndataset manual (NL)\n\nClick on “Save” to store the registration"
  },
  {
    "objectID": "topics/data-registration.html#register-your-data-in-pure",
    "href": "topics/data-registration.html#register-your-data-in-pure",
    "title": "Data Registration in PURE",
    "section": "",
    "text": "Just like your publications, data that you have collected for your research constitutes research output, too. Therefore you are required to record your data in PURE.1 Your data can be of interest to others, which can in turn lead to new collaboration opportunities. Data recorded in PURE also appear in reports that are used for research evaluations. Even if access to your data is closed, you are required to register your data in PURE. It is a record of the research, data collection and analysis that you have carried out.\n\n\n\nIt increases the visibility and findability of your data\nIt contributes to re-use and transparency\nIt boosts your collaboration opportunities\nIt counts towards research evaluations and assessments\n\n\n\n\n\n\n\nAn image of PURE, indicating where to add a new dataset\n\n\n\nLog into the VU PURE using your VU credentials\nClick on the “+” (plus) icon next to selecting “Datasets/Software” in the overview\nYou can fill in the form using the following manuals and read more about the various metadata in use (generic and subject specific):\n\ndataset manual (NL)\n\nClick on “Save” to store the registration"
  },
  {
    "objectID": "topics/data-registration.html#footnotes",
    "href": "topics/data-registration.html#footnotes",
    "title": "Data Registration in PURE",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“Researchers are responsible for ensuring that a description of archived and published data and software is included in the ‘Current Research Information System’ (CRIS) of VU Amsterdam. In most cases, this is done automatically. Researchers should be able to provide information about data and software in an Availability statement.” Responsibility number 8 from the Research Data and Software Management Policy↩︎"
  },
  {
    "objectID": "topics/data-management-section.html",
    "href": "topics/data-management-section.html",
    "title": "Data Management Section",
    "section": "",
    "text": "Many funders require researchers to include a section in their project proposal about Research Data Management, in which they explain whether existing data will be reused, whether new data will be collected or generated during the project, and how they plan to structure, archive and share their data. Depending on requirements of the funder, the paragraph can be short or more extensive.\nFunders may have different requirements for the data management section in the project proposal. Always check what your funder asks for. Below is a list of information on data management sections from main Dutch funding bodies.\n\nNWO\nZonMw\n\nWe recommend you to ask advice from the RDM Support Desk when writing your data management section."
  },
  {
    "objectID": "topics/researchdrive.html",
    "href": "topics/researchdrive.html",
    "title": "Research Drive",
    "section": "",
    "text": "SURF Research Drive is an online storage and collaboration platform for research data. With Research Drive you can easily store and share files with other researchers, inside and outside VU Amsterdam. You can access your data via a web interface or tools, from anywhere in the world.\nResearch Drive is based on the Open Source ownCloud software and is hosted by SURF in their Amsterdam datacentre."
  },
  {
    "objectID": "topics/researchdrive.html#what-is-it",
    "href": "topics/researchdrive.html#what-is-it",
    "title": "Research Drive",
    "section": "",
    "text": "SURF Research Drive is an online storage and collaboration platform for research data. With Research Drive you can easily store and share files with other researchers, inside and outside VU Amsterdam. You can access your data via a web interface or tools, from anywhere in the world.\nResearch Drive is based on the Open Source ownCloud software and is hosted by SURF in their Amsterdam datacentre."
  },
  {
    "objectID": "topics/researchdrive.html#what-can-it-be-used-for",
    "href": "topics/researchdrive.html#what-can-it-be-used-for",
    "title": "Research Drive",
    "section": "What can it be used for?",
    "text": "What can it be used for?\n\nData storage\nResearch Drive is a Cloud storage solution that can be used for small (a few GBs) to larger (a few TBs) datasets. Because it is a cloud storage platform you will need to download data to your laptop to work with it. Research Drive makes this easy by using the ownCloud client, which allows you to automatically sync the folders you want to work with. Data is backed up daily.\n\n\nData sharing\nAs project owner you can invite internal and external collaborators yourself, or you can delegate this task to others.\nYou can set access rights to folders and subfolders yourself, making Research Drive ideal for use in collaborations with many institutions.\n\n\nSensitive data\nHosting at SURF and the use of Multi Factor Authentication (MFA), among other measures, makes Research Drive suitable for storing data that score Medium on confidentiality (see the Policy Classification of Research Data and the Research Data Classification Tool). Data that score High on confidentiality can be stored in Research Drive with additional security measures. Please make sure to contact the RDM Support Desk to check if further measures are needed.\n\n\nData life cycle\nResearch Drive is meant for data you are actively working with. We recommend to archive datasets that are no longer actively used, but can’t be deleted, in a repository. Transferring data from Research Drive to a repository ensures Research Drive is used optimally and costs are kept down for your research group and VU Amsterdam. Repositories that are available at VU Amsterdam are Yoda and DataverseNL. Yoda is suitable for all types of data, including personal data and other types of confidential data. DataverseNL is only suitable for data that can be made available publicly.\n\n\nCollaborative tools\nWithin Research Drive, various apps and integrations are available to simplify the use and handling of research data, such as a tool to edit documents directly in the web interface. You can find a current list of app integrations on the SURF User Knowledge Base.\n\n\nSURFdrive replacement\nSince both are based on ownCloud, Research Drive is very similar to SURFdrive, the main difference is that SURFdrive is personal storage while Research Drive is group based.\nResearchers looking for a new home for research data currently on SURFdrive are encouraged to migrate to Research Drive. Manuals for migrating data to Research Drive are available in English and Dutch. Please contact the Research Support Desk if you have any questions about migrating to Research Drive."
  },
  {
    "objectID": "topics/researchdrive.html#how-to-request-access",
    "href": "topics/researchdrive.html#how-to-request-access",
    "title": "Research Drive",
    "section": "How to request access",
    "text": "How to request access\nA new Research Drive projectfolder can be requested via the form on 🔒 ServiceNow, go to: Research Data Support &gt; Research Data Support &gt; Request Research Drive.\nOnce the projectfolder is created you can invite internal and external collaborators yourself."
  },
  {
    "objectID": "topics/researchdrive.html#are-there-costs-involved",
    "href": "topics/researchdrive.html#are-there-costs-involved",
    "title": "Research Drive",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThe costs of storing data in Research Drive are detailed on the 🔒 VU website."
  },
  {
    "objectID": "topics/researchdrive.html#getting-started",
    "href": "topics/researchdrive.html#getting-started",
    "title": "Research Drive",
    "section": "Getting started",
    "text": "Getting started\n\nLog in to the Research Drive web application at vu.data.surfsara.nl. You are only able to log in after you have been invited to one or more project folders. The login process requires a Multi-Factor Authentication (MFA) account, which students do not have by default. If you do not yet have an MFA account, you can, as a VU student, researcher or employee, request an account at the IT Servicedesk in the main building with a legitimate ID.\nInstall the ownCloud Client software, you can find installation instructions on the SURF User Knowledge Base. The Server Address is https://vu.data.surfsara.nl.\n\nFor transferring large amounts of data Rclone is good option. The SURF User Knowledge Base explains how.\nRclone can also be used to mount (make accessible via a drive letter in Windows) a Research Drive folder. This means you can directly access the data from tools such as R, without downloading the entire dataset first. This method has some limitations, but should work fine with smaller datasets (a few GB).\nThe SURF User Knowledge Base contains more Tutorials on working with Research Drive."
  },
  {
    "objectID": "topics/researchdrive.html#contact",
    "href": "topics/researchdrive.html#contact",
    "title": "Research Drive",
    "section": "Contact",
    "text": "Contact\nWondering if Research Drive fits your research needs? Please contact the Research Support Desk."
  },
  {
    "objectID": "topics/persistent-identifier.html",
    "href": "topics/persistent-identifier.html",
    "title": "Persistent Identifier",
    "section": "",
    "text": "A Persistent Identifier (PID) is a durable reference to a digital dataset, document, website or other object. In the context of research data and software, it is essentially a URL that will never break. By using a Persistent Identifier, you make sure that your dataset will be findable well into the future when it is registered online (for example at DataCite. Another advantage is that it makes a digital object citable."
  },
  {
    "objectID": "topics/persistent-identifier.html#multiple-pid-systems",
    "href": "topics/persistent-identifier.html#multiple-pid-systems",
    "title": "Persistent Identifier",
    "section": "Multiple PID systems",
    "text": "Multiple PID systems\nThere are multiple PID systems, each with its own particular properties. Examples of widely used PIDs in the research domain include the following.\n\nDOI: A Digital Object Identifier can be used to refer to research data, research software and publications.\nORCiD: An Open Researcher and Contributor ID is used to create a researcher profile with a unique identification number.\nROR: The Research Organization Registry is a global register with persistent identifiers for research institutes.\n\nSee the Persistent Identifier guide of Netwerk Digitaal Erfgoed for a more elaborate overview. Apart from widely used domain-agnostic PIDs, there is a wide range of domain-specific unique identifiers that can be used. If you are interested in domain-specific identifiers, it is useful to ask colleagues in your department or discipline."
  },
  {
    "objectID": "topics/persistent-identifier.html#persistent-identifiers-for-data-and-software-in-repositories",
    "href": "topics/persistent-identifier.html#persistent-identifiers-for-data-and-software-in-repositories",
    "title": "Persistent Identifier",
    "section": "Persistent Identifiers for data and software in repositories",
    "text": "Persistent Identifiers for data and software in repositories\nPersistent Identifiers can be assigned to datasets and software upon their deposit in a repository. In many repositories, this is a DOI. Data repositories are entitled to generate Persistent Identifiers for data and software. This is one of the reasons why archiving and publishing data and software has to be done in a repository. After the process of uploading data or software to a repository, a Persistent Identifier will be generated. Upon publishing the data or software, the DOI is registered online (usually at DataCite when it concerns a dataset).\nSome repositories enable their users to reserve a Persistent Identifier before the publishing process has finished, so that you can include the Persistent Identifier in a publication before the data will be actually published, or to include the Persistent Identifier in a readme file. This is for example possible in Zenodo.\nThe repositories offered by VU Amsterdam, Yoda and DataverseNL provide DOIs for deposited datasets and software."
  },
  {
    "objectID": "topics/persistent-identifier.html#creating-and-using-an-orcid",
    "href": "topics/persistent-identifier.html#creating-and-using-an-orcid",
    "title": "Persistent Identifier",
    "section": "Creating and using an ORCiD",
    "text": "Creating and using an ORCiD\nResearchers can use an ORCiD to identify their research output as their work. You can request an ORCiD yourself. Instructions for setting up an ORCiD and connecting it to your VU research profile in PURE are available in this ORCiD LibGuide. An ORCiD is often asked for when you submit a publication or upload data or software to a repository. You can use your ORCiD record to create a research profile as well."
  },
  {
    "objectID": "topics/persistent-identifier.html#using-a-ror",
    "href": "topics/persistent-identifier.html#using-a-ror",
    "title": "Persistent Identifier",
    "section": "Using a ROR",
    "text": "Using a ROR\nResearchers can use the ROR for VU Amsterdam when filling metadata forms for their research output to show that their work has been created within their employment at VU Amsterdam."
  },
  {
    "objectID": "topics/software-registration.html",
    "href": "topics/software-registration.html",
    "title": "Software Registration in PURE",
    "section": "",
    "text": "Just like your publications, research sofware that you have developed for your research constitutes research output, too. Therefore you are required to record your research software in PURE.1 Your research software can be of interest to others, which can in turn lead to new collaboration opportunities. Research software recorded in PURE also appears in reports that are used for research evaluations. Even if access to your research software is closed, you are required to register your research software in PURE. It is a record of the work that you have carried out.\n\n\n\nIt increases the visibility and findability of your research software\nIt contributes to re-use and transparency\nIt boosts your collaboration opportunities\nIt counts towards research evaluations and assessments\n\n\n\n\n\n\n\nAn image of PURE, indicating where to add new software\n\n\n\nLog into the VU PURE using your VU credentials\nClick on the “+” (plus) icon next to selecting “Datasets/Software” in the overview\nYou can fill in the form using the following manual and read more about the various metadata in use (generic and subject specific):\n\nsoftware manual (EN)\n\nClick on “Save” to store the registration"
  },
  {
    "objectID": "topics/software-registration.html#register-software-in-pure",
    "href": "topics/software-registration.html#register-software-in-pure",
    "title": "Software Registration in PURE",
    "section": "",
    "text": "Just like your publications, research sofware that you have developed for your research constitutes research output, too. Therefore you are required to record your research software in PURE.1 Your research software can be of interest to others, which can in turn lead to new collaboration opportunities. Research software recorded in PURE also appears in reports that are used for research evaluations. Even if access to your research software is closed, you are required to register your research software in PURE. It is a record of the work that you have carried out.\n\n\n\nIt increases the visibility and findability of your research software\nIt contributes to re-use and transparency\nIt boosts your collaboration opportunities\nIt counts towards research evaluations and assessments\n\n\n\n\n\n\n\nAn image of PURE, indicating where to add new software\n\n\n\nLog into the VU PURE using your VU credentials\nClick on the “+” (plus) icon next to selecting “Datasets/Software” in the overview\nYou can fill in the form using the following manual and read more about the various metadata in use (generic and subject specific):\n\nsoftware manual (EN)\n\nClick on “Save” to store the registration"
  },
  {
    "objectID": "topics/software-registration.html#footnotes",
    "href": "topics/software-registration.html#footnotes",
    "title": "Software Registration in PURE",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“Researchers are responsible for ensuring that a description of archived and published data and software is included in the ‘Current Research Information System’ (CRIS) of VU Amsterdam. In most cases, this is done automatically. Researchers should be able to provide information about data and software in an Availability statement.” Responsibility number 8 from the Research Data and Software Management Policy↩︎"
  },
  {
    "objectID": "topics/dataversenl.html",
    "href": "topics/dataversenl.html",
    "title": "DataverseNL",
    "section": "",
    "text": "DataverseNL is an Open Access dataset archiving and publication platform used by various institutions. VU Amsterdam has a section for each faculty to archive and publish their datasets.\nDataverseNL helps the researcher make their data “FAIR” by providing a solution that enables data discovery and sharing (i.e., findable, accessible). In addition, it facilitates the use of metadata, contributing to data interoperability and reusability. DataverseNL provides a platform for the implementation of standard workflows that can ensure metadata quality satisfying VU policy requirements for data archiving and publication. Many research institutions and funding organisations (such as NWO and ZonMw) require researchers to make their data FAIR.\nDataverseNL is open source software developed and maintained by Harvard University. The Dutch version is hosted by DANS."
  },
  {
    "objectID": "topics/dataversenl.html#what-is-it",
    "href": "topics/dataversenl.html#what-is-it",
    "title": "DataverseNL",
    "section": "",
    "text": "DataverseNL is an Open Access dataset archiving and publication platform used by various institutions. VU Amsterdam has a section for each faculty to archive and publish their datasets.\nDataverseNL helps the researcher make their data “FAIR” by providing a solution that enables data discovery and sharing (i.e., findable, accessible). In addition, it facilitates the use of metadata, contributing to data interoperability and reusability. DataverseNL provides a platform for the implementation of standard workflows that can ensure metadata quality satisfying VU policy requirements for data archiving and publication. Many research institutions and funding organisations (such as NWO and ZonMw) require researchers to make their data FAIR.\nDataverseNL is open source software developed and maintained by Harvard University. The Dutch version is hosted by DANS."
  },
  {
    "objectID": "topics/dataversenl.html#what-can-it-be-used-for",
    "href": "topics/dataversenl.html#what-can-it-be-used-for",
    "title": "DataverseNL",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nDataverseNL is a simple method to archive and publish datasets. Through the platform it becomes very easy to share data and documents from your research. The platforms generates a webpage displaying your data and accompanying metadata, and a Digital Object Identifier (DOI) which enables increased visibility and quick references to your dataset. It is possible to make files within your dataset only accessible on request. Please note that DataverseNL is only suitable for archiving and publishing datasets that do not contain personal data or other types of confidential data. Even though access to data files in DataverseNL can be restricted, datasets containing personal data or other types of confidential data must not be uploaded to DataverseNL. A suitable repository for archiving and publishing personal and sensitive data is Yoda.\n\nData storage\nDataverseNL is a Cloud storage solution that can be used for small to large datasets. The datasets are preserved through backup copies of the data.\n\n\nData sharing\nThrough the generated DOI you can make your dataset easy to find and access. You can reference it in your publications and through your profile page on the VU Research Portal (PURE).\n\n\nSensitive data\nAlthough DataverseNL is meant for Open Access datasets, it is possible to restrict access to particular files. This means it is possible to archive medium sensitive (anonymised) data. As explained above, personal data or other types of confidential data that score High or Very High on confidentiality (see the Policy Classification of Research Data and the Research Data Classification Tool) must not be uploaded to DataverseNL. Data that score High or Very High on confidentiality can be archived and published in Yoda.\n\n\nMetadata\nYou can add descriptive metadata to a dataset draft in DataverseNL. After publication of the dataset it is still possible to alter the metadata, but this will result in a new version of the dataset. If you feel metadata fields are missing, a request can be sent to SURF to add these fields. The requirement for this change is that the added metadata fields are part of an internationally recognised dataset metadata scheme."
  },
  {
    "objectID": "topics/dataversenl.html#how-to-request-access",
    "href": "topics/dataversenl.html#how-to-request-access",
    "title": "DataverseNL",
    "section": "How to request access",
    "text": "How to request access\n\nUploading data\nAll VU employees can create an account in DataverseNL and upload and publish datasets. When you wish to upload data to DataverseNL, it is important to select your faculty or department. If you want to upload your dataset as part of a certain department, and your department is not yet included in DataverseNL, you can contact the DataverseNL manager to request your department to be added. You can use the Contact button in DataverseNL to submit such a request.\n\n\nViewing and reusing data\nData that are publicly available, are visible and downloadable for everyone.\nIf a dataset includes files with restricted access, people interested in the data have to create an account in DataverseNL to be able to request access to those files. The contact person for the dataset needs to grant access in order for others to use the data."
  },
  {
    "objectID": "topics/dataversenl.html#are-there-costs-involved",
    "href": "topics/dataversenl.html#are-there-costs-involved",
    "title": "DataverseNL",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThe costs for archiving datasets for the required period stated in the Research Data and Software Management Policy are currently covered through the Cost Recharge Model (KDM). The details can be found in the 🔒 Research Archiving & Storage Cost Model."
  },
  {
    "objectID": "topics/dataversenl.html#getting-started",
    "href": "topics/dataversenl.html#getting-started",
    "title": "DataverseNL",
    "section": "Getting Started",
    "text": "Getting Started\nThe DataverseNL website has practical information in their User Guide."
  },
  {
    "objectID": "topics/dataversenl.html#contact",
    "href": "topics/dataversenl.html#contact",
    "title": "DataverseNL",
    "section": "Contact",
    "text": "Contact\nWondering if DataverseNL fits your research needs? Please contact the RDM support desk."
  },
  {
    "objectID": "topics/care-principles.html",
    "href": "topics/care-principles.html",
    "title": "CARE Principles",
    "section": "",
    "text": "The CARE Principles for Indigenous Data Governance are a set of guidelines that complement the FAIR principles by focusing on people and purpose in data management, particularly for Indigenous data. CARE stands for Collective benefit, Authority to control, Responsibility, and Ethics. These principles were developed by the Global Indigenous Data Alliance to ensure that data practices support Indigenous communities’ self-determination and promote equitable outcomes for Indigenous peoples.\nWhile originally developed for Indigenous data, the CARE principles have broader applicability to research involving any communities or populations, particularly those that have been historically marginalised or disadvantaged. They emphasise community engagement, ethical responsibility, and the importance of ensuring that data use benefits the communities from which data originate."
  },
  {
    "objectID": "topics/care-principles.html#what-are-the-care-principles",
    "href": "topics/care-principles.html#what-are-the-care-principles",
    "title": "CARE Principles",
    "section": "",
    "text": "The CARE Principles for Indigenous Data Governance are a set of guidelines that complement the FAIR principles by focusing on people and purpose in data management, particularly for Indigenous data. CARE stands for Collective benefit, Authority to control, Responsibility, and Ethics. These principles were developed by the Global Indigenous Data Alliance to ensure that data practices support Indigenous communities’ self-determination and promote equitable outcomes for Indigenous peoples.\nWhile originally developed for Indigenous data, the CARE principles have broader applicability to research involving any communities or populations, particularly those that have been historically marginalised or disadvantaged. They emphasise community engagement, ethical responsibility, and the importance of ensuring that data use benefits the communities from which data originate."
  },
  {
    "objectID": "topics/care-principles.html#the-care-principles",
    "href": "topics/care-principles.html#the-care-principles",
    "title": "CARE Principles",
    "section": "The CARE principles",
    "text": "The CARE principles\nThe CARE principles encompass four key areas:\n\nCollective Benefit\nData ecosystems shall be designed and function in ways that enable Indigenous Peoples to derive benefit from the data. This is specified in the following ways:\n\nInclusive development and innovation: Data should support Indigenous innovation and generate value for Indigenous communities. Use and reuse of data by Indigenous Peoples should be enabled and stimulated by governments and research institutions.\nCommunity value creation: Data ecosystems should be designed to support Indigenous communities’ self-determination and collective benefit, and to foster transparency, engagement and understanding between Indigenous Peoples and their (local) governments and policymakers.\nEquitable outcomes: Data use should promote equitable outcomes for Indigenous peoples and communities and contribute to Indigenous aspirations for wellbeing.\n\n\n\nAuthority to Control\nIndigenous Peoples’ must have the right and authority to control their data and how they and information about them are represented in data. This is specified further as follows:\n\nRights recognition: Indigenous Peoples have inherent rights and interests relating to Indigenous data and to individual and collective Free, Prior and Informed Consent (FPIC).\nData for governance: Indigenous Peoples have the right to (access to) data that empower their world-view, self-determination and self-governance.\nGovernance of data: Indigenous Peoples have the right to determine what happens to their data.\n\n\n\nResponsibility\nThose working with Indigenous data are responsible for showing that the data use supports and benefits Indigenous Peoples. They also have to be transparent about how the data are used. This is specified as follows:\n\nPositive relationships: Researchers and data users should build respectful, trusted and reciprocal relationships with Indigenous Communities.\nFor expanding capability and capacity: Those working with the data should support Indigenous Peoples’ capacity to work with data capability to develop infrastructure for data.\nFor Indigenous languages and worldviews: Those working with the data should provide resources that enable generating and collecting data in Indigenous languages and cultural contexts.\n\n\n\nEthics\nIndigenous People’s rights and wellbeing should be the primary concern for data users during the entire data lifecycle. This is specified in the following points:\n\nMinimising harm and maximising benefit: Data use should minimise harm and risks to Indigenous communities and should be collected and used according to Indigenous Peoples’ frameworks. Benefits should be assessed based on Indigenous Peoples’ perspectives.\nJustice: Data practices should promote justice and representation for Indigenous Peoples\nFuture use: Data governance must include considerations for future use and prevent potential future misuse of data according to the Indigenous People’s frameworks."
  },
  {
    "objectID": "topics/care-principles.html#implementation-of-the-care-principles",
    "href": "topics/care-principles.html#implementation-of-the-care-principles",
    "title": "CARE Principles",
    "section": "Implementation of the CARE principles",
    "text": "Implementation of the CARE principles\nLike the FAIR principles, the CARE principles must be implemented consciously and conscientiously, and specific effort must be made to support them in research-performing institutions. That said, it is important to emphasise that the purpose of the CARE principles is fundamentally different from the FAIR principles. The FAIR principles aim to promote transparency and maximum data reuse potential, which can create an image of data as a neutral, independent entity. Under the CARE principles, data collected by/with/about Indigenous Peoples are understood as fundamentally tied to these Indigenous Peoples and the CARE principles underscore their ownership, authority and rights to the data. While data reuse can occur and/or be beneficial for Indigenous Peoples data, it is not always the best outcome or the primary aim.\nIn the context of the Netherlands research-performing institutions could consider the following to support researchers with implementing the CARE principles:\n\nMaking researchers aware of the CARE principles and helping them to find resources for their application in their field.\nSupporting international working groups and alliances that develop the CARE principles further, such as the Global Indigenous Data Alliance and the Research Data Alliance (RDA’s) International Indigenous Data Sovereignty Interest Group.\nMaking Indigenous data FAIR, bearing in mind the considerations outlined above.\nApplying the CARE principles to their own collections and services.\n\n\nIndigenous data in university (library) collections\nUniversities and other research-performing institutions may already be holding data concerning Indigenous Peoples, whether they be research data or archives or objects in a university library’s (special) collections. This means that universities and university libraries have responsibilities with regards to the CARE principles.\nWhere research data are concerned, it is mostly important to ensure that free, prior and informed consent was given for the data to be collected and/or published, and that the data were also initially shared with the Indigenous People from which they originated. At VU Amsterdam, data stewards already have experience with similar processes around (regular) personal data. If you find that you are working with, or your department holds datasets to which the CARE principles apply, and you have questions about how they should be handled, your first point of contact may be the RDM Support Desk or your faculty’s data steward.\nLibrary (special) collections may also require some care, especially if researchers would like to use them. At the 2025 LIBER Conference in Lausanne (Switzerland) a roundtable comprising of librarians who specialise in Indigenous Knowledges and/or had an Indigenous background discussed the ways libraries can incorporate Indigenous Knowledges and collections in their services while taking the CARE principles into account. The roundtable highlighted the fact that Indigenous Peoples may historically not have been included in libraries’ collection development and collection access, and that due to a historical legacy of colonialism and racism, existing library catalogues may contain terms and descriptions that are inaccurate, offensive and harmful. The roundtable further raised that library staff need to be more aware of these issues in managing their collections. To actively engage with some of these concerns, the VU University Library started a project to revisit descriptions of works in the library catalogue through the lens of decolonisation. In this way, the project tries to contribute to a more inclusive library environment for diverse users."
  },
  {
    "objectID": "topics/care-principles.html#sources-and-resources",
    "href": "topics/care-principles.html#sources-and-resources",
    "title": "CARE Principles",
    "section": "Sources and resources",
    "text": "Sources and resources\n\nThe definitions of the CARE principles were taken from: Research Data Alliance International Indigenous Data Sovereignty Interest Group. (September 2019). “CARE Principles for Indigenous Data Governance.” The Global Indigenous Data Alliance. GIDA-global.org. More in-depth information can be found there.\nThe recommendations for implementation of the CARE principles were taken from: Carroll, S.R., Herczog, E., Hudson, M. et al. Operationalizing the CARE and FAIR Principles for Indigenous data futures. Sci Data 8, 108 (2021). https://doi.org/10.1038/s41597-021-00892-0.\nPractical examples of implementation of the CARE principles are given in: Carroll, S, et al. 2020. The CARE Principles for Indigenous Data Governance. Data Science Journal, 19: XX, pp. 1–12. DOI: https://doi.org/10.5334/dsj-2020-042.\nThe programme of the 2025 LIBER Conference, with the description of the roundtable on page 158.\nA presentation on the project at the VU University Library to remove harmful subject headings in the catalogue was also given at the 2024 LIBER Conference."
  },
  {
    "objectID": "topics/care-principles.html#ai-statement",
    "href": "topics/care-principles.html#ai-statement",
    "title": "CARE Principles",
    "section": "AI statement",
    "text": "AI statement\nA first draft of this text was written by Claude LLM. It was subsequently edited and rewritten by Handbook editors."
  },
  {
    "objectID": "topics/ada.html",
    "href": "topics/ada.html",
    "title": "ADA HPC",
    "section": "",
    "text": "ADA is a high performance compute (HPC) cluster for research at the Vrije Universiteit Amsterdam. ADA is named in honour of Ada Lovelace, the pioneering mathematician and writer known for her work on Charles Babbage’s Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation. ADA is the rebranded name of our previous cluster, BAZIS, and is maintained by the IT for Research team.\nADA is a heterogenious cluster composed of partitions and servers financed by various VU research departments and the VU IT department. The cluster is particularly useful for executing multi-node computations that are not possible on the general VU compute servers but do not require the scale of the National Supercomputer, Snellius.\nADA users are granted access to a set of compute partitions based on the resources owned by their research department. Users not affiliated with a research department that owns cluster hardware can get access to the community partition.\nA large collection of tools, compilers and libraries is available for your analysis, and your data on SciStor are directly accessible from ADA."
  },
  {
    "objectID": "topics/ada.html#what-is-it",
    "href": "topics/ada.html#what-is-it",
    "title": "ADA HPC",
    "section": "",
    "text": "ADA is a high performance compute (HPC) cluster for research at the Vrije Universiteit Amsterdam. ADA is named in honour of Ada Lovelace, the pioneering mathematician and writer known for her work on Charles Babbage’s Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation. ADA is the rebranded name of our previous cluster, BAZIS, and is maintained by the IT for Research team.\nADA is a heterogenious cluster composed of partitions and servers financed by various VU research departments and the VU IT department. The cluster is particularly useful for executing multi-node computations that are not possible on the general VU compute servers but do not require the scale of the National Supercomputer, Snellius.\nADA users are granted access to a set of compute partitions based on the resources owned by their research department. Users not affiliated with a research department that owns cluster hardware can get access to the community partition.\nA large collection of tools, compilers and libraries is available for your analysis, and your data on SciStor are directly accessible from ADA."
  },
  {
    "objectID": "topics/ada.html#what-can-it-be-used-for",
    "href": "topics/ada.html#what-can-it-be-used-for",
    "title": "ADA HPC",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nMost researchers start out by running their analysis tools on their laptop. The performance of a laptop is limited however. You might find your analysis takes up so many resources that your laptop becomes unusable for other tasks, or tasks take so long that you have to find a way to keep your laptop running overnight. For example a lot of AI tasks, such as running Large Language Models (LLMs), require a dedicated GPU, which most laptops don’t have. These tasks will run very slowly, or not at all.\nA next step might be purchasing a Workstation with more performance and maybe a GPU. You can run the same applications as your laptop and leave it running overnight and during weekends. The modern VU offices are not geared for workstations, however, so that might not be possible.\nThe point where your laptop or even a workstation becomes unusable for your analysis workflow is when you should consider HPC. HPC nodes have a large amount of RAM, many processor cores and often multiple GPUs. HPC clusters work with a queueing system, meaning the system will wait until enough resources are available to run your job and it will run multiple jobs simultaneously so its resources are used optimally.\nBe aware that it is generally not possible to run graphical desktop applications (such as RStudio, SPSS or ArcGIS) on an HPC cluster. Your analysis needs to be able to run as a script that can be started from a Linux command line. This means there is a learning curve to use HPC, especially if you are not used to a Command-line Interface (CLI) and scripting.\nCLI and scripting skills are very useful to have for every researcher, but if you feel you do not have the time to learn these skills there might be other options available such as the VU Compute Hub or SURF Research Cloud where you can run some graphical tools.\n\nGPUs in ADA\nSome workloads, such as Machine Learning, require a GPU. At the moment only some of the compute nodes in the ADA community partition have GPUs, the availability is not sufficient for everyone at any given time. If your workload requires more extensive use of GPUs and your department has no dedicated compute nodes with GPUs, you can apply for access to the national HPC infrastructure Snellius or consider buying ADA compute nodes with GPUs for your department."
  },
  {
    "objectID": "topics/ada.html#how-to-request-access",
    "href": "topics/ada.html#how-to-request-access",
    "title": "ADA HPC",
    "section": "How to request access",
    "text": "How to request access\nA form to request an account on ADA can be found on 🔒 VU Service Portal under IT &gt; My work field &gt; Research &gt; HPC Cluster Computing &gt; New ADA HPC Cluster Computing."
  },
  {
    "objectID": "topics/ada.html#are-there-costs-involved",
    "href": "topics/ada.html#are-there-costs-involved",
    "title": "ADA HPC",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThe ADA cluster community nodes are free to use for VU researchers, although resources are limited.\n\nBuying dedicated compute nodes\nIf your research projects require heavy usage of HPC you can consider spending part of your research budget to buy compute hardware for your group. Please contact IT for Research for more information on what is possible."
  },
  {
    "objectID": "topics/ada.html#getting-started",
    "href": "topics/ada.html#getting-started",
    "title": "ADA HPC",
    "section": "Getting started",
    "text": "Getting started\nYou can find information on how to use ADA on ada-hpc.readthedocs.io.\nAlso take a look at the SURF wiki Snellius pages, they contain a lot of information that applies to ADA as well.\nSURF organises regular “Introduction to Supercomputing” training sessions, these are free to attend for VU researchers. The course is aimed at using Snellius, but what you learn is applicable to ADA as well. Please consult the SURF Agenda for dates and registration."
  },
  {
    "objectID": "topics/ada.html#contact",
    "href": "topics/ada.html#contact",
    "title": "ADA HPC",
    "section": "Contact",
    "text": "Contact\nWondering if ADA fits your research needs? Please contact IT for Research"
  },
  {
    "objectID": "topics/trainings.html",
    "href": "topics/trainings.html",
    "title": "Trainings",
    "section": "",
    "text": "It is easy to get overwhelmed with all the trainings available. On this page we provide a list of trainings available."
  },
  {
    "objectID": "topics/trainings.html#bytes-and-bites",
    "href": "topics/trainings.html#bytes-and-bites",
    "title": "Trainings",
    "section": "Bytes and Bites",
    "text": "Bytes and Bites\nDo you want to meet other researchers, improve your programming skills, or ask questions related to programming? Pick up your laptop and come to Bytes & Bites. We’re back in full swing for another edition of our coding cafe Bytes & Bites. At Bytes & Bites anyone is welcome, whether you are a beginner or advanced programmer, whether you write in R or in C++. And of course, you can’t program and work with “Bytes” without any tasty “Bites”! We’ll make sure there is pizza or snacks available!\n\n\nMore information: https://ubvu.github.io/bytes-and-bites/\nTopics: Programming, Python, R, Community, Software, Coding\nTarget audience: Students, researchers, data stewards\nStatus: Monthly\nDuration: 120 minutes\nOnline/in-person: In-person"
  },
  {
    "objectID": "topics/trainings.html#data-analysis-with-r-data-carpentry-workshop-for-programming-beginners",
    "href": "topics/trainings.html#data-analysis-with-r-data-carpentry-workshop-for-programming-beginners",
    "title": "Trainings",
    "section": "Data Analysis with R — Data Carpentry workshop for programming beginners",
    "text": "Data Analysis with R — Data Carpentry workshop for programming beginners\nAre you analysing tabular data in your research? Would you like to learn how to use the programming language R to make your work more effective and efficient? This workshop is for absolute programming beginners and introduces basic steps for the analysis and visualization of tabular data with R Studio. You will:\n\nOrganize tabular data, handle date formatting, carry out quality control and quality assurance and export data to use with downstream applications.\nExplore, summarize, and clean tabular data reproducibly.\nImport data, calculate summary statistics, and create publication-quality graphics using the programming language R\n\n\n\nRegistration form: https://vu-nl.libcal.com/calendar/universitylibrary?t=g&q=data%20carpentry&cid=7052&cal=7052&inc=0\nTraining materials: https://datacarpentry.org/lessons/#social-science-curriculum\nTopics: Software skills, Data analysis, Plotting, R, OpenRefine, Spreadsheets\nTarget audience: Researchers, students\nStatus: Available on set moments\nDuration: 28 hours over four days\nOnline/in-person: In-person and online (self-study)"
  },
  {
    "objectID": "topics/trainings.html#escape-room-data-horror",
    "href": "topics/trainings.html#escape-room-data-horror",
    "title": "Trainings",
    "section": "Escape Room: Data Horror",
    "text": "Escape Room: Data Horror\nResolve the data horror of professor Hutseephluts and secure the grant! This online escape room challenges everyone to tackle the horrors of research data management. Will you be able to escape within an hour?\nThe Data Horror Escape Room was made for the Data Horror week 2020.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.6949510\nLicence: CC-BY-SA-4.0\nTopics: Research data, Escape room, Workshop, Data management, Research data management, FAIR\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 60 minutes\nOnline/in-person: Online"
  },
  {
    "objectID": "topics/trainings.html#escape-room-open-science-horror",
    "href": "topics/trainings.html#escape-room-open-science-horror",
    "title": "Trainings",
    "section": "Escape Room: Open Science Horror",
    "text": "Escape Room: Open Science Horror\nHelp the cyborgs by publishing their code the right way — the open science way! This online escape room challenges everyone to tackle the horrors of open science and open access publishing. Will you be able to save the cyborgs and finally get a coffee?\nThe Open Science Horror Escape Room was made for the Data Horror week 2021.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.6963493\nLicence: CC-BY-4.0\nTopics: Open science, Escape room, Workshop, Open access, Research data management, FAIR\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 30-60 minutes\nOnline/in-person: Online"
  },
  {
    "objectID": "topics/trainings.html#escape-room-software-horror",
    "href": "topics/trainings.html#escape-room-software-horror",
    "title": "Trainings",
    "section": "Escape Room: Software Horror",
    "text": "Escape Room: Software Horror\nThe only thing between you and certain doom — getting your software management in order! This online escape room challenges everyone to tackle the horrors of software management and open software publishing. Will you be able to save your own soul and publish in Frontiers in Hell?\nThe Software Horror Escape Room was made for the Data Horror week 2022.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.7350527\nLicence: CC-BY-4.0\nTopics: Software management, Escape room, Workshop, Software, Research data management, FAIR,\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 60 minutes\nOnline/in-person: Online"
  },
  {
    "objectID": "topics/trainings.html#lego-workshop",
    "href": "topics/trainings.html#lego-workshop",
    "title": "Trainings",
    "section": "Lego Workshop",
    "text": "Lego Workshop\nThis workshop offers a hands-on experience in the importance of careful documentation during research. Participants will discover the pitfalls in communicating research progress through written media. This offers a fun introduction in writing well structured contextual metadata such as research logs, protocols, machine settings and general README files.\nThe data package offers a powerpoint and general guidelines in hosting the workshop.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.10174000\nLicence: CC-BY-4.0\nTopics: Metadata, Contextual metadata, LEGO, Workshop\nTarget audience: Researchers\nStatus: Active\nDuration: 30-90 minutes\nOnline/in-person: In-person"
  },
  {
    "objectID": "topics/trainings.html#open-science-framework-osf-workshop",
    "href": "topics/trainings.html#open-science-framework-osf-workshop",
    "title": "Trainings",
    "section": "Open Science Framework (OSF) Workshop",
    "text": "Open Science Framework (OSF) Workshop\nThis is a hands-on course to get started with the Open Science Framework (OSF). You won’t need any experience with the tool beforehand. We will show the differences and similarities between OSF and other tools at VU Amsterdam (such as Yoda). We will make a preregistration of a (mock) OSF research.\nThe OSF is an open-source project management tool that supports researchers throughout their entire project life cycle. As a collaboration tool, OSF helps research teams work on projects privately or make the whole project publicly accessible for broad dissemination. As a workflow system, OSF enables connections to the many scientific tools researchers already use, streamlining their process and increasing efficiency. You may even use OSF as a portfolio tool for sharing your work as a prepublication with potential collaborators.\n\n\nRegistration form: https://vu-nl.libcal.com/calendar/universitylibrary?t=g&q=osf&cid=7052&cal=7052&inc=0\nTraining materials: https://osf.io/ab923/\nTopics: OSF, Preprint, Publishing, Archiving, RDM tools, Data management\nTarget audience: Students, researchers, data stewards\nStatus: Bi-annually during the Support Training Days\nDuration: 120 minutes\nOnline/in-person: Online"
  },
  {
    "objectID": "topics/trainings.html#open-science-against-humanity",
    "href": "topics/trainings.html#open-science-against-humanity",
    "title": "Trainings",
    "section": "Open Science against Humanity",
    "text": "Open Science against Humanity\nThis card game is based on “Cards Against Humanity” and teaches basic concepts of Open Science, Research Data Management, Software Management, FAIR principles, and Research Ethics in a fun and entertaining way. The white cards describe research related situations or statements relevant for researchers. The black cards contain potential answers or prompts that have a connection to Open Science. The goal of the game is to pair the white cards (prompts) and the black cards in the funniest, most provocative, or smartest way you can. Playing the card game online or with a physical deck creates awareness of issues around resesarch practices and allows for discussions around Open Science.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.10017280\nLicence: CC-BY-4.0\nTopics: Open science, Card game, Workshop, Game, Research data management, FAIR, Software management\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 30-60 minutes\nOnline/in-person: Online and in-person"
  },
  {
    "objectID": "topics/trainings.html#open-loves-science",
    "href": "topics/trainings.html#open-loves-science",
    "title": "Trainings",
    "section": "Open loves Science",
    "text": "Open loves Science\nOpen Science aims to improve, streamline and elevate science to something bigger. Why? Out of love for science of course!\nIn Open loves Science, players are invited to engage in playful and deep conversations about Open Science. The card game features an encyclopedia of issues that pervade this movement of research reform and ask participants to consider their role and values in changing academic culture. Like Open Science, this game is about connection. Players are meant to look into each other’s eyes, engage in conversation, and better understand one another.\n“Open loves Science” was made for the Data love week 2024.\n\n\nTraining materials: https://nlesc.github.io/open-loves-science/\nLicence: CC-BY-4.0\nTopics: Open science, Card game, Workshop, Game, Research data management, FAIR, Software management\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 30-60 minutes\nOnline/in-person: Online and in-person"
  },
  {
    "objectID": "topics/trainings.html#software-carpentries",
    "href": "topics/trainings.html#software-carpentries",
    "title": "Trainings",
    "section": "Software Carpentries",
    "text": "Software Carpentries\nThe Software Carpentries are hands-on workshops that teach basic skills needed to program in a reproducible way.\nA Software Carpentry workshop covers lessons on:\n\nPlotting and Programming in Python or R\nThe Unix Shell\nVersion Control with Git and GitHub\n\nThe lessons are designed for programming beginners and do not require any experience. You program along, learn by helping one another, and apply what you have learned in exercises.\n\n\nRegistration form: https://vu-nl.libcal.com/calendar/universitylibrary?t=g&q=software%20carpentry&cid=7052&cal=7052&inc=0\nTraining materials: https://software-carpentry.org/lessons/\nTopics: Coding, Software skills, Python, R, Bash, Unix Shell, Git, GitHub, Version control\nTarget audience: Researchers, students\nStatus: Available on set moments\nDuration: 28 hours over four days\nOnline/in-person: In-person and online (self-study)"
  },
  {
    "objectID": "topics/trainings.html#writing-a-data-management-plan",
    "href": "topics/trainings.html#writing-a-data-management-plan",
    "title": "Trainings",
    "section": "Writing a Data Management Plan",
    "text": "Writing a Data Management Plan\nIn this course you learn how you write a good Data Management Plan (DMP) for your research project. The course is aimed at PhD students at the beginning of their research project.\nThe course consists of 2 workshops (either in person or online) and an online peer review session. In preparation for the workshops, you are requested to study some materials. You will do three assignments (RDM Framework, First draft of DMP and Final DMP) and peer review one other participant’s DMP. You will receive a certificate worth 1 EC for this course if you successfully complete all mandatory components.\n\n\nRegistration form: https://vu-nl.libcal.com/calendar/universitylibrary?t=g&q=writing%20a%20data%20management%20plan&cid=7052&cal=7052&inc=0\nMore information: https://vu.nl/en/employee/university-library/course-for-phd-students-writing-a-data-management-plan\nTopics: Data Management Plan, data overview, legal and ethical requirements, data storage, data archiving and publishing, metadata and documentation\nTarget audience: Researchers, PhD\nStatus: Available on set moments\nDuration: 28 hours spread over about 3 months (2 workshops, peer review session and homework)\nOnline/in-person: In-person or online (see registration form for particular course)"
  },
  {
    "objectID": "topics/data-classification.html",
    "href": "topics/data-classification.html",
    "title": "Data Classification",
    "section": "",
    "text": "Before the start of a new research project, it is necessary to assess the risks associated with the data that will be collected and/or used in the project."
  },
  {
    "objectID": "topics/data-classification.html#data-classification",
    "href": "topics/data-classification.html#data-classification",
    "title": "Data Classification",
    "section": "Data Classification",
    "text": "Data Classification\nThe purpose of classifying data is to assess the risks associated with the data in terms of Confidentiality, Integrity and Availability, and to determine a suitable level of protection. Classifying research data enables researchers to protect the data in an appropriate manner. What is relevant, is that the security level matches the identified risks. This enables the researcher to determine where the data may or may not be processed and under which conditions.\nA data classification addresses risks relating to Confidentiality, Integrity and Availability. For the research domain, Confidentiality is the crucial aspect in many cases. Examples of data that are classified as confidential are personal data (as defined in the General Data Protection Regulation), commercially or politically sensitive data and data under protection of a non-disclosure agreement. If you work with these types of data, it is necessary to classify your data. You can address the classification of your data in your Data Management Plan (DMP) and use the Data Classification Tool (see below) as a starting point."
  },
  {
    "objectID": "topics/data-classification.html#data-classification-tool",
    "href": "topics/data-classification.html#data-classification-tool",
    "title": "Data Classification",
    "section": "Data Classification Tool",
    "text": "Data Classification Tool\nThe Data Classification Tool will help assess the risks associated with research data and provide feedback on what measures need to be undertaken to protect the data. The tool assesses the three risk categories i.e., Confidentiality, Integrity and Availability, by asking whether certain conditions apply to the data. Each category has an “i” which provides for more explanation on each condition.\nThe first category (Confidentiality) is relevant to privacy or other data that needs to be kept confidential. The other two categories relate to the impacts of data losses (Availability) and inappropriate alterations or corruption (Integrity). Once all relevant boxes under each category have been checked, a tile will be highlighted. This tile contains further details about the data-related risks and describes the steps that should be taken.\nYou can save the results of the risk assessment by pressing the “Export” button. This will produce a PDF, including the links. The result you get is not a formal data classification, although it will be sufficient for many projects with low and medium risks.\nThe information from the assessment can be used for DMPs, Data Protection Impact Assessments (DPIAs) or full (formal) classification. You can also use it to find a suitable storage location for your data through the Data Storage Finder. One of the filters in the Data Storage Finder is called ‘Data classification’, which refers to the level of ‘Confidentiality’ from a data classification.\nNote that because the risks may vary for different types of data, you should repeat this process for each type of data you will use in your research. For example, a research project with multiple datasets, will require numerous risk assessments."
  },
  {
    "objectID": "topics/data-classification.html#policy-classification-of-research-data",
    "href": "topics/data-classification.html#policy-classification-of-research-data",
    "title": "Data Classification",
    "section": "Policy Classification of Research Data",
    "text": "Policy Classification of Research Data\nThe Policy Classification of Research Data contains more information about classifying research data in terms of Confidentiality, Integrity and Availability. It also explains how the classification process should be carried out. The Research Data Classification Policy will determine what level of security measures are necessary to manage data securely. The document contains tables with practical information relating to information security:\n\nexamples of data for the various levels of Confidentiality, Integrity and Availability;\na list of standard security measures per aspect;\nan overview of research data management tools and what types of data are allowed in these systems;\nan overview of what research data management tool is suitable in which situation."
  },
  {
    "objectID": "topics/data-classification.html#knowledge-security",
    "href": "topics/data-classification.html#knowledge-security",
    "title": "Data Classification",
    "section": "Knowledge Security",
    "text": "Knowledge Security\nOne factor that has become more prominent for data classification in recent years is knowledge security. While data classification and knowledge security are different concepts, the degree to which knowledge security applies to a research project and its data also influences the eventual classification of the data, particularly in the case of research into dual use items. You can find more information about knowledge security, the VU’s implementation of a Knowledge Security Framework and the definition of dual use items on the Knowledge Security page in this handbook."
  },
  {
    "objectID": "topics/cff.html",
    "href": "topics/cff.html",
    "title": "Citation File Format (CFF)",
    "section": "",
    "text": "A Citation File Format (CFF) is a computer file that contains all information needed to cite something. For example, a dataset or a piece of software.\nSeveral data and software repositories, such as Zenodo and GitHub, support this format and enable others to easily select the citation information in their preferred format. Most reference managers can work with these standardized citation files, and automatically format the references in a document.\n\n\n\nA screenshot of the interface to cite a GitHub repository\n\n\nAn example, CFF-file is given below, but to enable you to easily create a CFF-file you can use this website.\ncff-version: 1.2.0\nmessage: \"If you use this data, please cite it as below.\"\nauthors:\n - family-names: Druskat\n   given-names: Stephan\n   orcid: https://orcid.org/1234-5678-9101-1121\ntitle: \"My Research Software\"\nversion: 2.0.4\nidentifiers:\n  - type: doi\n    value: 10.5281/zenodo.1234\ndate-released: 2021-08-11"
  },
  {
    "objectID": "topics/itvo.html",
    "href": "topics/itvo.html",
    "title": "IT for Research (ITvO)",
    "section": "",
    "text": "ITvO (IT voor Onderzoek, IT for Research) is a dedicated team within the university IT department, focused on supporting researchers with IT solutions. We bridge the gap between research needs and IT possibilities, making sure researchers have access to the right tools, infrastructure, and expertise."
  },
  {
    "objectID": "topics/itvo.html#our-services",
    "href": "topics/itvo.html#our-services",
    "title": "IT for Research (ITvO)",
    "section": "Our Services",
    "text": "Our Services\n\nSciStor: Scientific storage service of VU Amsterdam. Data is stored on campus in our Data Centre.\nSciCloud: A flexible platform where researchers can create and manage virtual machines for diverse projects.\nAda HPC: High Performance Computing cluster of VU Amsterdam, for compute-intensive research tasks."
  },
  {
    "objectID": "topics/itvo.html#consultancy",
    "href": "topics/itvo.html#consultancy",
    "title": "IT for Research (ITvO)",
    "section": "Consultancy",
    "text": "Consultancy\nDoes your research project require specific IT infrastructure? Do you need to set up a publicly accessible web application for your project? Is your laptop getting too slow to run your analysis? Does your lab instrument require specialised server software?\nResearch projects often have specific IT needs that fall outside the standard solutions the IT department supplies, and they can only be met by expensive custom solutions falling outside your project budget.\nIT for Research was specifically tasked to offer researchers practical advice and solutions to make the most of your limited time and budget. We offer:\n\nNeeds Assessment: Collaborating with you to understand your research goals and IT requirements.\nSolution Matching: Identifying the most suitable university and external IT resources for your project.\nTechnical Support: Assisting with setup, optimisation, and troubleshooting of research IT environments.\nBest Practices: Advising on data management, security and analysis workflows."
  },
  {
    "objectID": "topics/itvo.html#contact",
    "href": "topics/itvo.html#contact",
    "title": "IT for Research (ITvO)",
    "section": "Contact",
    "text": "Contact\nYou can contact IT for Research by using the form on 🔒ServiceNow, select “Research” under “Service Domain” or email us directly at itvo.it@vu.nl"
  },
  {
    "objectID": "topics/data-citation.html",
    "href": "topics/data-citation.html",
    "title": "Data Citation",
    "section": "",
    "text": "Citing data is not different from citing a journal publication. Similar to citing a journal publication, it helps to give and receive credit, and show the impact of the original source.\nMake sure to check the rules of the journal to know how you should cite when writing an article for a specific academic journal. For all of the journals, however, the minimum compulsory elements in a data citation include:\n\nAuthor(s): Name of the author (creator) of the dataset\nTitle: Name of the dataset\nDate of publication\nPublisher: Archive where dataset is stored\nPersistent Identifier: Unique identifier, most common is the DOI (see section Persistent Identifier).\n\nOptional elements that may be included in the reference are:\n\nFile Type: Codebook, movie, software\nVersion: Version number of the edition\nCreation Date\nDate of Consultation (last)\n\nIf you (re)used another, openly accessible dataset to create your own, it is also important to (first check that the original dataset’s licence permits this and to) cite that dataset correctly. If you want to make clear in a journal article that another dataset was reused, you can add this information, including a citation to the original dataset, to the data availability statement, besides the reference list. In your own dataset, you can use the README file to cite the original dataset and explain how it was reused. You should also add documentation about what processing you did to the original dataset to create your own, and refer to this documentation in the README file. Many repositories prescribe a standard way to cite datasets for several citation styles, and one can very often simply copy and paste that. For example, Zenodo has a citation box on the bottom right of the page, and there one can choose a citation style and simply copy that or export the citation to a citation file (which is useful if you are using EndNote or Zotero). The same can be done in Datacite (example).\n\n\nStephens, William, 2020, “Resiliences to Radicalisation - QSort Data”, https://doi.org/10.34894/35MTMN, DataverseNL, V1.\n\nFor more information, see the following guidelines:\n\nDataverse\nDataCite\nDCC UK\nData Citation Synthesis Group (2014). Joint Declaration of Data Citation Principles. Martone M. (ed.) San Diego CA: FORCE11\nCESSDA on accessing, using and citing data\nCESSDA on citing your own data\n\nRelevant is also the Citation File Format (CFF)."
  },
  {
    "objectID": "topics/data-citation.html#citation-elements",
    "href": "topics/data-citation.html#citation-elements",
    "title": "Data Citation",
    "section": "",
    "text": "Citing data is not different from citing a journal publication. Similar to citing a journal publication, it helps to give and receive credit, and show the impact of the original source.\nMake sure to check the rules of the journal to know how you should cite when writing an article for a specific academic journal. For all of the journals, however, the minimum compulsory elements in a data citation include:\n\nAuthor(s): Name of the author (creator) of the dataset\nTitle: Name of the dataset\nDate of publication\nPublisher: Archive where dataset is stored\nPersistent Identifier: Unique identifier, most common is the DOI (see section Persistent Identifier).\n\nOptional elements that may be included in the reference are:\n\nFile Type: Codebook, movie, software\nVersion: Version number of the edition\nCreation Date\nDate of Consultation (last)\n\nIf you (re)used another, openly accessible dataset to create your own, it is also important to (first check that the original dataset’s licence permits this and to) cite that dataset correctly. If you want to make clear in a journal article that another dataset was reused, you can add this information, including a citation to the original dataset, to the data availability statement, besides the reference list. In your own dataset, you can use the README file to cite the original dataset and explain how it was reused. You should also add documentation about what processing you did to the original dataset to create your own, and refer to this documentation in the README file. Many repositories prescribe a standard way to cite datasets for several citation styles, and one can very often simply copy and paste that. For example, Zenodo has a citation box on the bottom right of the page, and there one can choose a citation style and simply copy that or export the citation to a citation file (which is useful if you are using EndNote or Zotero). The same can be done in Datacite (example).\n\n\nStephens, William, 2020, “Resiliences to Radicalisation - QSort Data”, https://doi.org/10.34894/35MTMN, DataverseNL, V1.\n\nFor more information, see the following guidelines:\n\nDataverse\nDataCite\nDCC UK\nData Citation Synthesis Group (2014). Joint Declaration of Data Citation Principles. Martone M. (ed.) San Diego CA: FORCE11\nCESSDA on accessing, using and citing data\nCESSDA on citing your own data\n\nRelevant is also the Citation File Format (CFF)."
  },
  {
    "objectID": "topics/snellius.html",
    "href": "topics/snellius.html",
    "title": "Snellius",
    "section": "",
    "text": "Snellius is the National Supercomputer infrastructure hosted by SURF in Amsterdam."
  },
  {
    "objectID": "topics/snellius.html#what-is-it",
    "href": "topics/snellius.html#what-is-it",
    "title": "Snellius",
    "section": "",
    "text": "Snellius is the National Supercomputer infrastructure hosted by SURF in Amsterdam."
  },
  {
    "objectID": "topics/snellius.html#what-can-it-be-used-for",
    "href": "topics/snellius.html#what-can-it-be-used-for",
    "title": "Snellius",
    "section": "What can it be used for?",
    "text": "What can it be used for?\n\nSimulation and modelling\nDo you work with large and complex models that require a lot of computing power? The National Supercomputer provides that with a large number of super-fast processors. The system is ideally suited for large-scale experiments, such as simulations and modelling. These require a lot of processing power and memory usage, but also communication between the different processors. An important feature of Snellius is its fast internal network.\n\n\nComputing power\nSnellius runs on Linux. Besides AMD processors, the system also features GPGPUs (General Purpose Graphics Processing Units). These accelerators combine the processing power of graphics cards (GPUs) with that of CPUs. In addition, Snellius has ‘fat nodes’ with more memory space (1 TB) and ‘high-memory nodes’ (4 TB and 8 TB of memory space).\n\n\nTools and libraries\nAs a researcher, you can make use of a large collection of tools, compilers and libraries.\nAre you doing research or experiments in the field of machine learning, e.g. neural networks? The libraries and tools on Snellius make it a lot easier."
  },
  {
    "objectID": "topics/snellius.html#how-to-request-access",
    "href": "topics/snellius.html#how-to-request-access",
    "title": "Snellius",
    "section": "How to request access",
    "text": "How to request access\nYou can request access via a form on the 🔒SURF service desk portal. There are 2 options:\n\n1. Direct institute contract\nThe VU has a contract with SURF for the usage of Snellius. Every VU researcher or master student can request Snellius SBUs (System Billing Units). The total amount available to the VU is limited however, only use this option for smaller projects, say up to 1.000.000 CPU and/or GPU SBUs.\nThe SURF wiki provides some guidance on estimating the amount of SBUs you need. We recommend you start with the default 50.000 CPU and/or GPU SBUs. You can use the same form to request a top-up if you run out.\n\n\n2. NWO compute grant\nIf you have a large project involving more than 1.000.000 CPU and/or GPU SBUs you should apply for an NWO Large Compute applications grant.\nEach Snellius account is provided with 200GB Home space (backups available), apart from that 8TB of temporary fast scratch space is available for your calculations. If the Home space is not sufficient or you can request Project Space to store your data during your project. Note that the Project Space is not backed-up! Always make sure a copy of valuable data is also stored on a recommended storage system.\nNote that for large-scale GPU projects access the European LUMI supercomputer can also be requested by VU researcers. Obtaining compute time on LUMI."
  },
  {
    "objectID": "topics/snellius.html#are-there-costs-involved",
    "href": "topics/snellius.html#are-there-costs-involved",
    "title": "Snellius",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThere are no direct costs for researchers, but be aware that “Direct institute contract” usage costs are billed to the faculties via KDM (“Kosten Doorbelasting Model”)."
  },
  {
    "objectID": "topics/snellius.html#getting-started",
    "href": "topics/snellius.html#getting-started",
    "title": "Snellius",
    "section": "Getting started",
    "text": "Getting started\nThe SURF User Knowledge Base has lots of information to get you started.\nSURF organises regular “Introduction to Supercomputing” training sessions, these are free to attend for VU researchers. Please consult the SURF Agenda for dates and registration.\nNote that there is a free community partition available on the VU HPC cluser ADA, where you can refine your analysis scripts before running them on the more expensive Snellius cluster. Experts at IT for Research can help you optimise your code to run more efficiently."
  },
  {
    "objectID": "topics/snellius.html#contact",
    "href": "topics/snellius.html#contact",
    "title": "Snellius",
    "section": "Contact",
    "text": "Contact\nSURF offers limited direct support for researchers using Snellius. To ask a question create a ticket on the 🔒SURF Service Desk Portal.\nFor general questions on HPC please contact IT for Research."
  },
  {
    "objectID": "topics/scistor.html",
    "href": "topics/scistor.html",
    "title": "SciStor",
    "section": "",
    "text": "The storage service SciStor is intended for cheaply storing large amounts of research data.\nSciStor is hosted by IT for Research (ITvO) on the VU campus enabling a high-speed connection to lab equipment, laptops and workstations, the ADA HPC cluster and SciCloud. It can also be accessed off-campus.\nYour data is stored in a share, basically a folder with group-based access rights (read/write or read-only). Access rights can be set one level deep, so one share could be used to host data from different projects.\nIf desired, automatic backups can be made of the data."
  },
  {
    "objectID": "topics/scistor.html#what-is-it",
    "href": "topics/scistor.html#what-is-it",
    "title": "SciStor",
    "section": "",
    "text": "The storage service SciStor is intended for cheaply storing large amounts of research data.\nSciStor is hosted by IT for Research (ITvO) on the VU campus enabling a high-speed connection to lab equipment, laptops and workstations, the ADA HPC cluster and SciCloud. It can also be accessed off-campus.\nYour data is stored in a share, basically a folder with group-based access rights (read/write or read-only). Access rights can be set one level deep, so one share could be used to host data from different projects.\nIf desired, automatic backups can be made of the data."
  },
  {
    "objectID": "topics/scistor.html#what-can-it-be-used-for",
    "href": "topics/scistor.html#what-can-it-be-used-for",
    "title": "SciStor",
    "section": "What can it be used for?",
    "text": "What can it be used for?\n\nNetworked Drive\nBecause SciStor is connected to the VU on-campus network you can directly mount (map a network drive) SciStor shares on your laptop and work as if the data is on a local disk.\n\n\nAccess off-campus\nAlthough SciStor is most useful on campus you can also access your shares off-campus.\n\n\nLab instruments\nIn many cases lab equipment can write data directly to SciStor. IT for Research can help you setup an automated and secure connection.\n\n\nStorage space for SciCloud servers\nSciCloud virtual servers are provisioned with a 20 to 50GB local disk. A SciStor share can be directly mounted on the server to increase storage for your application or directly access your source data for analysis.\n\n\nADA\nThe ADA HPC cluster is connected to SciStor via a high speed netwodrk. You can run your analysis software directly on your data and easily access the results on your laptop.\n\n\nSharing data\nBecause SciStor is mainly intended for high performance, on-campus use, access is only possible with a VUnetId. If you need to share data with non-VU researchers you could register them as an external employee or host a copy of the data on another storage platform like Research Drive or Yoda\n\n\nData life-cycle\nSciStor is meant for data you are actively working with. We recommend archiving datasets that are no langer actively used, but can’t be deleted, in Yoda. This ensures SciStor is used optimally and costs are kept down for your research group and the VU."
  },
  {
    "objectID": "topics/scistor.html#how-to-request-access",
    "href": "topics/scistor.html#how-to-request-access",
    "title": "SciStor",
    "section": "How to request access",
    "text": "How to request access\n\nRequesting a new share\nSciStor is available for all VU research groups. You can find the request form on 🔒 ServiceNow, go to: IT &gt; My work field &gt; Research &gt; SciStor &gt; Realisation of new storage for research (SciStor)\nMinimum storage space that can be requested is 100 GB, for a minimum of three months. The capacity can be increased or decreased in units of 100 GB if needed.\nAfter submitting the application, IT for Research will contact you to schedule an interview to discuss naming the SciStor share, how the backups work, who should have access, etc.\nMost SciStor configurations can be delivered within one or two days. More complex configurations may take a little longer.\n\n\nAdding a colleague to an existing share\nThe owner of a SciStor share can request to add or remove access to the share via 🔒 ServiceNow, go to: IT &gt; My work field &gt; Research &gt; SciStor &gt; Change SciStor access rights"
  },
  {
    "objectID": "topics/scistor.html#are-there-costs-involved",
    "href": "topics/scistor.html#are-there-costs-involved",
    "title": "SciStor",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nYou pay for the amount of space reserved for your share: €0,10 per GB per year without backup or €0,20 per GB per year with backup. Note that without backup data will be lost in case of accidental deletion or major problems with the SciStor infrastructure.\nThe owner of the SciStor share receives monthly usage reports. The report provides insight on used and available space.\n\nBackups\nThere are two type of flavours when it comes to data protection within SciStor.\n\n\n\n\n\n\n\nSnapshots\nBackups\n\n\n\n\n“Photo moments” of your data stored within the same location storage\nComplete copy stored in a different physical location\n\n\nDefault Policies within ITvO: a) Daily snapshots kept for 1 week (1d:1w) b) Weekly snapshots kept for 4 weeks (1w:4w)\nAutomatic daily backups around midnight\n\n\nCustom policies available upon request\nInvisible to users - runs in the background\n\n\nNo additional storage costs\nAdditional Costs: Doubles the storage costs\n\n\n\nThe ITvO team recommend having both ways activated for complete data protection."
  },
  {
    "objectID": "topics/scistor.html#getting-started",
    "href": "topics/scistor.html#getting-started",
    "title": "SciStor",
    "section": "Getting started",
    "text": "Getting started\n\nOn-campus access\n\nMacOS\n\nOpen the Finder application\nIn the “Go” menu, pick “Connect to Server…” or press “⌘K”\nFill in: smb://scistor.vu.nl/shares\nClick “Connect”\nSelect “Registered User” if this is not yet selected\nFill in your VUnetID and password\nPress “Connect”. Optionally, tick the “Remember this password in my keychain” checkbox. After doing this, macOS will no longer ask for credentials the next time this connection is used.\n\nSciStor shares appear on the left after opening the SciStor location. You may open the desired SciStor share by double-clicking it.\n\n\nWindows\n\nOpen Windows File Explorer\nRight-click on This PC and choose “Map network drive…””\nSelect a desired drive letter, for example S. In the Folder field you can enter the following: \\\\scistor.vu.nl\\shares\\&lt;the name of the share folder&gt;. Make sure the checkboxes are checked.\nClick “Finish”\nYou will now be asked to log in. This is not possible with your PIN code. Choose the “More choices” option, and log in with your VU email address and password\n\n\n\n‘Green’ Linux workspaces\nGreen Linux workplaces (supported by VU IT) have a connection to SciStor from home. All SciStor shares can be found under the path /research.\n\n\nOther Linux workstations\nOther self-managed Linux workstations can also connect to SciStor.\nVia the SFTP protocol: SciStor with the SFTP protocol can be used via the server sftp.data.vu.nl. Find the shares under the path /research.\nYou can do as follows:\n$ ssh &lt;vunetID&gt;@sftp.data.vu.nl # this will ask your vunet password\n$ cd /research/&lt;name-of-scitstor-share&gt;\nTo to connect to SciStor using samba protocol, you can do as follows:\n$ sudo apt install cifs-utils\n$ sudo nano /etc/credentials/&lt;vunetID&gt;\n    # nano\nusername=&lt;vumail@vu.nl&gt;\npassword=&lt;your-vunet-password&gt;\n$ sudo mkdir /data/VU/shares/&lt;name-of-your-share&gt;\n$ sudo mount -t cifs //scistor.vu.nl/shares/&lt;name-of-your-share&gt; /data/VU/shares/&lt;name-of-your-share&gt; -o credentials=/etc/credentials/&lt;vunetID&gt;\nThe scistor share will be mounted at location: /data/VU/shares. To unmount it, simply do:\n$ sudo umount /data/VU/shares/&lt;name-of-your-share&gt;\n\n\n\n\nOff-campus access\n\neduVPN\nThe easiest way is to install the app for eduVPN institute access. Once the VPN is active you can follow the “on-campus access” steps above. Note that performance over the internet is limited, you might run into problems when editing large files. If needed copy them to you local disk.\n\n\nSFTP\nOn windows you can use a free tool like WinSCP or CyberDuck to access your data via the SFTP protocol. The server URL is sftp.data.vu.nl, find the shares under the path /research.\nOn a Mac you can connect via the IT supported 🔒 Expandrive (follow the SFTP instructions).\nThe configuration is as follows:\n\n\n\nItem\nValue\n\n\n\n\nHost\nssh.data.vu.nl OR sftp.data.vu.nl\n\n\nProtocol\nSFTP\n\n\nPort\n22\n\n\nUsername\nYour VUnetID\n\n\nPassword\nYour VUnet password\n\n\n\nLinux users outside campus can follow the previous SFTP explanation."
  },
  {
    "objectID": "topics/scistor.html#contact",
    "href": "topics/scistor.html#contact",
    "title": "SciStor",
    "section": "Contact",
    "text": "Contact\nWondering if SciStor fits your research needs? Please contact IT for Research"
  },
  {
    "objectID": "topics/data-licensing.html",
    "href": "topics/data-licensing.html",
    "title": "Data Licensing",
    "section": "",
    "text": "A data licence agreement is a legal instrument that lets others know what they can and cannot do with a particular dataset (and any documentation, scripts and metadata that are published with the data - information about software licensing can be found on the software licensing page). It is important to consider what kind of limitations are relevant. Usually, at least the following questions are considered:\n\nCan people make copies or even distribute copies?\nDo others (and you) reusing the dataset need to acknowledge you as the author of the original dataset? (This is called Attribution.)\nDo others (and you) who reuse the dataset and/or make derivatives of the dataset need to share their work under a similar licence? (This is called Share-Alike.)\nCan others (and you) use your dataset commercially? (A restriction on commercial use is called Non-Commercial.)\nCan others (and you) create a new work based on the dataset? (This is called a Derivative.)\n\nThe considerations above are the ‘building blocks’ that Creative Commons licences use. There are also other considerations, and also other licences.\n\n\n\nAn image of open data, made up of public domain icons"
  },
  {
    "objectID": "topics/data-licensing.html#introduction",
    "href": "topics/data-licensing.html#introduction",
    "title": "Data Licensing",
    "section": "",
    "text": "A data licence agreement is a legal instrument that lets others know what they can and cannot do with a particular dataset (and any documentation, scripts and metadata that are published with the data - information about software licensing can be found on the software licensing page). It is important to consider what kind of limitations are relevant. Usually, at least the following questions are considered:\n\nCan people make copies or even distribute copies?\nDo others (and you) reusing the dataset need to acknowledge you as the author of the original dataset? (This is called Attribution.)\nDo others (and you) who reuse the dataset and/or make derivatives of the dataset need to share their work under a similar licence? (This is called Share-Alike.)\nCan others (and you) use your dataset commercially? (A restriction on commercial use is called Non-Commercial.)\nCan others (and you) create a new work based on the dataset? (This is called a Derivative.)\n\nThe considerations above are the ‘building blocks’ that Creative Commons licences use. There are also other considerations, and also other licences.\n\n\n\nAn image of open data, made up of public domain icons"
  },
  {
    "objectID": "topics/data-licensing.html#reusing-existing-data",
    "href": "topics/data-licensing.html#reusing-existing-data",
    "title": "Data Licensing",
    "section": "Reusing existing data",
    "text": "Reusing existing data\nIf you wish to reuse data collected by others (this could be data you received from for example Statistics Netherlands or from a company, a dataset you have found in an online repository, commonly used databases for which VU Amsterdam has a licence, etc.), make sure that you read the licence or terms of use. Also make sure that you work with the data according to the licence or terms of use. This can mean different things depending on the licence, but common things to consider are for example:\n\ncite the data in an appropriate manner;\ndo not share the data beyond the project/purpose for which you received them;\nshare the outcome of your research based on the data under a similar licence;\nonly use them for scientific purposes (and not for commercial purposes, for example).\n\nIf you have questions about the legal context of using an existing dataset, you can contact the RDM Support Desk or the legal experts at IXA VU."
  },
  {
    "objectID": "topics/data-licensing.html#licensing-data",
    "href": "topics/data-licensing.html#licensing-data",
    "title": "Data Licensing",
    "section": "Licensing data",
    "text": "Licensing data\nIf you want to make your data available for other (research) purposes, it is important to apply a licence to it. Without a licence, it is impossible for others to reuse your data without your explicit approval. When you deposit your data in a repository, the repository will usually ask you to select a standard licence, or to create and add a custom licence yourself. If you need help with drawing up licence agreements, you can contact the VU’s legal office.\n\nDataverseNL\nIn DataverseNL you can choose your terms of use when uploading data to the repository. The DataverseNL user guide explains how licensing works in the repository.\n\n\nYoda\nIf you publish your data in Yoda, there is guidance available on how to choose a licence and how to customise licences.\n\n\nOpen Science Framework (OSF)\nIn OSF, you can apply a standard licence to your materials or upload your own custom licence. The OSF user guide explains both options.\n\n\nExternal repositories\nSome data repositories require you to use a certain licence if you want to deposit your data with them. At Dryad, for example, all datasets are published under the terms of Creative Commons Zero to minimise legal barriers and to maximise the impact for research and education. Some funders may also require that you publish the data as open data. Open data are data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and share alike (Open Knowledge International definition)."
  },
  {
    "objectID": "topics/data-licensing.html#additional-websites-and-tools",
    "href": "topics/data-licensing.html#additional-websites-and-tools",
    "title": "Data Licensing",
    "section": "Additional websites and tools:",
    "text": "Additional websites and tools:\n\nExplanation about copyrights and licences by a professor from Leiden University (English subtitles available)\nThe Guide to Creative Commons for Scholarly Publishing and Educational Resources by NWO, VSNU and the University and Royal Libraries\nDCC how-to guide on licensing research data, a guide that links to the Creative Commons website, where many terms are explained\nOpen Data Commons Public Domain Dedication and License (PDDL)\nEUDAT B2SHARE licence selection wizard, which Pawel Kamocki (et al.) released under an open source licence.1"
  },
  {
    "objectID": "topics/data-licensing.html#footnotes",
    "href": "topics/data-licensing.html#footnotes",
    "title": "Data Licensing",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the source code, see https://github.com/ufal/public-license-selector/↩︎"
  },
  {
    "objectID": "topics/knowledge-security.html",
    "href": "topics/knowledge-security.html",
    "title": "Knowledge Security",
    "section": "",
    "text": "Knowledge security is about secure international collaboration, which is very important for VU Amsterdam. For international collaboration to take place securely, it is necessary to assess the knowledge security risks associated with the research topic, the data that will be collected and/or the potential collaborative partner(s), which can be an institution or individual(s). This assessment has to take place before and during the start of a new research project. VU Amsterdam developed the Knowledge Security Framework (hereinafter: the Framework) as a useful and mandatory guide on asking the important and critical questions about the background of the foreign partner organisation or person, and the research project itself (topic, data, funding). The Framework and all necessary information regarding knowledge security can be found on the knowledge security page for employees."
  },
  {
    "objectID": "topics/knowledge-security.html#introduction",
    "href": "topics/knowledge-security.html#introduction",
    "title": "Knowledge Security",
    "section": "",
    "text": "Knowledge security is about secure international collaboration, which is very important for VU Amsterdam. For international collaboration to take place securely, it is necessary to assess the knowledge security risks associated with the research topic, the data that will be collected and/or the potential collaborative partner(s), which can be an institution or individual(s). This assessment has to take place before and during the start of a new research project. VU Amsterdam developed the Knowledge Security Framework (hereinafter: the Framework) as a useful and mandatory guide on asking the important and critical questions about the background of the foreign partner organisation or person, and the research project itself (topic, data, funding). The Framework and all necessary information regarding knowledge security can be found on the knowledge security page for employees."
  },
  {
    "objectID": "topics/knowledge-security.html#the-importance-of-knowledge-security-regarding-research-data",
    "href": "topics/knowledge-security.html#the-importance-of-knowledge-security-regarding-research-data",
    "title": "Knowledge Security",
    "section": "The importance of knowledge security regarding research data",
    "text": "The importance of knowledge security regarding research data\nAt VU Amsterdam, we attach great value to international collaboration, which is crucial for top-level research and high-quality academic education. As well as opportunities – for research, education, innovation and open knowledge sharing – it also entails risks. Universities are being targeted for acquiring sensitive knowledge and technologies. A possible consequence of this is the undermining of academic freedom and censorship (including self-censorship).\nThe Framework addresses potential ethical issues, such as the risk of violating human rights or academic values, the misuse of knowledge, the safety of researchers and respondents (for instance if the research might cause them to be pressured or coerced), unintended knowledge transfer, and harm to people, animals or the environment. This means that it is important to consider the possible consequences for yourself, your colleagues and the research subjects if your research data falls into the wrong hands, e.g. data on a minority group or a key technology (especially technology that falls under dual use1 regulation) that a repressive government can misuse. If you work with sensitive research data*, want to openly publish your data and/or your collaborative partner is an organisation or affiliated to an organisation from a country that has a score of 0.4 or less on the Academic Freedom Index, the collaboration should be discussed with the faculty’s contact person.\nAlso, measures can be taken in consultation with the contact person (see Support within your faculty) and data steward to mitigate the risks. Possible measures include limiting access to sensitive research data (physically and digitally, e.g. encryption), data anonymisation or pseudonymisation, an adequate data classification, a Data Protection Impact Assessement (DPIA), limiting or excluding collaboration with certain partners and other appropriate protection measures.\n* Sensitive research data regarding knowledge security includes: \n\nResearch data that falls under the dual use regulation1;\nResearch data on key technologies or other technologies that are considered by the Dutch government to be militarily, economically and geopolitically strategic;\nResearch data on ethically sensitive topics (see question 5 of the Framework);\nResearch data related to minority or repressed research subjects."
  },
  {
    "objectID": "topics/knowledge-security.html#support-within-your-faculty",
    "href": "topics/knowledge-security.html#support-within-your-faculty",
    "title": "Knowledge Security",
    "section": "Support within your faculty",
    "text": "Support within your faculty\nTo provide support regarding knowledge security at VU Amsterdam, each faculty has one or more contact persons available who are the first point of contact for questions regarding knowledge security. The contact persons can be found on the knowledge security page for employees."
  },
  {
    "objectID": "topics/knowledge-security.html#footnotes",
    "href": "topics/knowledge-security.html#footnotes",
    "title": "Knowledge Security",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDual use items are defined as ‘items, including software and technology, which can be used for both civil and military purposes, and includes items which can be used for the design, development, production or use of nuclear, chemical or biological weapons or their means of delivery, including all items which can be used for both non-explosive uses and assisting in any way in the manufacture of nuclear weapons or other nuclear explosive devices’ (definition taken from the European Union’s Dual Use Regulation).↩︎"
  },
  {
    "objectID": "topics/open-science.html",
    "href": "topics/open-science.html",
    "title": "Open Science",
    "section": "",
    "text": "UNESCO defines Open Science as\n\na set of principles and practices that aim to make scientific research from all fields accessible to everyone for the benefits of scientists and society as a whole. Open science is about making sure not only that scientific knowledge is accessible but also that the production of that knowledge itself is inclusive, equitable and sustainable\n\nThis includes making openly available research data, methods, and documentation where possible. As such, the practices outlined in the Research Support Handbook are a precondition of Open Science.\nMore information about how researchers can practice Open Science at VU Amsterdam is available on the VU page about Open Science. The VU Open Access Policy and more information about different ways of open access publishing and how VU Amsterdam supports those, can be found on the VU Open Access page.\nYou can read more about Open Science in the Netherlands on the website of the Nationaal Programma Open Science. If you are interested in learning more about Open Science or if you are looking for ways to make your research more open and transparent, you can join the Open Science Community Amsterdam, the community of VU employees and students interested in Open Science (joint with the University of Amsterdam and Amsterdam University of Applied Sciences)."
  },
  {
    "objectID": "topics/software-licensing.html",
    "href": "topics/software-licensing.html",
    "title": "Software Licensing",
    "section": "",
    "text": "Publishing research software under an appropriate licence is crucial for its accessibility, usability, and further integration into research. Choosing a licence usually happens right when you start developing the software or when you put it in a public repository, rather than when the software is finished and fully baked.\nA software licence states how other people may re-use your code and under which circumstances. For research software, it is recommended (and often required by funders) that licences are as permissible as possible.\nThere are many licences out there; below we list some very frequently used licences in research software. However, if none of these licences fit your case, there are several tools that can help you to choose a suitable software licence. If you need guidance in choosing a licence for your software, get in touch with the RDM Support Desk."
  },
  {
    "objectID": "topics/software-licensing.html#licensing-software",
    "href": "topics/software-licensing.html#licensing-software",
    "title": "Software Licensing",
    "section": "",
    "text": "Publishing research software under an appropriate licence is crucial for its accessibility, usability, and further integration into research. Choosing a licence usually happens right when you start developing the software or when you put it in a public repository, rather than when the software is finished and fully baked.\nA software licence states how other people may re-use your code and under which circumstances. For research software, it is recommended (and often required by funders) that licences are as permissible as possible.\nThere are many licences out there; below we list some very frequently used licences in research software. However, if none of these licences fit your case, there are several tools that can help you to choose a suitable software licence. If you need guidance in choosing a licence for your software, get in touch with the RDM Support Desk."
  },
  {
    "objectID": "topics/software-licensing.html#mit-license",
    "href": "topics/software-licensing.html#mit-license",
    "title": "Software Licensing",
    "section": "MIT License",
    "text": "MIT License\nThe MIT License is a popular choice, due to its readability and permissiveness. It allows users to reuse the software for any purpose, including using, copying, modifying, and distributing it, provided they include the original copyright notice and licence text.\nHowever, its permissiveness means that derivative works can be closed-source and do not need to mention that they use your code, which might not align with all scientific openness goals or general."
  },
  {
    "objectID": "topics/software-licensing.html#gnu-gplv3",
    "href": "topics/software-licensing.html#gnu-gplv3",
    "title": "Software Licensing",
    "section": "GNU GPLv3",
    "text": "GNU GPLv3\nThe GNU General Public License (GPLv3) is another option, designed to ensure that the software and any derivatives remain open-source.\nThis encourages collaborative improvement of software. Any software that includes GPL-licensed code must also be open-source under the GPLpotentially deterring commercial use or integration with proprietary software. In conclusion, when you want your code to be used by others, but only the code that uses your code is also open source, this is the way to go."
  },
  {
    "objectID": "topics/software-licensing.html#apache-license-2.0",
    "href": "topics/software-licensing.html#apache-license-2.0",
    "title": "Software Licensing",
    "section": "Apache License 2.0",
    "text": "Apache License 2.0\nThe Apache License 2.0 allows for modification and distribution of the software and its derivative works, with the requirement that changes to the original code are documented.\nIt is a more complex licence than the MIT License and can be incompatible with GPL-licensed software. The specifics of this go beyond the scope of the handbook."
  },
  {
    "objectID": "topics/software-licensing.html#adding-a-licence-to-github",
    "href": "topics/software-licensing.html#adding-a-licence-to-github",
    "title": "Software Licensing",
    "section": "Adding a licence to GitHub",
    "text": "Adding a licence to GitHub\nOn GitHub you add a licence on creating a new repository, by selecting the licence from the drop-down menu. If your repository already exists, add a new file called “LICENSE” using the “+”-button on top of the repository (see below).\n\n\n\nLocation of file creation button\n\n\nOne the next page, start to type LICENSE as the file name, and a button to “Choose a license template” should automatically pop up. Follow the steps provided by GitHub to finish adding the licence to the repository.\nYou should now see your licence shown on the main page of your repository."
  },
  {
    "objectID": "topics/software-licensing.html#further-considerations",
    "href": "topics/software-licensing.html#further-considerations",
    "title": "Software Licensing",
    "section": "Further considerations",
    "text": "Further considerations\n\nIf you are reusing software or libraries written by someone else, you must stick to the clauses of the licence given to the original software/library;\nWhen choosing a licence, do not just think about what others may do with the software, but also what you might want to do with the software in the future."
  },
  {
    "objectID": "topics/academic-integrity.html",
    "href": "topics/academic-integrity.html",
    "title": "Academic Integrity",
    "section": "",
    "text": "Dutch scientists are required to comply with the Netherlands Code of Conduct for Research Integrity (VSNU, 2018). The principles of proper scientific and scholarly research, according to the Code of Conduct are:\n\nHonesty\nScrupulousness\nTransparency\nIndependence\nResponsibility\n\nThe principles of honesty and transparency state explicit guidelines for the way in which you treat your research data:\n\nHonesty: you should refrain from fabricating or falsifying data\nTransparency:\n\nYou should ensure that it is clear to others what data your research is based on, how the data were obtained, what the results are and how you got to these results\nAll steps in your research process must be verifiable (e.g. choice of research question, research design, methodology, sources used), so that it is clear to others how your research was conducted\n\n\nTo live up to these general principles, the Code of Conduct provides the following standards, which are addressed in a Data Management Plan (DMP), for good research practices related to data management:\n\nProvide a description of the way in which the collected research data are organised and classified, so that they can be verified and re-used (standard 3.2.10)\nMake research data public upon completion of your research project; if this is not possible, explain why (standards 3.2.11 and 3.4.45)\nDescribe the data you have collected and used in your research honestly, scrupulously and transparently (standard 3.3.23)\nManage your data carefully and store both the raw and processed versions for a period appropriate for your discipline (standard 3.3.24)\nContribute towards making data FAIR, where possible (standard 3.3.25)\nBe transparent about your methods and working procedures by using e.g. research protocols, logs, lab journals or reports to describe these processes (standard 3.4.35)"
  },
  {
    "objectID": "topics/academic-integrity.html#netherlands-code-of-conduct-for-research-integrity",
    "href": "topics/academic-integrity.html#netherlands-code-of-conduct-for-research-integrity",
    "title": "Academic Integrity",
    "section": "",
    "text": "Dutch scientists are required to comply with the Netherlands Code of Conduct for Research Integrity (VSNU, 2018). The principles of proper scientific and scholarly research, according to the Code of Conduct are:\n\nHonesty\nScrupulousness\nTransparency\nIndependence\nResponsibility\n\nThe principles of honesty and transparency state explicit guidelines for the way in which you treat your research data:\n\nHonesty: you should refrain from fabricating or falsifying data\nTransparency:\n\nYou should ensure that it is clear to others what data your research is based on, how the data were obtained, what the results are and how you got to these results\nAll steps in your research process must be verifiable (e.g. choice of research question, research design, methodology, sources used), so that it is clear to others how your research was conducted\n\n\nTo live up to these general principles, the Code of Conduct provides the following standards, which are addressed in a Data Management Plan (DMP), for good research practices related to data management:\n\nProvide a description of the way in which the collected research data are organised and classified, so that they can be verified and re-used (standard 3.2.10)\nMake research data public upon completion of your research project; if this is not possible, explain why (standards 3.2.11 and 3.4.45)\nDescribe the data you have collected and used in your research honestly, scrupulously and transparently (standard 3.3.23)\nManage your data carefully and store both the raw and processed versions for a period appropriate for your discipline (standard 3.3.24)\nContribute towards making data FAIR, where possible (standard 3.3.25)\nBe transparent about your methods and working procedures by using e.g. research protocols, logs, lab journals or reports to describe these processes (standard 3.4.35)"
  },
  {
    "objectID": "topics/academic-integrity.html#academic-integrity-at-vu-amsterdam",
    "href": "topics/academic-integrity.html#academic-integrity-at-vu-amsterdam",
    "title": "Academic Integrity",
    "section": "Academic integrity at VU Amsterdam",
    "text": "Academic integrity at VU Amsterdam\nTo protect academic integrity at VU Amsterdam and Amsterdam UMC (location VUmc) subscribe to the Netherlands Code of Conduct for Research Integrity. On the Academic Integrity page on the VU website, you can find more information about how these organisations implement the duties of care for institutions to uphold the principles of academic integrity.\n\nConfidential counsellors\nVU Amsterdam has a number of confidential counsellors who handle academic integrity issues.\n\n\nAcademic integrity complaints procedure\nVU Amsterdam and Amsterdam UMC, location VUmc employ a joint policy for the handling academic integrity complaints. This policy outlines the steps to be taken in the event of a complaint, the officers who play a role in this procedure, and what should be expected once a complaint has been lodged."
  },
  {
    "objectID": "topics/academic-integrity.html#rios-center-for-research-integrity-and-open-science",
    "href": "topics/academic-integrity.html#rios-center-for-research-integrity-and-open-science",
    "title": "Academic Integrity",
    "section": "RIOS: Center for Research Integrity and Open Science",
    "text": "RIOS: Center for Research Integrity and Open Science\nRIOS connects initiatives related to research integrity, research ethics, responsible research and innovation, open science, and research culture at VU Amsterdam and Amsterdam UMC. The mission of RIOS is to strengthen the position of VU Amsterdam and Amsterdam UMC regarding research integrity and open science."
  },
  {
    "objectID": "topics/osf.html",
    "href": "topics/osf.html",
    "title": "Open Science Framework (OSF)",
    "section": "",
    "text": "The Open Science Framework (OSF) is a cloud-based open-source research project management tool that supports researchers throughout the active research stage. It facilitates collaboration, connects services across the research life cycle, materials, and other research objects for private use or public sharing. The OSF is developed by the Center of Open Science (COS) that strives to increase openness, integrity, and reproducibility of research. This is in line with the VU open science commitment where the aim is to make the process of creating and sharing scientific knowledge more transparent, inclusive and equitable.\n\nAs a collaboration tool, OSF helps research teams work on projects privately or make them publicly accessible for broad dissemination.\nAs a workflow system, OSF enables connections to the many products researchers already use, streamlining their process and increasing efficiency.\nResearchers can manage files, data, code, and protocols in one centralised location and easily build custom organisation for their unique needs.\nIntegrated metadata support on project level improves findability and reuse of research materials. Soon content on OSF will support FAIR metadata for all files, which will even further enhance responsible preservation and discovery.\n\nRead more about OSF best practices for new OSF users in OSF Getting started below."
  },
  {
    "objectID": "topics/osf.html#what-is-it",
    "href": "topics/osf.html#what-is-it",
    "title": "Open Science Framework (OSF)",
    "section": "",
    "text": "The Open Science Framework (OSF) is a cloud-based open-source research project management tool that supports researchers throughout the active research stage. It facilitates collaboration, connects services across the research life cycle, materials, and other research objects for private use or public sharing. The OSF is developed by the Center of Open Science (COS) that strives to increase openness, integrity, and reproducibility of research. This is in line with the VU open science commitment where the aim is to make the process of creating and sharing scientific knowledge more transparent, inclusive and equitable.\n\nAs a collaboration tool, OSF helps research teams work on projects privately or make them publicly accessible for broad dissemination.\nAs a workflow system, OSF enables connections to the many products researchers already use, streamlining their process and increasing efficiency.\nResearchers can manage files, data, code, and protocols in one centralised location and easily build custom organisation for their unique needs.\nIntegrated metadata support on project level improves findability and reuse of research materials. Soon content on OSF will support FAIR metadata for all files, which will even further enhance responsible preservation and discovery.\n\nRead more about OSF best practices for new OSF users in OSF Getting started below."
  },
  {
    "objectID": "topics/osf.html#what-can-it-be-used-for",
    "href": "topics/osf.html#what-can-it-be-used-for",
    "title": "Open Science Framework (OSF)",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nOSF can be used during the active research stage. It can be used for preregistration, projects or preprints:\n\nPreregistration of your research ideas - OSF Support.\nProjects: See the video Welcome to OSF Projects - OSF Support.\nWhitin an OSF project you can store, share and collaborate with your colleagues. You can invite both internal and external collaborators to different components within your project. You can choose to have your project open, for everyone to read, or you can choose to have it closed for up to four years of embargo. It is possible to create a DOI for your research project, see the manual Create DOIs (OSF Projects) - OSF Support.\nPreprints: OSF can also be used to publish your preprints. See the manual Creating a Preprint - OSF Support, which describes in seven steps how you can publish a preprint."
  },
  {
    "objectID": "topics/osf.html#how-to-request-access",
    "href": "topics/osf.html#how-to-request-access",
    "title": "Open Science Framework (OSF)",
    "section": "How to request access?",
    "text": "How to request access?\nIf you like to start with OSF please go to: OSF.\nYou can either create a new OSF account and choose \"Sign up using Institution\" and select Vrije Universiteit Amsterdam (OSF Guide). VU researchers can make use of OSF by logging in with their VUnetID credentials (SSO). The OSF account will be automatically created. Or you can add your VUnetID login to your existing OSF account (OSF Guide). If you already have an OSF account and would like to affiliate this to VU Amsterdam, please visit: Affiliate an OSF Project with an Institution - OSF Support and registrations with the VU (OSF Guide).\nWhen the OSF account is created, you can start directly with using OSF to create a project, registering your preregistration or publishing using the preprints options at OSF (see the section What it can be used for?).\n\nAccess for students\nStudents are also welcome to use OSF. Note that logging in with VUnetID requires MFA via de SURFsecureID (with the tiqr app or a YubiKey). Secure sign on - MS Authenticator activation for SURF Secure ID has more information on how to register for MFA if you have not already done so."
  },
  {
    "objectID": "topics/osf.html#are-there-costs-involved",
    "href": "topics/osf.html#are-there-costs-involved",
    "title": "Open Science Framework (OSF)",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThe costs for storing data in OSF are detailed on the VU website.\nOSF storage has a limit of 5GB for a private project and 50GB for a public project. Note that it is possible to request additional (paid) OSF storage via the Request form. More information on available storage tiers can be found on the Supporting OSF Usage page. Another way to acquire more storage is connecting an alternative storage provider via Add-ons as described in Connecting storage and apps. The OSF storage caps page has more information on extending storage capacity."
  },
  {
    "objectID": "topics/osf.html#getting-started",
    "href": "topics/osf.html#getting-started",
    "title": "Open Science Framework (OSF)",
    "section": "Getting started",
    "text": "Getting started\nTo get started with OSF please visit the Getting started on the OSF (Video) - OSF Support. You can also subscribe to the onboarding webinars OSF | Trainings and Webinars.\nOnce a year, there will be an OSF workshop organised by VU application managers, where you learn how you can use OSF. See the Trainings page for training materials and scheduled workshops.\nMore in-depth information is available in the guide How can you use Open Science Framework (OSF) in your research project?. See the Information for new users guide in that guide for more information for new users."
  },
  {
    "objectID": "topics/osf.html#contact---support-options-for-vu-researchers",
    "href": "topics/osf.html#contact---support-options-for-vu-researchers",
    "title": "Open Science Framework (OSF)",
    "section": "Contact - Support options for VU researchers",
    "text": "Contact - Support options for VU researchers\nThe following hierarchy of support options is available if you run into problems or have questions about using the OSF.\n\nTry the OSF Guides first, they are quite extensive. Quick start up guide for VU OSF users is available in the section Getting started.\nIf the answer to your question is not in the OSF Guides or if you run into a technical problem, you can contact OSF support directly via the contact form. As a member of OSF institutions, VU users receive priority support.\nContact the application managers through Contact Research Data Support - VU Service Portal (category; RDM tools and subcategory: OSF) if you have questions with regard to the operation of VU OSF or more general questions about Research Data Management."
  },
  {
    "objectID": "topics/qualtrics.html",
    "href": "topics/qualtrics.html",
    "title": "Qualtrics",
    "section": "",
    "text": "Qualtrics is a cloud-based subscription and software platform (SaaS) that enables users to create and manage online surveys. The Qualtrics survey tool can support a variety of (complex) survey design requirements by providing such functionalities as different question types, display and branching logic configuration and the use of embedded data and APIs."
  },
  {
    "objectID": "topics/qualtrics.html#what-is-it",
    "href": "topics/qualtrics.html#what-is-it",
    "title": "Qualtrics",
    "section": "",
    "text": "Qualtrics is a cloud-based subscription and software platform (SaaS) that enables users to create and manage online surveys. The Qualtrics survey tool can support a variety of (complex) survey design requirements by providing such functionalities as different question types, display and branching logic configuration and the use of embedded data and APIs."
  },
  {
    "objectID": "topics/qualtrics.html#what-can-it-be-used-for",
    "href": "topics/qualtrics.html#what-can-it-be-used-for",
    "title": "Qualtrics",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nAll VU students, employees and researchers are eligible to make use of a Qualtrics licence. VU’s Qualtrics licence usage is limited for creating, managing and collecting data for scientific research purposes only.\nQualtrics should not be used for non-scientific purposes such as the creation of registration or attendance lists and course evaluation surveys for example; instead users should go to other available tools such as MS Forms.\nVU Amsterdam holds an academic licence which includes non-standard, advanced features and functions, including but not limited to:\n\nFILE UPLOAD – a non-standard question type that allows respondents to upload a file along with their survey response\nSIGNATURE QUESTION – a non-standard question type that presents survey participants with an entry box where they can draw their signature.\nAPI INTEGRATION – an advanced licence feature that can be used to automate repetitive processes inside of Qualtrics or to pass information in and out of Qualtrics.\nOFFLINE SURVEY APP – an advanced licence feature that comprises a downloadable application available for iOS and Android that allows you to administer surveys on your mobile device or tablet without an internet connection."
  },
  {
    "objectID": "topics/qualtrics.html#how-to-request-access",
    "href": "topics/qualtrics.html#how-to-request-access",
    "title": "Qualtrics",
    "section": "How to request access",
    "text": "How to request access\n\nCreating and Accessing User Accounts\nVU Amsterdam Qualtrics Central Brand (hereafter VU’s Central Brand) at vuamsterdam.eu.qualtrics.com allows for user’s auto-enrolment, an automated account creation and registration process. Any user with an enabled VU email address may auto-enroll on VU’s Central Brand. The email address will function as the account’s username.\nVU’s Central Brand makes use of Single-Sign On (SSO). This means that users can log in to Qualtrics using VU’s internal login system. Multi-Factor Authentication (MFA) is mandatory to all Qualtrics users utilising the vuamsterdam brand (i.e. employees and researchers – students will be informed of upcoming project for MFA implementation). MFA acts as an additional layer of security to prevent unauthorised users from accessing accounts and resources, even when the password has been stolen. Qualtrics will use multi-factor authentication to validate user identity and provide quick and convenient access to authorised users.\nTo create a user account and access the Qualtrics environment at the Central Brand, please proceed as follows:\n\nGo to: https://vuamsterdam.eu.qualtrics.com\nOn the login page, choose: Vrije Universiteit SSO\nLog in with your VU account credentials (email address and password)\n\n\n\nVU’s central brand login page\n\n\nChoose “No, I don’t have a preexisting account here” when it is your first time enrolling the central brand\n\n\n\nQualtrics preexisting account\n\n\nClick [Sign In]\n\n\n\nQualtrics account created successfully\n\n\nTerms of Service or General Terms and Conditions for Qualtrics Services are presented for review and acceptance.\n\n\n\nQualtrics terms conditions\n\n\n\n\nIt is recommended to save VU’s Central Brand as a Favourite or Bookmark link for future reference.\n\n\n\nNote to Existing Users\n\nSecurity Settings: Login Error Disabled Account\nSecurity settings are in place that disable a user account after a certain amount of inactivity. This threshold is currently 12 months. This setting follows security requirements regarding User Account Management.\n\n\n\nNotification of disabled Qualtrics account\n\n\nA disabled account status does not affect its data.\nUsers who receive an error when trying to log back in after extended periods of inactivity ([User account is disabled]) should contact the RDM Support Desk to have their accounts re-enabled."
  },
  {
    "objectID": "topics/qualtrics.html#are-there-costs-involved",
    "href": "topics/qualtrics.html#are-there-costs-involved",
    "title": "Qualtrics",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThere are no costs involved. All students and researchers with a VU email address enabled can use Qualtrics for scientific purposes."
  },
  {
    "objectID": "topics/qualtrics.html#getting-started",
    "href": "topics/qualtrics.html#getting-started",
    "title": "Qualtrics",
    "section": "Getting Started",
    "text": "Getting Started\nThe following resources are available for you to get started with Qualtrics:\n\nQualtrics Basecamp\nbasecamp.qualtrics.com, the online learning platform where you have access to learning instructions on how to use Qualtrics.\n\n\nQualtrics Knowledge Base\nQualtrics offers access to an extensive library of knowledge base articles, including detailed instructions on how to use and configure (advance) features.\nQualtrics Knowledge Base library can be accessed directly at qualtrics.com/support\n\n\nQualtrics Community\nAsk questions to the Qualtrics community (platform of all Qualtrics users).\nWhen logging in choose “Sign in with SSO”, when asked “Enter your company’s Organization ID” fill in vuamsterdam."
  },
  {
    "objectID": "topics/qualtrics.html#contact",
    "href": "topics/qualtrics.html#contact",
    "title": "Qualtrics",
    "section": "Contact",
    "text": "Contact\nThe following support channels are available:\n\nFor general queries on how to use the tool, including the configuration of advanced features, please refer to the online documentation at the Qualtrics website.\nFor questions concerning survey design and faculty policies with regards to the usage of Qualtrics for your specific research area, please contact your faculty Data Steward/Privacy Champion (see Qualtrics Faculty Contact – Division Managers). Students should contact their course coordinator.\n\nIf you cannot login or encounter an error, for example when using collaboration or email distribution functionalities, please contact the RDM Support Desk (an FAQ is not available at the moment, but we are working on it)."
  },
  {
    "objectID": "topics/data-publishing.html",
    "href": "topics/data-publishing.html",
    "title": "Data Publishing",
    "section": "",
    "text": "When we mention data publishing at VU Amsterdam, we mean the following:\n\nMaking research data, associated metadata, accompanying documentation, and software code (where relevant) accessible in a repository in such a manner that they can be discovered on the Web and referred to in a unique and persistent way (Inspired by the definition in the CODATA Research Data Management Terminology).\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for publishing all research data that leads to a published result (either in an article or other narrative form) for scientific reuse, meaning that these materials can be discovered on the Web and referred to in a unique and persistent way. This means that the existence of a dataset is announced and that basic information about this dataset (like title, creator, moment of publication, etc.) can be found online, but it doesn’t necessarily mean that others will be able to access and download the actual data. The level of accessibility to the data must be determined during the publication process. If data or software contain confidential information, information to which intellectual properties apply, and/or personal data, an assessment must take place to determine whether these data can be made available for reuse and if so, under which conditions. A custom licence (‘restricted’ or ‘closed’) will indicate if conditional access can be granted, and if so, what the conditions are."
  },
  {
    "objectID": "topics/data-publishing.html#what-is-data-publishing",
    "href": "topics/data-publishing.html#what-is-data-publishing",
    "title": "Data Publishing",
    "section": "",
    "text": "When we mention data publishing at VU Amsterdam, we mean the following:\n\nMaking research data, associated metadata, accompanying documentation, and software code (where relevant) accessible in a repository in such a manner that they can be discovered on the Web and referred to in a unique and persistent way (Inspired by the definition in the CODATA Research Data Management Terminology).\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for publishing all research data that leads to a published result (either in an article or other narrative form) for scientific reuse, meaning that these materials can be discovered on the Web and referred to in a unique and persistent way. This means that the existence of a dataset is announced and that basic information about this dataset (like title, creator, moment of publication, etc.) can be found online, but it doesn’t necessarily mean that others will be able to access and download the actual data. The level of accessibility to the data must be determined during the publication process. If data or software contain confidential information, information to which intellectual properties apply, and/or personal data, an assessment must take place to determine whether these data can be made available for reuse and if so, under which conditions. A custom licence (‘restricted’ or ‘closed’) will indicate if conditional access can be granted, and if so, what the conditions are."
  },
  {
    "objectID": "topics/data-publishing.html#purpose",
    "href": "topics/data-publishing.html#purpose",
    "title": "Data Publishing",
    "section": "Purpose",
    "text": "Purpose\nData publishing is crucial for the accessibility of research output. It helps to make VU Amsterdam’s research visible, verifiable and, where possible, reusable. These are important goals for VU Amsterdam, as they contribute to a transparent reseach practice and enable other researchers to build on work that has been done by VU researchers. Publishing data means that researchers make their datasets known to the world, even if they cannot be accessed by others directly, but only after granting conditional access. This enables other researchers reusing these data, leading to more impact of research that is carried out at VU Amsterdam. It may also result in new collaborations. Another advantage is that it makes the work of a researcher more visible, going beyond the visibility of a publication alone."
  },
  {
    "objectID": "topics/data-publishing.html#requirements",
    "href": "topics/data-publishing.html#requirements",
    "title": "Data Publishing",
    "section": "Requirements",
    "text": "Requirements\nAt VU Amsterdam, we strive to make our research data FAIR. Publishing data is a crucial step in making data findable. As explained in the definition above, publishing means that you make data discoverable on the internet. As a result, other researchers can find out about the existence of your dataset and consider whether it may be useful for them in their own research.\nA persistent identifier helps in making data findable, because it ensures that the persistent identifier always resolves to the correct digital object. Rich metadata also contribute to the findability of a dataset. The more information you provide, the more likely it is that others will be able to find your dataset. It is beneficial to use terminology that is common in your discipline when filling out the metadata fields in a repository. Rich information about your dataset will also help other researchers determine whether your dataset is potentially relevant for them.\nRepositories provided by VU Amsterdam (Yoda and DataverseNL) will generate a Persistent Identifier for your dataset and they will ask you to fill out metadata fields. In this way, they contribute to making your data findable. This will also be the case for external trusted repositories.\nWhen you publish your data, it is important to apply a licence to it. If you don’t do that, others will not be allowed to reuse your data. A licence is a legal instrument that tells others what they can and cannot do with your data and is therefore an important aspect of making data reusable."
  },
  {
    "objectID": "topics/data-publishing.html#how-does-data-publishing-work-in-practice",
    "href": "topics/data-publishing.html#how-does-data-publishing-work-in-practice",
    "title": "Data Publishing",
    "section": "How does data publishing work in practice?",
    "text": "How does data publishing work in practice?\nAs mentioned above, data publishing must happen through a repository. Detailed workflows addressing publishing data can be found in the guides about making your data FAIR and archiving and publishing data."
  },
  {
    "objectID": "topics/software-archiving.html",
    "href": "topics/software-archiving.html",
    "title": "Software Archiving",
    "section": "",
    "text": "When we mention data archiving at VU Amsterdam, we mean the following:\n\nCreation of a secure and immutable copy of research data, associated metadata, accompanying documentation, and software code (where relevant) with the intention to ensure (conditional) access for a predetermined, minimum, period of time.\n\nIn the case of software archiving the software code takes the place of research data in the above quote. The two main differences are the inclusion of a version number in the metadata and the distinction of user and developer documentation.\nAs stated in the Research Data and Software Management Policy, researchers are responsible for archiving all research software and data that leads to a published result (either in an article or other narrative form) in a trusted repository for a period of at least ten years after this publication, unless legal requirements, discipline-specific guidelines or contractual arrangements dictate otherwise."
  },
  {
    "objectID": "topics/software-archiving.html#what-is-software-archiving",
    "href": "topics/software-archiving.html#what-is-software-archiving",
    "title": "Software Archiving",
    "section": "",
    "text": "When we mention data archiving at VU Amsterdam, we mean the following:\n\nCreation of a secure and immutable copy of research data, associated metadata, accompanying documentation, and software code (where relevant) with the intention to ensure (conditional) access for a predetermined, minimum, period of time.\n\nIn the case of software archiving the software code takes the place of research data in the above quote. The two main differences are the inclusion of a version number in the metadata and the distinction of user and developer documentation.\nAs stated in the Research Data and Software Management Policy, researchers are responsible for archiving all research software and data that leads to a published result (either in an article or other narrative form) in a trusted repository for a period of at least ten years after this publication, unless legal requirements, discipline-specific guidelines or contractual arrangements dictate otherwise."
  },
  {
    "objectID": "topics/software-archiving.html#purpose",
    "href": "topics/software-archiving.html#purpose",
    "title": "Software Archiving",
    "section": "Purpose",
    "text": "Purpose\nSoftware archiving is a vital approach to allow research to be verified and reproduced. Verification is important for a transparent research practice, a value VU Amsterdam is strongly committed to. Software is typically used to clean and analyse datasets gathered or recorded by researchers, meaning it is a fundamental part of the research process. Archiving your software ensures that software will be preserved for the long term and can be accessed, even when the Principal Investigator or other members of the research team are no longer available at VU Amsterdam.\nProper software archiving transforms research software from temporary project tools into lasting scientific contributions that continue to generate value long after the original project concludes, supporting both individual career development and broader scientific progress."
  },
  {
    "objectID": "topics/software-archiving.html#requirements",
    "href": "topics/software-archiving.html#requirements",
    "title": "Software Archiving",
    "section": "Requirements",
    "text": "Requirements\nAt VU Amsterdam, we strive to make our research software FAIR. When research software is archived in a repository provided by VU Amsterdam (Yoda or DataverseNL), the following requirements apply:\n\nThe software must be provided with associated Metadata using the VU Minimal metadata guide;\nThe software must have a Persistent identifier (or Identifiers) to increase findability;\nA licence must be applied to the data and software in order to indicate if it can be reused by others and if so, under which conditions. Without a license the software cannot be used in future research as easily;\nThe software must be accompanied by documentation, both user and developer. User documentation should cover installation and basic use, whereas developer documentation should cover how it works and why certain design decisions were made.\n\nIf you use an external repository, these requirements are useful to keep in mind as well, because they make the software FAIR to a large extent, but in that case you will have to rely on the properties of the repository.\nSince code can be written in any number of ways to solve a problem, the absolute minimum that should be archived to ensure verification is a (working) copy of the code (or workflow) that takes the raw data to the end result and a list of the dependencies and their versions."
  },
  {
    "objectID": "topics/software-archiving.html#how-does-software-archiving-work-in-practice",
    "href": "topics/software-archiving.html#how-does-software-archiving-work-in-practice",
    "title": "Software Archiving",
    "section": "How does software archiving work in practice?",
    "text": "How does software archiving work in practice?\nData archiving must happen in a repository. This means that data storage solutions for during research, like Research Drive, are not suitable for software archiving. They don’t generate a Persistent Identifier and do not ask for metadata or a licence. Code repositories like GitHub and GitLab fall under the label of development environments: They have the possibility to include a DOI and metadata, but do not require it. As a result, VU Amsterdam recommends using the following services for archiving research software:\n\nZenodo: Long-term preservation with permanent DOIs, integrated with GitHub for automatic archiving\nDataverseNL: For software associated with published datasets and research outputs\nYoda: For data and software associated with research; note that this is not by default publicly accessible.\n\nA more complete form of software archiving involves capturing not just the source code, but also the complete software environment, dependencies, documentation, and metadata necessary to understand, execute, and maintain the software over time. This includes preserving information about the runtime environment, operating system requirements, library dependencies, and usage instructions. As a result, unlike regular backup or version control, software archiving specifically focuses on long-term preservation to combat software decay and technological obsolescence."
  },
  {
    "objectID": "topics/software-archiving.html#how-does-this-help-you-in-your-research",
    "href": "topics/software-archiving.html#how-does-this-help-you-in-your-research",
    "title": "Software Archiving",
    "section": "How does this help you in your research?",
    "text": "How does this help you in your research?\nArchiving is a form of preservation and preserving your work means it remains accessible and usable for the rest of the research community for longer. This will allow greater levels of research continuity and help to avoid duplication of code reducing research time and costs in your field. Correctly archiving will include a DOI, licence, documentation, and metadata allowing you to receive more citations and professional recognition, avoid legal disputes on sharing your work, open you up to global collaboration, meet requirements needed for additional funding and publications, and makes knowledge transfer easier.\nA detailed workflow for archiving is available in the guide about archiving and publishing data."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The Open Handbook is a project started by Research Data Support in early 2024. After planning and design phases, we launched the initial version of the resource at the Research Support Days in May 2024.\nThe Open Handbook centralizes resources that VU researchers need to do their work. The Open Handbook also provides everyone with direct guides to change resources in case anything has become outdated.\nPreviously such resources were spread out across many different pages at VU and were hard to update. The Open Handbook is curated by us all, and reviewed by specialists. This way we can help each other.\n\n\nThe Open Handbook was initiated by Lena Karvovskaya, Jessica Hrudey, Elisa, and Jolien Scholten. The initial infrastructure for the Open Handbook was built by Liberate Science. Guide images are by Bres and Bittner (2024).\nWe want to specifically call out the following folk who contributed outside of GitHub:\n\nDiogenes Cruz de Arcelino\nJochem Lybaart\nJochem Nijs\nRebecca Silva dos Santos\n\n\n\n\n\n\nAll contributions to this project are gratefully acknowledged using the allcontributors package following the all-contributors specification. Contributions of any kind are welcome!\n\n\n\n   chartgerink\n\n\n   Jolien-S\n\n\n   Elisa-on-GitHub\n\n\n   peer35\n\n\n   Karvovskaya\n\n\n   meronvermaas\n\n\n   jensdebruijn\n\n\n\n\n   jhrudey\n\n\n   timveken\n\n\n   Alex-van-der-Jagt\n\n\n   Dimitri-Unger\n\n\n   charliegreene9\n\n\n   Sergi095\n\n\n   TMHofstra\n\n\n\n\n   imartorelli\n\n\n   CMOGUZ\n\n\n   KirianneG\n\n\n   MarkBruyneel\n\n\n   olindensen77\n\n\n   zesloth\n\n\n   vansteph\n\n\n\n\n   ELNijland\n\n\n   gus-mxx\n\n\n   emilybarabas-vu\n\n\n   reinout538\n\n\n   MarcelRas-391\n\n\n   D-Unger\n\n\n   sarnoult\n\n\n\n\n   davor-cc\n\n\n   tmunker\n\n\n   Kostusas\n\n\n   dtk-10"
  },
  {
    "objectID": "about.html#contributors",
    "href": "about.html#contributors",
    "title": "About",
    "section": "",
    "text": "The Open Handbook was initiated by Lena Karvovskaya, Jessica Hrudey, Elisa, and Jolien Scholten. The initial infrastructure for the Open Handbook was built by Liberate Science. Guide images are by Bres and Bittner (2024).\nWe want to specifically call out the following folk who contributed outside of GitHub:\n\nDiogenes Cruz de Arcelino\nJochem Lybaart\nJochem Nijs\nRebecca Silva dos Santos\n\n\n\n\n\n\nAll contributions to this project are gratefully acknowledged using the allcontributors package following the all-contributors specification. Contributions of any kind are welcome!\n\n\n\n   chartgerink\n\n\n   Jolien-S\n\n\n   Elisa-on-GitHub\n\n\n   peer35\n\n\n   Karvovskaya\n\n\n   meronvermaas\n\n\n   jensdebruijn\n\n\n\n\n   jhrudey\n\n\n   timveken\n\n\n   Alex-van-der-Jagt\n\n\n   Dimitri-Unger\n\n\n   charliegreene9\n\n\n   Sergi095\n\n\n   TMHofstra\n\n\n\n\n   imartorelli\n\n\n   CMOGUZ\n\n\n   KirianneG\n\n\n   MarkBruyneel\n\n\n   olindensen77\n\n\n   zesloth\n\n\n   vansteph\n\n\n\n\n   ELNijland\n\n\n   gus-mxx\n\n\n   emilybarabas-vu\n\n\n   reinout538\n\n\n   MarcelRas-391\n\n\n   D-Unger\n\n\n   sarnoult\n\n\n\n\n   davor-cc\n\n\n   tmunker\n\n\n   Kostusas\n\n\n   dtk-10"
  },
  {
    "objectID": "index.html#upcoming-events",
    "href": "index.html#upcoming-events",
    "title": "Research Support Handbook",
    "section": "Upcoming events",
    "text": "Upcoming events"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Subscribe to the blog via RSS.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew Manuals section in the Handbook\n\n\n\nHandbook\n\nYoda\n\n\n\n\n\n\n\n\n\nJul 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nITvO blog\n\n\n\nIT for Research\n\n\n\n\n\n\n\n\n\nJul 24, 2025\n\n\nSergio Gutierrez, Peter Vos\n\n\n\n\n\n\n\n\n\n\n\n\nSixth Handbook Hackathon\n\n\n\nHandbook\n\nHackathon\n\n\n\n\n\n\n\n\n\nJul 24, 2025\n\n\nEmily Barabas, Diógenes Cruz de Arcelino, Kirianne Goossen, Charlie Greene, Sergio Gutierrez Maury, Sam Heijnen, Marcel Ras, Elisa Rodenburg, Jolien Scholten, Dimitri Unger, Peter Vos\n\n\n\n\n\n\n\n\n\n\n\n\nHow to embed handbook pages using iframes\n\n\n\nHandbook\n\n\n\n\n\n\n\n\n\nMay 19, 2025\n\n\nChris Hartgerink, Elisa Rodenburg, Jessica Hrudey\n\n\n\n\n\n\n\n\n\n\n\n\nFifth Handbook Hackathon\n\n\n\nHandbook\n\nHackathon\n\n\n\n\n\n\n\n\n\nNov 28, 2024\n\n\nLena Karvovskaya, Jolien Scholten, Kostas Vilkelis, Tycho Hofstra, Irene Martorelli, Peter Vos\n\n\n\n\n\n\n\n\n\n\n\n\nFourth Handbook Hackathon\n\n\n\nHandbook\n\nHackathon\n\n\n\n\n\n\n\n\n\nNov 1, 2024\n\n\nChris Hartgerink, Lena Karvovskaya, Jolien Scholten, Tycho Hofstra, Elisa Rodenburg, Stephanie van de Sandt\n\n\n\n\n\n\n\n\n\n\n\n\nWhy was rdm.vu.nl down for ten hours?\n\n\n\nHandbook\n\n\n\n\n\n\n\n\n\nOct 22, 2024\n\n\nChris Hartgerink, Lena Karvovskaya\n\n\n\n\n\n\n\n\n\n\n\n\nThird Handbook Hackathon\n\n\n\nHandbook\n\nHackathon\n\n\n\n\n\n\n\n\n\nSep 30, 2024\n\n\nAlex van der Jagt, FGB, sec. KNOP, Chris Hartgerink (host), Diogenes Cruz de Arcelino, Elisa Rodenburg, UBVU, Jessica Hrudey, FGB, Jolien Scholten, UB, Lena Karvovskaya, UBVU, Stephanie van de Sandt, UBVU, Tycho Hofstra, UBVU\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Handbook Hackathon\n\n\n\nHandbook\n\nHackathon\n\n\n\n\n\n\n\n\n\nSep 5, 2024\n\n\nAlex van der Jagt, Chris Hartgerink, Elisa Rodenburg, Jens de Bruijn, Jolien Scholten, Joy Jiayi Cheng, Lena Karvovskaya, Meron Vermaas, Peter Vos, Stephanie van de Sandt, Tycho Hofstra\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Handbook Hackathon\n\n\n\nHandbook\n\nHackathon\n\n\n\n\n\n\n\n\n\nJun 27, 2024\n\n\nAlex van der Jagt, Chris Hartgerink, Dimitri Unger, Elisa Rodenburg, Jessica Hrudey, Jolien Scholten, Lena Karvovskaya, Lucy O’ Shea, Mar Barrantes-Cepas, Meron Vermaas, Peter Vos, Stephanie van de Sandt\n\n\n\n\n\n\n\n\n\n\n\n\nHello world!\n\n\n\nHandbook\n\n\n\n\n\n\n\n\n\nMay 23, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "guides/process-and-analyse.html",
    "href": "guides/process-and-analyse.html",
    "title": "How can you ensure data provenance and accurate data analysis?",
    "section": "",
    "text": "Provenance describes the origin of an object. Data provenance refers to the knowledge of where data originate, where they were collected, by whom, for what reason, and similar aspects that help to understand how the data were originally gathered, processed and altered. In daily use, the term “data provenance” refers to a record trail that accounts for the origin of a piece of data (in a database, document or repository) together with an explanation of how and why it got to the present place (Encyclopedia of Database Systems, pp 608-608). You can also call it the process of keeping records of changes in the data. The need for Data Provenance increases as the reuse of datasets becomes more common in research. The term was originally mostly used in relation to works of art, but is now used in similar senses in a wide range of fields (Wikipedia).\n\nResearchers regularly use a lab notebook or a journal to document their hypotheses, experiments and initial analysis or interpretation of these experiments. If you manually change data in a dataset, this should also be documented. Sometimes records of changes in data can be kept by adding notes to programmes or scripts that are used.\n\nElectronic Lab Journals or Electronic Lab Notebooks are used to meticulously describe and document the process of analysis. Mostly used used in a laboratory environment,; biolab, chemical lab, etc.\nFor computational analyses, Computational Notebooks like Jupyter notebook are used, where you can describe the analysis steps alongside the computer code in different languages like Python, R, Spark, etc. It is important to document steps and changes in your code by writing comments. This way, others and future you can understand how your code works.\nThe Open Science Framework connects different storage types you already use (for example, Dataverse) and logs automatically all changes of all the steps you make while you progress. With the fine grained history-log and version control system of OSF, you can see all steps you made. You can store and archive the whole provenance trail for citable reproducibility.\n\nFinally, when a dataset contains personal data, data provenance can help researchers to understand the specifics and the context in which the data were gathered, also to be able to assess whether or not the informed consent given for the first research, is applicable.\nFor every step of your data analysis, good Data Documentation is necessary."
  },
  {
    "objectID": "guides/process-and-analyse.html#data-provenance",
    "href": "guides/process-and-analyse.html#data-provenance",
    "title": "How can you ensure data provenance and accurate data analysis?",
    "section": "",
    "text": "Provenance describes the origin of an object. Data provenance refers to the knowledge of where data originate, where they were collected, by whom, for what reason, and similar aspects that help to understand how the data were originally gathered, processed and altered. In daily use, the term “data provenance” refers to a record trail that accounts for the origin of a piece of data (in a database, document or repository) together with an explanation of how and why it got to the present place (Encyclopedia of Database Systems, pp 608-608). You can also call it the process of keeping records of changes in the data. The need for Data Provenance increases as the reuse of datasets becomes more common in research. The term was originally mostly used in relation to works of art, but is now used in similar senses in a wide range of fields (Wikipedia).\n\nResearchers regularly use a lab notebook or a journal to document their hypotheses, experiments and initial analysis or interpretation of these experiments. If you manually change data in a dataset, this should also be documented. Sometimes records of changes in data can be kept by adding notes to programmes or scripts that are used.\n\nElectronic Lab Journals or Electronic Lab Notebooks are used to meticulously describe and document the process of analysis. Mostly used used in a laboratory environment,; biolab, chemical lab, etc.\nFor computational analyses, Computational Notebooks like Jupyter notebook are used, where you can describe the analysis steps alongside the computer code in different languages like Python, R, Spark, etc. It is important to document steps and changes in your code by writing comments. This way, others and future you can understand how your code works.\nThe Open Science Framework connects different storage types you already use (for example, Dataverse) and logs automatically all changes of all the steps you make while you progress. With the fine grained history-log and version control system of OSF, you can see all steps you made. You can store and archive the whole provenance trail for citable reproducibility.\n\nFinally, when a dataset contains personal data, data provenance can help researchers to understand the specifics and the context in which the data were gathered, also to be able to assess whether or not the informed consent given for the first research, is applicable.\nFor every step of your data analysis, good Data Documentation is necessary."
  },
  {
    "objectID": "guides/process-and-analyse.html#data-processing",
    "href": "guides/process-and-analyse.html#data-processing",
    "title": "How can you ensure data provenance and accurate data analysis?",
    "section": "Data processing",
    "text": "Data processing\n\nData cleaning\nThe process of detecting and correcting (or removing) corrupt or inaccurate information or records, is called data cleaning. In essence, it refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting this data (Wikipedia). Depending on the type of analysis that is done, different pieces of software can be used to do this data cleaning. More often than not, the same software can also be used to perform the analysis. Licensed software may sometimes also be installed on personal computers or laptops.\n\nSoftware especially designed to clean re-used data is OpenRefine. It cleans starting and trailing blank spaces in cell field, clusters values based on similarities (e.g. in free text fields: Alphen a/d Rhijn, alfen ad rijn, etc. can be easily clustered), normalise data fields into one standard, etc. See below for several tutorials.\nIn some cases, researchers write their own scripts (in programming languages such as Python, R or SQL) to clean data, in which case the process must be documented. Researchers should include their scripts when they archive the datasets to allow for replication and verification.\nExtra background information:\n\nEMGO Quality Handbook on data cleaning\nMaking sense of data I: a practical guide to exploratory data analysis and data mining / Glenn J. Myatt, Wayne P. Johnson, 2014 (eBook)\nOpen Refine\n\nData Carpentry Open Refine website\nTutorial by the Programming Historian\nIntroduction to Digital Humanities with Open Refine\n\n\nFor every step of your data cleaning, good documentation and clarifying the data provenance is necessary.\n\n\nData transcription\nIt is common in many fields to hold interviews, focus group sessions, or make other observations that were recorded - video or audio. If indeed you have done so, and you need to have the text transcribed, there are several ways to do this. One option is to do this by hand, although this is very time-consuming.\nAnother option is to pay a transcription service to make the transcription or to use specialised software. VU Amsterdam has drawn up processing agreements with one transcription service, Transcript Online, and one transcription software service, Amberscript.\nYou can find more information on the VU Library page on what these transcription options do, how they work, how much they cost, and how they can be used.\n\n\nAnonymisation/Pseudonymisation\nProcessing of personal data requires you as a researcher to make sure that any personal data collected from a human subject is according to the EU GDPR regulation. Anonymisation and Pseudonymisation are two ways to make personal data less easy to identify, in other words, it allows you to de-identify personal data.\nThere are various online tools that may help facilitate these processes. VU Amsterdam has therefore recommended Amnesia as one of the tools to assist in the anonysmisation/pseudonymistaion of data.\nVU Amsterdam is preparing a decision guide on anonymisation and pseudonymisation."
  },
  {
    "objectID": "guides/process-and-analyse.html#data-analysis",
    "href": "guides/process-and-analyse.html#data-analysis",
    "title": "How can you ensure data provenance and accurate data analysis?",
    "section": "Data analysis",
    "text": "Data analysis\n\nData Analysis\nAlthough data analysis is an ongoing process throughout the research project, this page focuses on the analysis of the data subsequent to its collection. To ensure that research is empirical and verifiable, it is crucial that researchers keep records (data documentation) of every step made during the data analysis.\nData analysis converts raw/processed data into information that is useful for understanding. Many steps may be required to gain useful information from raw data. The process of processing and analysing data may require computing power not readily available or specific storage and protection options. If multiple parties are involved in the analysis, data sharing may also be necessary.\nData analysis often requires the use of specialised software.The software offered and licensed by the university currently includes: Stata, SPSS, and Atlas.TI. For open software, see below.\nIn some cases researchers write their own scripts to analyse the data. At VU Amsterdam, most scripts are written in R, Python and SQL.\nIf you want to read up on data analysis you should check out what journal articles and books VU Amsterdam library has available on the subject:\n\nAll sources: Data analysis\nQuantitative data analysis\nQualitative data analysis\nBig data\nData mining\n\n\n\nOpen Software\nUsing open software increases the Accessiblity, Interoperability and Reusability of your data. For that reason, we recommend that you use open software as much as possible for your data analysis. This could be software, code or scripts that you have written yourself - where possible, please make this software public, so your analysis is reproducible. Examples of open software are R and Python, which can be used instead of proprietary, commercial software such as SPSS and Matlab.\nResearchers often write their software themselves. There are also organisations that specialise in writing research software, such as the eScience Center. The eScience Center offers the software they built for free use online. Their software is tagged with a DOI and stored in Zenodo as well as GitHub.\nIf you use software for analysing personal or otherwise sensitive data, you need a processing agreement with the developer if the software does not run locally. You can contact your 🔒 Privacy Champion if you are not sure if you need one, and for help to set up a processing agreement.\nThere are several ways in which to start using open software:\n\nFor Python: you should install Anaconda and launch the Jupyter Notebook from the Navigator.\nFor R: you should install Anaconda and launch R Studio from the Navigator.\nUse the Software Carpentries to learn the basics of programming in Python and R and version control with Git\nRead the recommendations for FAIR Software.\n\nVU Amsterdam has several research groups that offer their code online. You can find them here:\n\nThe Systems Bioinformatics research group, on GitHub\nThe Computational Lexicology & Terminology Lab, on GitHub\nThe course Python for Text Analysis, on GitHub\nVU RDM Tech IT group, on GitHub\nA list of RDM tools, on GitHub\n\n\n\nCompute services\n\nIf your pc or laptop takes too much time performing your analysis, it is time to scale up to a higher level. There are several options for employees and students who require more computing power than their own desktop or laptop can provide.\nSeveral options are detailed below. 🔒 Contact IT for Research for advice on which solution could best fit your workflow\n\nHigh Performance Computing (HPC)\n\n\n\nA set of servers in an undescript room\n\n\nRoughly speaking, you should try to get access to the HPC when you need to stick a post-it on your laptop or PC that says: “do not touch, analysis ongoing”. Or when you want to run analyses parallel to each other, because they take too long. It is important to consider such a situation at the very beginning of your research or when writing your Data Management Plan: is it conceivable that your dataset will become so large or your analysis so complicated that you will need HPC? Please note that this can occur for any discipline and any sort of data, qualitative and quantitative. If you may need HPC, you also need to reconsider your analysis methods. Programmes like SPSS and Excel do not run well on a HPC, and you would need to (learn to) write scripts in R or Python. If you want to know if using HPC may be necessary or useful for your project, you can contact IT for Research to ask for more information (select the “Onderzoek service domain”).\n\n\nSURF Snellius Compute Cluster\nSnellius is the Dutch National supercomputer hosted at SURF. The system facilitates scientific research carried out in many Universities, independent research institutes, governmental organizations, and private companies in the Netherlands.\nIt’s a service comprising a wide range of resources, compilers and, such as R statistics and MATLAB, and libraries. SURF continually adjusts the service to the needs of the user community. For example, Snellius Compute Cluster includes accelerators (very fast processors),high memory nodes and GPU nodes. \nYou can find more information on the SURF Snellius Wiki.\n\n\nADA Compute Cluster\nIT for Research (ITvO) offers access to your own Linux computational cluster at VU Amsterdam. ADA is a managed service for high performance computing (HPC). Research groups can add their own compute server hardware to ADA, ITvO will take care of configuring and maintaining the software stack on your servers.\nADA also has several “community” nodes for use by all VU researchers, sponsored by VU Amsterdam HPC Council.\nADA is connected to SciStor  providing easy access to your research data and analysis result.\n\n\nVU JupyterHub for education\nIf you are not yet ready to take the leap to cluster computing and work with Python consider JupyterHub. VU IT has built a Jupyter Notebook environment meant mainly for Education purposes, but accessible for researchers as well on https://hub.compute.vu.nl/\n\n\n(Virtual) servers\nThere are also several options to run applications in a server environment. This is useful if for example you use software that does not work on HPC, you want to run a web service, you want to create a research environment for your project. There are several options available for researchers.\n\nSciCloud\nIT for Research (ITvO) offers a virtual server environment where you can run your own server (Linux or Windows). ITvO installs the basic operating system and you are free to install needed software. Web services can be made accessible on the internet. You can find more information and a request form on the 🔒 VU service portal\n\n\nSURF Research Cloud\nSURF also offers a virtual server environment. Several environments with pre-installed software can easily be installed from a catalog. Find more information on the SURF wiki.\n\n\nDedicated hardware\nSometimes your workload needs dedicated hardware. ITvO offers the option to host your own server hardware in our on-campus data center. Please 🔒 Contact IT for Research to discuss possibilities."
  },
  {
    "objectID": "guides/use-osf.html",
    "href": "guides/use-osf.html",
    "title": "How can you use Open Science Framework (OSF) in your research project?",
    "section": "",
    "text": "In the introduction video below, you can see how Open Science Framework (OSF) supports the Open Research Lifecycle."
  },
  {
    "objectID": "guides/use-osf.html#osf-information-for-new-users",
    "href": "guides/use-osf.html#osf-information-for-new-users",
    "title": "How can you use Open Science Framework (OSF) in your research project?",
    "section": "OSF information for new users",
    "text": "OSF information for new users\nMany manuals are available for using OSF. They are listed below for the different types of functionality that OSF provides.\n\nBest Practices\n\nFile Management and Licensing\n\nFile naming (OSF Projects) - OSF Support\nOrganising files (OSF Projects) - OSF Support \nLicensing - OSF Support \nVersion Control Version Control - OSF Support\n\n\n\nResearch Design\n\nPreregistration Preregistration - OSF Support\nCreating a data management plan (DMP) Creating a data management plan (DMP) document - OSF Support\n\n\n\nHandling Data\n\nHow to Make a Data Dictionary How to Make a Data Dictionary - OSF Support\nSharing Research Outputs Sharing Research Outputs - OSF Support\nSharing data Data Management - OSF Support\n\n\n\nPreprints\n\nWelcome to OSF Preprints (Video) - OSF&gt; Support\n\n\n\nCreating and Managing OSF Projects\n\nManaging projects (OSF Projects) - OSF&gt; Support\n\n\n\n\nThe Open Scholarship Knowledgebase (OSKB)\nResource guides on reproducibility: oercommons.org/curated-collections/1038\n\n\nCurated Reading List of Metascience\nThe Center for Open Science (COS) has compiled a list of papers related to the need for more transparent research and the effectiveness of such research practices. You can find the list on their Open Science Literature page. The list includes literature on the following aspects:\n\nBeneﬁts of transparency\nData sharing policies and practices\nReporting Standards, Guidelines, and Checklists\nEffects of preregistration or Registered Reports\nQuestionable research practices\nThe Reproducibility Crisis\nEvaluating Journals Policies\nRecommendations for Increasing Reproducibility\nAttitudes about open science\n\n\n\nOvercoming the Knowledge Barrier\nOn their page Overcoming the Knowledge Barrier(osf.io/bk6r7/wiki](https://osf.io/bk6r7/wiki/home/), the Center for Open Science provides a lot of information to get started with an open and reproducible research practice. This page lists a lot of resources to get you up to speed with open science practices:\n\nPrimers on implementing open science practices\nTutorials and online curricula for coded statistical analysis\nLinks to open science communities\n\n\n\nCenter for Open Science content\n\nBlog series\nWebinars\nResources for researchers\n\n\n\nPreregistration\n\nWhat is preregistration?\n\nIt is the act of specifying in advance how data will be collected and analysed.\nPreregistrations are time-stamped, immutable documents.\nPreregistrations make the distinction between hypothesis testing, conﬁrmatory research and hypothesis generating, exploratory research more clear.\nPresenting exploratory results as conﬁrmatory increases the publish ability of results at the expense of credibility of results.\n\n\n\nHow to preregister?\nThe Preregistration Challenge was an education campaign designed to introduce preregistration as a regular habit. It includes a guided workﬂow to help you create a preregistration.\nSee the COS Preregistration page for more information about preregistration and start working on your own preregistration in OSF Registries.\n\n\n\nResources and Further Readings\n\nCan you preregister if you are using existing data? Yes, see template available at osf.io/registries\n“The Preregistration Revolution”, which covers nine challenging situations in which preregistration is beneﬁcial\nA blog series about preregistration\nThe Guardian: Trust in science would be improved by study pre-registration\nNature: A manifesto for reproducible science\nA presentation from a community member introducing OSF\nA helpful OSF presentation on how to create your first works"
  },
  {
    "objectID": "guides/use-osf.html#connecting-storage-and-apps",
    "href": "guides/use-osf.html#connecting-storage-and-apps",
    "title": "How can you use Open Science Framework (OSF) in your research project?",
    "section": "Connecting storage and apps",
    "text": "Connecting storage and apps\nOSF allows you to connect to other storage platforms and services via Add-ons, see the OSF Add-ons and integrations Guide for more information. Storage Add-ons are particularly well suited for data sharing in a project. However, please consider the following when adding them to your project:\n\nwhat data (folders) is being shared;\nwho this resource is being shared with and;\nwho manages the Add-on (e.g. how long will it be available).\n\nRecommended connected storage options are Research Drive (how-to guide) and SURFdrive (how-to guide). The VU discourages using Dropbox and Google Drive for storing research data.\nFor projects with a Code component creating connections to GitHub repos is a good idea, see the OSF Guide. If you just want to publish a GitHub repo itself consider using Zenodo, see this guide.\nYou can also connect a dataset in DataverseNL to your project, so published datasets can be viewed in OSF. You can even upload to and delete files from datasets in Draft (how-to guide).\nRemember, everyone who has access to your project will be able to see the files in the storage folder you connect, even if you have not explicitly shared the files on the source location!"
  },
  {
    "objectID": "guides/use-osf.html#metadata-recommendation",
    "href": "guides/use-osf.html#metadata-recommendation",
    "title": "How can you use Open Science Framework (OSF) in your research project?",
    "section": "Metadata recommendation",
    "text": "Metadata recommendation\nVU Amsterdam has a minimal metadata guide that describes which mandatory, recommended and optional properties VU researchers should use if they publish their data in any repository. These properties and their explanation are given below for OSF. See also the OSF | VU OSF Documentation Wiki.\nProperties and their explanation\nM Considered mandatory for findability of your dataset and correct registration in Pure\nR Recommended for optimal findability\nO Optional\n\n\n\nProperty\nObligation\nExplanation\nRemarks\n\n\n\n\nDOI\nR\n\nOSF Guide\nIf you want to be able to cite your project it is best to create a DOI for it.\n\n\nTitle\nM\nA descriptive title for your dataset, should not be longer than about 200 characters\n\n\n\nContributors\nM\nThe main researchers involved in producing the data, in priority order.\nOSF Guide.\nMake sure to check \"Bibliographic Contributor\". You can adjust the order of the contributors.\nPlease ask Contributors to fill in their employment status in their user profile to set their affiliation. Users logging in with their VUnetID will automatically be affiliated with the VU.\nAdding ORCID or other researcher identifiers to contributor profiles is also highly recommended.\n\n\nTags\nM\nProvide a list of keywords describing your dataset. This will make it easier to find your dataset on the internet.\nSome repositories will have controlled term lists to choose from.\nOSF Guide\n\n\nCategory\nM\nChoose the most appropriate category for your project\n\n\n\nLicense\nM\nChoose the most appropriate license for your project.\nOSF Guide\nFor most content and data \"CC-By 4.0 International\" is a good choice, but especially in the case of code you might look into a more appropriate license.\n\n\n\nBased on VU minimal metadata guidelines version rc2 2022-07-20"
  },
  {
    "objectID": "guides/use-osf.html#working-with-sensitive-data",
    "href": "guides/use-osf.html#working-with-sensitive-data",
    "title": "How can you use Open Science Framework (OSF) in your research project?",
    "section": "Working with sensitive data",
    "text": "Working with sensitive data\nActively choose \"Germany - Frankfurt\" in the account settings as default storage location when you start a new project. Your research data will be stored in the EU jurisdiction.\nMulti-Factor Authentication (MFA) via de SURFsecureID (with the tiqr app or a YubiKey) is enabled for all users who log in with VUnetID credentials for improved security and protection of your research data.\nOSF has implemented several measures (e.g. OSF storage encryption, regular backups, Standard Contractual Clauses) to increase security of your stored research data as well as guarantee GDPR compliance.\nThe OSF is developed to facilitate Open Science and sharing of digital research objects. Medium-level sensitive data (e.g. research data that score ‘medium’ at confidentiality in a data classification, research proposals) can be stored, provided it is available only to a specific group of users. VU Amsterdam does not recommend you to store privacy-sensitive data in OSF. For this type of data, please use a more suitable platform such as Research Drive or Yoda. If there is no other suitable way to share a file with privacy-sensitive data, make sure you encrypt the file(s) before you upload them to the OSF. A good way to do this is by adding the files to a password-protected zip file (how-to guide). Storing data that score ‘high’ or ‘very high’ on confidentiality in a data classification (e.g. directly identifying information, all special category personal data, classified information, data about vulnerable people, key files) is prohibited. Please contact the RDM Support Desk.\nIn case of a security incident or data leak, the data breach response plan is available. Please report possible incidents at OSF Support and always at the VU IT Servicedesk via email or phone: 020 598 0000.\nMore information on the OSF security policy and implemented measures can be found on OSF Guide."
  },
  {
    "objectID": "guides/use-osf.html#retaining-access-to-your-data-when-leaving-vu-amsterdam",
    "href": "guides/use-osf.html#retaining-access-to-your-data-when-leaving-vu-amsterdam",
    "title": "How can you use Open Science Framework (OSF) in your research project?",
    "section": "Retaining access to your data when leaving VU Amsterdam",
    "text": "Retaining access to your data when leaving VU Amsterdam\nIf you want to retain access to your OSF Projects, you could create a new account with a personal email address. Then merge this account with your institutional account, see the OSF Guide. Do this while your VUnetID is still active!\nIf your VUnetID has already expired, you can still create a new OSF account and ask a Project Admin to re-add you to the Projects.\nIf your VUnetID has expired and you are the only Project Admin please contact OSF Support.\n\nDeleting your account\nYou’re always welcome to deactivate or delete your account. If you would like to delete your OSF account and personal data, please email OSF Support."
  },
  {
    "objectID": "guides/publish-and-share.html",
    "href": "guides/publish-and-share.html",
    "title": "How can you archive and publish your data?",
    "section": "",
    "text": "In the Data Management Plan the researcher describes if the data will be stored for the mid or the long term.\n\n\n\nA monochrome picture of two women operating the ENIAC, an early computer\n\n\n\n\nAccording to the VU Research Data and Software Management Policy, all publication-related data should be archived for at least ten years for verification and replication of research. For this purpose, VU Amsterdam offers researchers two options to archive their data in one of the organisational repositories (DataverseNL and Yoda). Other archival options may be used depending on the discipline as described in faculty data management policy documents.\n\n\n\nData relevant for future research should be archived for the long term. A dataset is relevant for future research when at least one of the following general criteria applies:\n1. The data have a scientific or historical value 2. The data are unique 3. Others may want to reuse the data 4. The data cannot be reproduced\nResearchers should bear in mind that repositories can charge for archiving data. These costs can vary according to the data volume and the archive used. It is important that you consider in advance how you will budget for these costs. Whatever archiving option is used, proper descriptions of the dataset(s) and adding metadata are important.\n\n\n\n\nVU Amsterdam requests that researchers archive the data used in a publication in a repository for at least ten years after the release of the publication (see also VU Policies & Regulations). There are a lot of digital archives and many more keep appearing.\nThe right archival option depends on the nature of the data and the field of science as described in faculty or departmental data management policy documents. The university offers 2 different general repositories for data archiving. The RDM Support Desk and faculty data stewards can help researchers with the selection of a repository that meets all the relevant criteria of privacy (sensitivity), dataset size, etc.\n\nDataverseNL - an online platform for the publication of citable research data in a semi-open environment. DataverseNL allows users to link publications to datasets directly, and to share the data through online archives such as DANS.\n\nSpecifications:\n\nFor publishing research data on the internet\nThe researcher publishing the data decides whether access to the data is public or restricted\nNot suitable for privacy or otherwise sensitive information\nEnables researchers to publish open data according to grant providers’ regulations\nGenerates a link (persistent identifier), e.g. for data citations in publications\nRetention period is at least 10 years\n\n\nYoda - besides active storage, Yoda also has an archive function: the vault. You can use the vault in two ways:\n\n\nFor archiving data securely; data are only available for verification purposes and may be access only by special request. A special procedure will be followed if anyone requests access to the data in order to verify them.\nFor publishing data; data can be available for anyone, or on request. The data will get a persistent identifier as well.\n\nBefore sending data to the vault, you will need to add metadata. A data steward, metadata specialist or functional manager can help you with the metadata and the entire process of sending data to the vault. Please get in touch with the RDM Support Desk to find this help.\n\n\n\nBesides the repositories offered by VU Amsterdam, there are many others. Unless you are working with personal or otherwise confidential data and you need to archive them in Yoda, you are, in principle, free to choose a different repository from the ones hosted by VU Amsterdam.\nThere can be various reasons to decide to use a different repository, including funder requirements, preferences of research partners, and a repository being a common choice in your field. For example, Dutch archaeologists mostly use DANS Data Stations to deposit and publish their data. Using a repository that is a common choice in your field will make your data more findable for your colleagues and increase the visibility of your work as a researcher. Some of the data repositories most commonly used in the Netherlands include:\n\nDANS Data Stations: a collection of four domain-specific repositories hosted by the Data Archiving and Networked Services (DANS), an institute of NWO and KNAW (Koninklijke Nederlandse Akademie van Wetenschappen). They have Data Stations for Social Sciences and Humanities, Archaeology, Life Sciences, and Physical and Technical Sciences. DANS also develops policies, services and new infrastructures for research data and provides researchers with advice on how to preserve their data. VU researchers are also welcome to deposit their data at DANS Data Stations;\n4TU.ResearchData: a repository for science, engineering and design data hosted by the 4TU Federation. This is a consortium of the four Dutch technical universities: TU Delft, TU Eindhoven, University of Twente and Wageningen University and Research. VU researchers are also welcome to deposit their data at 4TU;\nZenodo: a domain-agnostic research data repository hosted by CERN in Switzerland and funded by the European Commission. Zenodo does not only host data, but also presentations, conference procedures and policy documents. It is also possible to archive GitHub repositories directly into Zenodo, by which you contribute to Open Science by making a snapshot of your code available in its current form and for the long term;\nOSF (Open Science Framework): a data management and research dissemination platform. VU Amsterdam is an institutional member of the OSF, which means that you can sign up (and in) using your VU account by clicking on the Institution Button on the sign in/up pages. You can use the OSF to create registrations and preregistrations for your research, to publish preprints, and publish and share data and documentation. You can also link other repositories such as DataverseNL to your OSF project. The same goes for GitHub and storage options such as Research Drive and Surfdrive. Do be careful about what you connect! A full guide for VU OSF users, including instructions about connecting external storage can be found here.\n\nYou can also find repositories via the Registry of Research Data Repositories. When you are choosing a repository, it is important to check that it provides all the services you need. A good way to find out is to check if a repository as a Core Trust Seal, which is a form of certification for quality repositories. But if a repository does not have the Core Trust Seal, it does not necessarily mean it is not a good repository. As a minimum, you should check that:\n\nThe repository provides a persistent identifier, such as a DOI;\nThe repository enables you to add rich metadata to your dataset and ideally follows an internationally recognised metadata standard, such as Dublin Core or DataCite;\nThe repository offers functionality to publish data with an embargo or under restrictions, if you need that;\nThe repository allows you to add a licence to the dataset;\nThe repository is funded sustainably for at least the next 50 years;\nAnd, in some cases, that the repository’s servers are located in the EU.\n\nMore recommendations for choosing a data repository can be found on CESSDA.\nIf you would like advice about what would be a good place for you to archive your research data, you can always reach out to the RDM Support Desk."
  },
  {
    "objectID": "guides/publish-and-share.html#selecting-an-archive",
    "href": "guides/publish-and-share.html#selecting-an-archive",
    "title": "How can you archive and publish your data?",
    "section": "",
    "text": "In the Data Management Plan the researcher describes if the data will be stored for the mid or the long term.\n\n\n\nA monochrome picture of two women operating the ENIAC, an early computer\n\n\n\n\nAccording to the VU Research Data and Software Management Policy, all publication-related data should be archived for at least ten years for verification and replication of research. For this purpose, VU Amsterdam offers researchers two options to archive their data in one of the organisational repositories (DataverseNL and Yoda). Other archival options may be used depending on the discipline as described in faculty data management policy documents.\n\n\n\nData relevant for future research should be archived for the long term. A dataset is relevant for future research when at least one of the following general criteria applies:\n1. The data have a scientific or historical value 2. The data are unique 3. Others may want to reuse the data 4. The data cannot be reproduced\nResearchers should bear in mind that repositories can charge for archiving data. These costs can vary according to the data volume and the archive used. It is important that you consider in advance how you will budget for these costs. Whatever archiving option is used, proper descriptions of the dataset(s) and adding metadata are important.\n\n\n\n\nVU Amsterdam requests that researchers archive the data used in a publication in a repository for at least ten years after the release of the publication (see also VU Policies & Regulations). There are a lot of digital archives and many more keep appearing.\nThe right archival option depends on the nature of the data and the field of science as described in faculty or departmental data management policy documents. The university offers 2 different general repositories for data archiving. The RDM Support Desk and faculty data stewards can help researchers with the selection of a repository that meets all the relevant criteria of privacy (sensitivity), dataset size, etc.\n\nDataverseNL - an online platform for the publication of citable research data in a semi-open environment. DataverseNL allows users to link publications to datasets directly, and to share the data through online archives such as DANS.\n\nSpecifications:\n\nFor publishing research data on the internet\nThe researcher publishing the data decides whether access to the data is public or restricted\nNot suitable for privacy or otherwise sensitive information\nEnables researchers to publish open data according to grant providers’ regulations\nGenerates a link (persistent identifier), e.g. for data citations in publications\nRetention period is at least 10 years\n\n\nYoda - besides active storage, Yoda also has an archive function: the vault. You can use the vault in two ways:\n\n\nFor archiving data securely; data are only available for verification purposes and may be access only by special request. A special procedure will be followed if anyone requests access to the data in order to verify them.\nFor publishing data; data can be available for anyone, or on request. The data will get a persistent identifier as well.\n\nBefore sending data to the vault, you will need to add metadata. A data steward, metadata specialist or functional manager can help you with the metadata and the entire process of sending data to the vault. Please get in touch with the RDM Support Desk to find this help.\n\n\n\nBesides the repositories offered by VU Amsterdam, there are many others. Unless you are working with personal or otherwise confidential data and you need to archive them in Yoda, you are, in principle, free to choose a different repository from the ones hosted by VU Amsterdam.\nThere can be various reasons to decide to use a different repository, including funder requirements, preferences of research partners, and a repository being a common choice in your field. For example, Dutch archaeologists mostly use DANS Data Stations to deposit and publish their data. Using a repository that is a common choice in your field will make your data more findable for your colleagues and increase the visibility of your work as a researcher. Some of the data repositories most commonly used in the Netherlands include:\n\nDANS Data Stations: a collection of four domain-specific repositories hosted by the Data Archiving and Networked Services (DANS), an institute of NWO and KNAW (Koninklijke Nederlandse Akademie van Wetenschappen). They have Data Stations for Social Sciences and Humanities, Archaeology, Life Sciences, and Physical and Technical Sciences. DANS also develops policies, services and new infrastructures for research data and provides researchers with advice on how to preserve their data. VU researchers are also welcome to deposit their data at DANS Data Stations;\n4TU.ResearchData: a repository for science, engineering and design data hosted by the 4TU Federation. This is a consortium of the four Dutch technical universities: TU Delft, TU Eindhoven, University of Twente and Wageningen University and Research. VU researchers are also welcome to deposit their data at 4TU;\nZenodo: a domain-agnostic research data repository hosted by CERN in Switzerland and funded by the European Commission. Zenodo does not only host data, but also presentations, conference procedures and policy documents. It is also possible to archive GitHub repositories directly into Zenodo, by which you contribute to Open Science by making a snapshot of your code available in its current form and for the long term;\nOSF (Open Science Framework): a data management and research dissemination platform. VU Amsterdam is an institutional member of the OSF, which means that you can sign up (and in) using your VU account by clicking on the Institution Button on the sign in/up pages. You can use the OSF to create registrations and preregistrations for your research, to publish preprints, and publish and share data and documentation. You can also link other repositories such as DataverseNL to your OSF project. The same goes for GitHub and storage options such as Research Drive and Surfdrive. Do be careful about what you connect! A full guide for VU OSF users, including instructions about connecting external storage can be found here.\n\nYou can also find repositories via the Registry of Research Data Repositories. When you are choosing a repository, it is important to check that it provides all the services you need. A good way to find out is to check if a repository as a Core Trust Seal, which is a form of certification for quality repositories. But if a repository does not have the Core Trust Seal, it does not necessarily mean it is not a good repository. As a minimum, you should check that:\n\nThe repository provides a persistent identifier, such as a DOI;\nThe repository enables you to add rich metadata to your dataset and ideally follows an internationally recognised metadata standard, such as Dublin Core or DataCite;\nThe repository offers functionality to publish data with an embargo or under restrictions, if you need that;\nThe repository allows you to add a licence to the dataset;\nThe repository is funded sustainably for at least the next 50 years;\nAnd, in some cases, that the repository’s servers are located in the EU.\n\nMore recommendations for choosing a data repository can be found on CESSDA.\nIf you would like advice about what would be a good place for you to archive your research data, you can always reach out to the RDM Support Desk."
  },
  {
    "objectID": "guides/publish-and-share.html#alternative-strategies",
    "href": "guides/publish-and-share.html#alternative-strategies",
    "title": "How can you archive and publish your data?",
    "section": "Alternative strategies",
    "text": "Alternative strategies\n\nPublishing your data in a data journal\nInstead of archiving research data in a data repository, you may choose to publish an article about your data collection. This is not necessarily common for all disciplines. Some examples of data journals where you can publish your data and dataset, are:\n\nScientific Data - Nature\nGeoscience Data Journal\nGigascience\nJournal of Physical and Chemical Reference Data\nEarth System Science Data\nJournal of Open Archaeology Data\nJournal of Open Psychology Data\n\n\n\nPublishing your data as supplementary information with your article\nAnother way to make your data available, is to add them as supplementary information with your article in a journal. At first sight, this may seem a practical solution, because the publication and the underlying data in that case appear together as part of a single publication. However, making your data available as a seperate piece of research output has other advantages:\n\nThe dataset will be citable on its own, which also enables you to get acknowledged for the work on your dataset\nDatasets with many files or many different types of files are easier to structure and present in a repository\nYou can assign different levels of accessibility (unrestricted, restricted or closed) if necessary, which is not possible in a publication\nYou don’t transfer copyright of your data publication to the publisher of your article\n\nIf you make your data available through a repository, you can link from your article to your dataset and the other way around, so that you can present them as related research output."
  },
  {
    "objectID": "guides/publish-and-share.html#persistent-identifier",
    "href": "guides/publish-and-share.html#persistent-identifier",
    "title": "How can you archive and publish your data?",
    "section": "Persistent Identifier",
    "text": "Persistent Identifier\nA Persistent Identifier (PID) is a durable reference to a digital dataset, document, website or other object. In the context of research data and software, it is essentially a URL that will never break. By using a Persistent Identifier, you make sure that your dataset will be findable well into the future when it is registered online (for example at DataCite. Another advantage is that it makes a digital object citable.\n\nMultiple PID systems\nThere are multiple PID systems, each with its own particular properties. Examples of widely used PIDs in the research domain include the following.\n\nDOI: A Digital Object Identifier can be used to refer to research data, research software and publications.\nORCiD: An Open Researcher and Contributor ID is used to create a researcher profile with a unique identification number.\nROR: The Research Organization Registry is a global register with persistent identifiers for research institutes.\n\nSee the Persistent Identifier guide of Netwerk Digitaal Erfgoed for a more elaborate overview. Apart from widely used domain-agnostic PIDs, there is a wide range of domain-specific unique identifiers that can be used. If you are interested in domain-specific identifiers, it is useful to ask colleagues in your department or discipline.\n\n\nPersistent Identifiers for data and software in repositories\nPersistent Identifiers can be assigned to datasets and software upon their deposit in a repository. In many repositories, this is a DOI. Data repositories are entitled to generate Persistent Identifiers for data and software. This is one of the reasons why archiving and publishing data and software has to be done in a repository. After the process of uploading data or software to a repository, a Persistent Identifier will be generated. Upon publishing the data or software, the DOI is registered online (usually at DataCite when it concerns a dataset).\nSome repositories enable their users to reserve a Persistent Identifier before the publishing process has finished, so that you can include the Persistent Identifier in a publication before the data will be actually published, or to include the Persistent Identifier in a readme file. This is for example possible in Zenodo.\nThe repositories offered by VU Amsterdam, Yoda and DataverseNL provide DOIs for deposited datasets and software.\n\n\nCreating and using an ORCiD\nResearchers can use an ORCiD to identify their research output as their work. You can request an ORCiD yourself. Instructions for setting up an ORCiD and connecting it to your VU research profile in PURE are available in this ORCiD LibGuide. An ORCiD is often asked for when you submit a publication or upload data or software to a repository. You can use your ORCiD record to create a research profile as well.\n\n\nUsing a ROR\nResearchers can use the ROR for VU Amsterdam when filling metadata forms for their research output to show that their work has been created within their employment at VU Amsterdam."
  },
  {
    "objectID": "guides/publish-and-share.html#licensing-data-and-software",
    "href": "guides/publish-and-share.html#licensing-data-and-software",
    "title": "How can you archive and publish your data?",
    "section": "Licensing data and software",
    "text": "Licensing data and software\n\nIntroduction\nA data licence agreement is a legal instrument that lets others know what they can and cannot do with a particular dataset (and any documentation, scripts and metadata that are published with the data - information about software licensing can be found on the software licensing page). It is important to consider what kind of limitations are relevant. Usually, at least the following questions are considered:\n\nCan people make copies or even distribute copies?\nDo others (and you) reusing the dataset need to acknowledge you as the author of the original dataset? (This is called Attribution.)\nDo others (and you) who reuse the dataset and/or make derivatives of the dataset need to share their work under a similar licence? (This is called Share-Alike.)\nCan others (and you) use your dataset commercially? (A restriction on commercial use is called Non-Commercial.)\nCan others (and you) create a new work based on the dataset? (This is called a Derivative.)\n\nThe considerations above are the ‘building blocks’ that Creative Commons licences use. There are also other considerations, and also other licences.\n\n\n\nAn image of open data, made up of public domain icons\n\n\n\n\nReusing existing data\nIf you wish to reuse data collected by others (this could be data you received from for example Statistics Netherlands or from a company, a dataset you have found in an online repository, commonly used databases for which VU Amsterdam has a licence, etc.), make sure that you read the licence or terms of use. Also make sure that you work with the data according to the licence or terms of use. This can mean different things depending on the licence, but common things to consider are for example:\n\ncite the data in an appropriate manner;\ndo not share the data beyond the project/purpose for which you received them;\nshare the outcome of your research based on the data under a similar licence;\nonly use them for scientific purposes (and not for commercial purposes, for example).\n\nIf you have questions about the legal context of using an existing dataset, you can contact the RDM Support Desk or the legal experts at IXA VU.\n\n\nLicensing data\nIf you want to make your data available for other (research) purposes, it is important to apply a licence to it. Without a licence, it is impossible for others to reuse your data without your explicit approval. When you deposit your data in a repository, the repository will usually ask you to select a standard licence, or to create and add a custom licence yourself. If you need help with drawing up licence agreements, you can contact the VU’s legal office.\n\nDataverseNL\nIn DataverseNL you can choose your terms of use when uploading data to the repository. The DataverseNL user guide explains how licensing works in the repository.\n\n\nYoda\nIf you publish your data in Yoda, there is guidance available on how to choose a licence and how to customise licences.\n\n\nOpen Science Framework (OSF)\nIn OSF, you can apply a standard licence to your materials or upload your own custom licence. The OSF user guide explains both options.\n\n\nExternal repositories\nSome data repositories require you to use a certain licence if you want to deposit your data with them. At Dryad, for example, all datasets are published under the terms of Creative Commons Zero to minimise legal barriers and to maximise the impact for research and education. Some funders may also require that you publish the data as open data. Open data are data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and share alike (Open Knowledge International definition).\n\n\n\nAdditional websites and tools:\n\nExplanation about copyrights and licences by a professor from Leiden University (English subtitles available)\nThe Guide to Creative Commons for Scholarly Publishing and Educational Resources by NWO, VSNU and the University and Royal Libraries\nDCC how-to guide on licensing research data, a guide that links to the Creative Commons website, where many terms are explained\nOpen Data Commons Public Domain Dedication and License (PDDL)\nEUDAT B2SHARE licence selection wizard, which Pawel Kamocki (et al.) released under an open source licence.1\n\n\n\nLicensing software\nPublishing research software under an appropriate licence is crucial for its accessibility, usability, and further integration into research. Choosing a licence usually happens right when you start developing the software or when you put it in a public repository, rather than when the software is finished and fully baked.\nA software licence states how other people may re-use your code and under which circumstances. For research software, it is recommended (and often required by funders) that licences are as permissible as possible.\nThere are many licences out there; below we list some very frequently used licences in research software. However, if none of these licences fit your case, there are several tools that can help you to choose a suitable software licence. If you need guidance in choosing a licence for your software, get in touch with the RDM Support Desk.\n\n\nMIT License\nThe MIT License is a popular choice, due to its readability and permissiveness. It allows users to reuse the software for any purpose, including using, copying, modifying, and distributing it, provided they include the original copyright notice and licence text.\nHowever, its permissiveness means that derivative works can be closed-source and do not need to mention that they use your code, which might not align with all scientific openness goals or general.\n\n\nGNU GPLv3\nThe GNU General Public License (GPLv3) is another option, designed to ensure that the software and any derivatives remain open-source.\nThis encourages collaborative improvement of software. Any software that includes GPL-licensed code must also be open-source under the GPLpotentially deterring commercial use or integration with proprietary software. In conclusion, when you want your code to be used by others, but only the code that uses your code is also open source, this is the way to go.\n\n\nApache License 2.0\nThe Apache License 2.0 allows for modification and distribution of the software and its derivative works, with the requirement that changes to the original code are documented.\nIt is a more complex licence than the MIT License and can be incompatible with GPL-licensed software. The specifics of this go beyond the scope of the handbook.\n\n\nAdding a licence to GitHub\nOn GitHub you add a licence on creating a new repository, by selecting the licence from the drop-down menu. If your repository already exists, add a new file called “LICENSE” using the “+”-button on top of the repository (see below).\n\n\n\nLocation of file creation button\n\n\nOne the next page, start to type LICENSE as the file name, and a button to “Choose a license template” should automatically pop up. Follow the steps provided by GitHub to finish adding the licence to the repository.\nYou should now see your licence shown on the main page of your repository.\n\n\nFurther considerations\n\nIf you are reusing software or libraries written by someone else, you must stick to the clauses of the licence given to the original software/library;\nWhen choosing a licence, do not just think about what others may do with the software, but also what you might want to do with the software in the future."
  },
  {
    "objectID": "guides/publish-and-share.html#dataset-registration",
    "href": "guides/publish-and-share.html#dataset-registration",
    "title": "How can you archive and publish your data?",
    "section": "Dataset Registration",
    "text": "Dataset Registration\n\nRegister your Data in PURE\nJust like your publications, data that you have collected for your research constitutes research output, too. Therefore you are required to record your data in PURE.2 Your data can be of interest to others, which can in turn lead to new collaboration opportunities. Data recorded in PURE also appear in reports that are used for research evaluations. Even if access to your data is closed, you are required to register your data in PURE. It is a record of the research, data collection and analysis that you have carried out.\n\nBenefits of recording your data in PURE\n\nIt increases the visibility and findability of your data\nIt contributes to re-use and transparency\nIt boosts your collaboration opportunities\nIt counts towards research evaluations and assessments\n\n\n\nHow to register your data in PURE?\n\n\n\nAn image of PURE, indicating where to add a new dataset\n\n\n\nLog into the VU PURE using your VU credentials\nClick on the “+” (plus) icon next to selecting “Datasets/Software” in the overview\nYou can fill in the form using the following manuals and read more about the various metadata in use (generic and subject specific):\n\ndataset manual (NL)\n\nClick on “Save” to store the registration"
  },
  {
    "objectID": "guides/publish-and-share.html#footnotes",
    "href": "guides/publish-and-share.html#footnotes",
    "title": "How can you archive and publish your data?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the source code, see https://github.com/ufal/public-license-selector/↩︎\n“Researchers are responsible for ensuring that a description of archived and published data and software is included in the ‘Current Research Information System’ (CRIS) of VU Amsterdam. In most cases, this is done automatically. Researchers should be able to provide information about data and software in an Availability statement.” Responsibility number 8 from the Research Data and Software Management Policy↩︎"
  },
  {
    "objectID": "guides/data-lifecycle.html",
    "href": "guides/data-lifecycle.html",
    "title": "What research data services and support are available for VU researchers?",
    "section": "",
    "text": "Vrije Universiteit Amsterdam is providing a range of data management solutions and support services, offered by various departments and support teams. An overview of these services is shown in the Research Data Management, Tools and services video below.\nResearch Data Management is supported by various departments at VU Amsterdam, all providing support on the topics shown in the overview above. Apart from that, all faculties have teams providing research data support for their own faculty members. In most cases this is the first line of support for researchers to start their inquiries."
  },
  {
    "objectID": "guides/data-lifecycle.html#vu-research-data-support-services-and-teams",
    "href": "guides/data-lifecycle.html#vu-research-data-support-services-and-teams",
    "title": "What research data services and support are available for VU researchers?",
    "section": "VU Research Data support services and teams",
    "text": "VU Research Data support services and teams\n\nFaculty support\nA faculty or institute research data management professional is a primary point of contact for any questions related to research data management (RDM). This can be a Data Steward, Data Manager or RDM coordinator. The VU website provides a list of all faculty support professionals.\n\n\nRDM Support Desk and library support professionals\nThe RDM Support Desk provides practical assistance, help and advice with any RDM- and RDM tools related questions, for example about: writing a data management plan, making your research FAIR, grants and RDM costs, training and workshops, data storage, data and software archiving and publishing, GDPR and the use of RDM tools like Yoda and Research Drive. In case your faculty or institute does not have a designated support officer, the RDM Support Desk is the go-to place.\nYou can contact the RDM Support Desk via the VU Research Data Support service portal (only for VU employees) or via rdm@vu.nl. You can also find a list of professionals of the RDM Support Desk on the VU website.\n\n\nPrivacy Champions\nPrivacy Champions are colleagues who are the first point of contact for all questions regarding privacy and data protection related topics. They can help you with the most common privacy questions, for example: can we process this personal data without consent of the data subjects? Is this software application suitable for the processing of sensitive personal data? An overview of all faculty and department Privacy Champions is provided on the 🔒 Privacy Champion who-is-who page.\n\n\nIT for Research (ITvO)\nThe expertise center research IT is a primary point of contact for questions related to compute services, high performance computing and local storage of large data volumes. ITvO will help you to find a suitable technical solution or support for your research group or project. You can find more information about the VU Compute Hub, the ADA high performance compute cluster, the VU local storage solution SciStor and server capacity on SciCloud in other Handbook topics. You can read more about the services ITvO provides on the ITvO topic page.\n\n\nVU Grants Office\nThe Grants Office provides advice on various types of national and international, individual and consortium grants: From complex multidisciplinary applications with multiple partners such as Horizon Europe, NWO Gravitation and NWA, to renowned individual grants such as NWO Veni, Vidi, Vici and ERC Starting, Consolidator and Advanced grants. The Grants Office gives advice throughout the grant application process and during the term of the subsidy. You can read more about the VU Grants Office on the 🔒 VU Amsterdam Grants Office page.\n\n\nLegal advice\nIf you need advice on legal and administrative matters, you can contact the team of Institutional and Legal Affairs. This is the VU legal enquiry centre. They can provide advice on a wide range of issues, for example: How do you arrange for personal data to be processed safely and carefully? How to set up contracts in collaborative research projects? What happens with the research results? Can each party use the other parties’ results? You can find out more about legal support at the Institutional and Legal Affairs pages.\n\n\nInformation Security Officers (ISOs)\nBefore the start of a new research project, it is necessary to assess the risks associated with the data that will be collected and/or used in the project. Classifying research data enables researchers to protect the data in an appropriate manner. What is relevant, is that the security level matches the identified risks. This enables the researcher to determine where the data may or may not be processed and under which conditions.\nThe IT Information and Security Officers (ISO) can help you with these security matters related to data protection and the use of the right software solutions. The RDM Support Desk or a faculty Privacy Champion is the first point of contact on these matters. If necessary, they will contact the ISO Office for further advice.\nOther helping aids in data-classification and classification policies are the Data Classification Tool and the Policy Classification of Research Data."
  },
  {
    "objectID": "guides/data-lifecycle.html#research-process-overview",
    "href": "guides/data-lifecycle.html#research-process-overview",
    "title": "What research data services and support are available for VU researchers?",
    "section": "Research process overview",
    "text": "Research process overview\nUse this detailed research process overview to get more information about steps that may occur during the research process and the support offered at VU Amsterdam for these steps. This overview is very detailed and starts at the earliest stages of identifying research and funding opportunities, and ends at the point of preparing communication about your research. We recommend to read the README and Instructions tabs first before you dive in. For questions, you can also reach the RDM Support Desk\nGeneral Faculty research support and management guidelines are available in the section Policies & Regulations."
  },
  {
    "objectID": "guides/data-lifecycle.html#decision-support-tools",
    "href": "guides/data-lifecycle.html#decision-support-tools",
    "title": "What research data services and support are available for VU researchers?",
    "section": "Decision support tools",
    "text": "Decision support tools\nThere are multiple data storage options that can be used, each with its own functionality and purpose. The Data Storage Finder is a tool that will give you a number of storage options suitable for your research. For more individual guidance, please get in touch with the RDM Support Desk) for advice, particularly when you are working with commercial, personal or otherwise sensitive data, or when you have a complex IT setup.\nThe Data Classification Tool helps in assessing the risks associated with research data and provides feedback on what measures need to be undertaken to protect the data."
  },
  {
    "objectID": "guides/data-lifecycle.html#communities",
    "href": "guides/data-lifecycle.html#communities",
    "title": "What research data services and support are available for VU researchers?",
    "section": "Communities",
    "text": "Communities\nResearchers and research support staff who are interested in research data management and want to find out more about it are welcome to join the RDM Community of VU Amsterdam. The objective of the network is to exchange knowledge and inspire each other. You can find out more about the community and its activities on the community pages.\nIf you want to meet other researchers, improve your programming skills, or ask questions related to programming, you can join the Monthly Programming cafe, Bytes & Bites. At Bytes & Bites anyone is welcome, whether you are a beginner or advanced programmer, whether you write in R or in C++. Find out more about this community on the Bytes and Bites Github pages."
  },
  {
    "objectID": "guides/data-lifecycle.html#training",
    "href": "guides/data-lifecycle.html#training",
    "title": "What research data services and support are available for VU researchers?",
    "section": "Training",
    "text": "Training\nOn the Training page you will find a complete overview of trainings and workshops provided by VU support staff. The page also contains information about open science games that you can set up yourself."
  },
  {
    "objectID": "guides/data-lifecycle.html#other-information-resources",
    "href": "guides/data-lifecycle.html#other-information-resources",
    "title": "What research data services and support are available for VU researchers?",
    "section": "Other information resources",
    "text": "Other information resources\nThere are numerous useful information resources on research data management available. Some of them are general and discipline-agnostic, others are strongly focussing on specific research disciplines or research data types. Below we have listed a number of these resources which can help you to learn more on research data management and related topics.\n\nThe Turing way is an open-source, community-driven handbook aimed at promoting best practices in reproducible, ethical and collaborative data science. It is a valuable resource for information on data management, data security and research projects in general.\nThe CESSDA Data Management Expert Guide is designed by European experts to help social science researchers make their research data Findable, Accessible, Interoperable and Reusable (FAIR). The guide is written for social science researchers who are in an early stage of practising research data management. The guide describes a lot of practical approaches to research data management which are useful for other domains as well.\nGO FAIR is a stakeholder-driven and self-governed initiative that aims to implement the FAIR principles. It offers numerous resources about how to make research data FAIR and how to organise communities.\nThe course Essentials 4 Data Support, developed by Research Data Netherlands, is an introductory program designed for professionals who want to assist researchers in storing, managing, archiving, and sharing their research data. Although the course is designed for data support professionals, it provides many online useful resources on various data management topics for researchers as well."
  },
  {
    "objectID": "guides/publishing-fair-software.html",
    "href": "guides/publishing-fair-software.html",
    "title": "How can you publish FAIR software",
    "section": "",
    "text": "This document provides some pointers that can help to set you up with a coding repository that follows the FAIR guiding principles, meaning Findability, Accessibility, Interoperability, and Reuse of digital assets. It is not meant to be an exhaustive guide for every step, but rather acts as a starting point and links to more exhaustive sources."
  },
  {
    "objectID": "guides/publishing-fair-software.html#introduction",
    "href": "guides/publishing-fair-software.html#introduction",
    "title": "How can you publish FAIR software",
    "section": "",
    "text": "This document provides some pointers that can help to set you up with a coding repository that follows the FAIR guiding principles, meaning Findability, Accessibility, Interoperability, and Reuse of digital assets. It is not meant to be an exhaustive guide for every step, but rather acts as a starting point and links to more exhaustive sources."
  },
  {
    "objectID": "guides/publishing-fair-software.html#publishing-online",
    "href": "guides/publishing-fair-software.html#publishing-online",
    "title": "How can you publish FAIR software",
    "section": "Publishing online",
    "text": "Publishing online\nResearch code (or other code) is best stored on a git repostory, like GitHub or GitLab. Both platforms are is used by millions of programmers and researchers around the world. To upload your code to GitHub/GitLab, you first need to make an account here. Once you have an account, you can create a repository that hosts your code.\nGitHub: You can create a free account. In addition, as a university employee, you can use your university email address to get a free “Pro” account, which gives you access to some additional features. You can find more information at the GitHub Education platform. GitLab: As VU employee, you can access GitLab using your VU credentials (VUnetID) by logging in through the VU portal.\n\nCreating a repository\nGitHub: After logging in, click your profile picture on the top right -&gt; “Your repositories” -&gt; “New”. Choose a name and set the visibility (do you want everyone to see your code already or wait a bit before sharing with the world?). It is common practice to immediately add a “README” file and add a licence (see next section). You can update the visibility of your repository later under the repository settings.\nGitLab: After logging, click on “Projects” in the left menu, and then on “Create project”. Choose a name and set the visibility (do you want everyone to see your code already or wait a bit before sharing with the world?). It is common practice to immediately add a “README” file and add a licence (see next section). You can update the visibility of your repository later under the repository settings.\n\n\nAdding code to your repository\nGitHub: You can create a new file using the “Add file” or “+”-button.\nGitLab: You can create a new file using the “+”-button and click “New file”.\nOnce you have uploaded your files or written your code, you need to write a “commit” message. This is basically a description of the changes you made between the previous version of the code and the current version. Since this is the first version of the files (that is available online) you can write something like “initial”.\nNote: never put sentitive information (like passwords or API keys) in your code.\n\n\nUsing Git locally\nWhen you plan to use GitHub/GitLab more often, adding files through the web interface can become cumbersome. In that case, it is useful to consider using GitHub Desktop or a git manager which is integrated in your IDE (integrated development environment), like Visual Studio Code. Git can also be used on the command line, for example, when using git from a server. The course Learn Git & GitHub provides a useful tutorial on using git from the command line.\nWell done! Your research code is not sitting on your own computer (or worse – deleted after publication*), but is available online for others to find. This is step one in following the FAIR principles. In the remainder of this guide, you will find steps that will guide you through all steps to release a “perfect” code repository. The first sections are most important, further sections provide room for further improvement, so please use this guide at your own discretion.\n*VU Amsterdam requires research data and software to be preserved for at least 10 years, unless legal provisions or discipline-specific guidelines dictate otherwise, as per the Research Data and Software Management Policy. Note that funding organisations may have specific requirements for preserving code as well. If you receive external funding for your research, please make sure to familiarise yourself with such requirements."
  },
  {
    "objectID": "guides/publishing-fair-software.html#licence",
    "href": "guides/publishing-fair-software.html#licence",
    "title": "How can you publish FAIR software",
    "section": "Licence",
    "text": "Licence\n\nLicensing software\nPublishing research software under an appropriate licence is crucial for its accessibility, usability, and further integration into research. Choosing a licence usually happens right when you start developing the software or when you put it in a public repository, rather than when the software is finished and fully baked.\nA software licence states how other people may re-use your code and under which circumstances. For research software, it is recommended (and often required by funders) that licences are as permissible as possible.\nThere are many licences out there; below we list some very frequently used licences in research software. However, if none of these licences fit your case, there are several tools that can help you to choose a suitable software licence. If you need guidance in choosing a licence for your software, get in touch with the RDM Support Desk.\n\n\nMIT License\nThe MIT License is a popular choice, due to its readability and permissiveness. It allows users to reuse the software for any purpose, including using, copying, modifying, and distributing it, provided they include the original copyright notice and licence text.\nHowever, its permissiveness means that derivative works can be closed-source and do not need to mention that they use your code, which might not align with all scientific openness goals or general.\n\n\nGNU GPLv3\nThe GNU General Public License (GPLv3) is another option, designed to ensure that the software and any derivatives remain open-source.\nThis encourages collaborative improvement of software. Any software that includes GPL-licensed code must also be open-source under the GPLpotentially deterring commercial use or integration with proprietary software. In conclusion, when you want your code to be used by others, but only the code that uses your code is also open source, this is the way to go.\n\n\nApache License 2.0\nThe Apache License 2.0 allows for modification and distribution of the software and its derivative works, with the requirement that changes to the original code are documented.\nIt is a more complex licence than the MIT License and can be incompatible with GPL-licensed software. The specifics of this go beyond the scope of the handbook.\n\n\nAdding a licence to GitHub\nOn GitHub you add a licence on creating a new repository, by selecting the licence from the drop-down menu. If your repository already exists, add a new file called “LICENSE” using the “+”-button on top of the repository (see below).\n\n\n\nLocation of file creation button\n\n\nOne the next page, start to type LICENSE as the file name, and a button to “Choose a license template” should automatically pop up. Follow the steps provided by GitHub to finish adding the licence to the repository.\nYou should now see your licence shown on the main page of your repository.\n\n\nFurther considerations\n\nIf you are reusing software or libraries written by someone else, you must stick to the clauses of the licence given to the original software/library;\nWhen choosing a licence, do not just think about what others may do with the software, but also what you might want to do with the software in the future."
  },
  {
    "objectID": "guides/publishing-fair-software.html#persistent-identifier",
    "href": "guides/publishing-fair-software.html#persistent-identifier",
    "title": "How can you publish FAIR software",
    "section": "Persistent Identifier",
    "text": "Persistent Identifier\nA persistent identifier is a durable reference to a digital dataset, document, website or other object. A Digital Object Identifier (DOI) is a widely used Persistent Identifier in the research domain and hence for research software as well. There are two ways to generate a DOI for your code. Depending on how often you intend to update your code, one or the other may be simpler.\n\nIf you do not intend to update your code often, it is sufficient to upload your code separately to Zenodo (or similar repository). This will then automatically generate a DOI for you, which can be included in a publication.\nIf however, you intend to update your code frequently, it may be easier to set up an automatic link between GitHub and Zenodo, so that a new version of the code is released on Zenodo on publication of a new version on GitHub. You can find instructions for this in this guide on referencing and citing content."
  },
  {
    "objectID": "guides/publishing-fair-software.html#readme-commenting-code-formatting",
    "href": "guides/publishing-fair-software.html#readme-commenting-code-formatting",
    "title": "How can you publish FAIR software",
    "section": "Readme, commenting, code formatting",
    "text": "Readme, commenting, code formatting\nTo allow others to understand and use your code effectively it is important to include a “README” file, and to comment your code.\n\nReadme file\nThe README file is the general introduction to a code repository. A good readme includes the following components (but may include other sections depending on the project):\n\nProject Title\nProject description\nInstallation Instructions: Provide step-by-step guidelines to get the project running.\nUsage Examples: Include examples of how to use the code, which can be particularly beneficial for libraries or APIs.\nDependencies: List any libraries or other software required to run the project.\nLicense: Specify the licensing under which the code is released (see above).\nCitation: Collect more citations 😉 by providing researchers a way to easily cite your paper.\n[if applicable] Contributing Guidelines: Explain how others can contribute to the project.\n\nOn GitHub, the README file should ideally be named “README.md”. GitHub automatically renders this file and displays it on the home page of your repository. You can find an example of a README file in the numpy repository.\n\n\nCode commenting\nCode commenting serves several essential purposes, such as enhancing readability, maintainability, and usability for original authors, future contributors and others interested in your code. Comments provide context or explanations for complex logic, variables, and algorithms, making the codebase accessible and understandable. Good practices include describing the purpose of functions, explaining the rationale behind decisions, and highlighting potential side effects.\nA huge part of commenting your code is variable naming. Good variable naming can go a long way in making your code “self-documenting”. In general, do not use abbreviations or very short variable names. This may save a couple of keystrokes when writing your code, but this time is easily recovered when looking at the code again months later. Good variable naming will help your colleagues or other interested people even more. Modern integrated development environments also usually include autocompletion.\n\n\nCode formatting\nConsistency in code formatting, and adherence to standards can be highly beneficial, allowing other people and yourself to more quickly grasp your code. Each language has different conventions. For example, Python uses PEP8, for which some examples are given below:\n\nUse 4 spaces as indentation\nlocal variable_names are all lowercase\nClassNames have each word starting with a Capital letter\nGLOBAL_VARIABLES are all uppercase\n\nOther examples are Google’s R Style Guide and Google’s C++ Style Guide.\n\n\nCode formatting tools\nYou can also configure Visual Studio Code to automatically help you formatting your code. You can find more information in the Visual Studio code formatting manual. Even more strict formatting can be done with ruff, which is PEP8-compliant but introduces additional rules. ruff can also format your code in place, running ruff format {source_file_or_directory}.\nYou can also use GitHub Actions to automatically check and format your code when you push new commits to your repository. For example for Python, ruff publishes GitHub actions that can be used to automatically check and format your code.\nIf you follow the steps above, your code is now following the FAIR principles already! However, there is always room for improvement. Further steps are explained below."
  },
  {
    "objectID": "guides/publishing-fair-software.html#documentation",
    "href": "guides/publishing-fair-software.html#documentation",
    "title": "How can you publish FAIR software",
    "section": "Documentation",
    "text": "Documentation\nExtensive documentation can help users of your code re-use your code effectively. There are some great tools out there to help you automatically build documentation from your code comments, which can be supplemented with general documentation. Sphinx is a great way to do this, and can be nicely integrated with your existing GitHub repository. An example of code documentation can be found in the ReadTheDocs documentation, which uses Sphinx. This guide is not meant to be a full guide on how to use Sphinx as many useful resources can be found on the internet. An example of a great resource is this blog post.\n\nInstalling Sphinx\nTo use Sphinx for automatic documentation generation in a GitHub repository, start by installing Sphinx using pip (pip install sphinx). Next, run sphinx-quickstart in your project’s root directory to generate the basic configuration (conf.py) and structure for your documentation.\n\n\nAutomatic documentation building\nDocumentation can be automatically updated when you push new commits to your GitHub repository. To do so, you can set up a continuous integration (CI) workflow using GitHub Actions. In a workflow file, you specify the steps to install Sphinx, build the documentation using the sphinx-build command, and then push the generated HTML files to the gh-pages branch or another branch designated for hosting your documentation. A guide on how to set this up can be found in this Sphinx manual.\nThis guide is not meant to be a full guide on how to use Sphinx, as many useful resources can be found on the internet. However, some useful resources (here, and here) are listed, and pointers are given.\n\n\nAutomatically documenting your code\nTo document a Python function using autodoc, ensure that the functions in your code have a properly formatted docstring. For example:\ndef add_numbers(a, b):\n    \"\"\"\n    Adds two numbers together.\n\n    :param a: first number\n    :type a: int or float\n    :param b: second number\n    :type b: int or float\n    :return: The sum of `a` and `b`\n    :rtype: int or float\n    \"\"\"\n    return a + b\nIn the conf.py file, enable the autodoc extension by adding 'sphinx.ext.autodoc' to the extensions list. This extension allows Sphinx to generate documentation directly from your source code’s docstrings. Then, in your Sphinx documentation source directory (usually docs/source), create a .rst file where you want this function’s documentation to appear. Use the autofunction directive to automatically include the function’s documentation:\n.. autofunction:: path.to.module.add_numbers\nReplace path.to.module with the actual Python import path to your function. Sphinx will extract the docstring from the function and incorporate it into the generated documentation, complete with the parameter descriptions and types."
  },
  {
    "objectID": "guides/publishing-fair-software.html#released-as-a-package",
    "href": "guides/publishing-fair-software.html#released-as-a-package",
    "title": "How can you publish FAIR software",
    "section": "Released as a package",
    "text": "Released as a package\nCreating a Python package allows you to share your code with a broader audience, promoting collaboration, and ensuring reproducibility. There are two “levels” of publishing your code. First of all, you can ensure that your code is directly installable from the GitHub repository. To do so, you can follow the steps explained in this Python tutorial, but only up to and including the section “Configuring metadata”. Here, we assume you already created a README.md and added a LICENCE as explained above.\nIn brief, you need to take the following steps, which are explained in full below:\n\nStructure your code as a package\nCreate a metadata file\n\nThen, once this is added to GitHub, you can install the package using the following command (of course adjusted to point to your own repository):\npip install git+https://github.com/your_username/your_repository.git\n\nPyPi\nIf this works, you can go on to the next step and publish your package on PyPi. When your package is published here, it is possible to directly install your code from pip, as such:\npip install your_package\nFor a full explanation of how to do so, follow the remaining steps explained in this Python tutorial.\n\n\nAutomatic publishing versions\nIf you publish new versions frequently, it may be useful to automatically release these versions to PyPi, directly from GitHub without taking manual steps. To do so, you can follow the guide in this repository on PyPI publish GitHub Action."
  },
  {
    "objectID": "guides/publishing-fair-software.html#testing",
    "href": "guides/publishing-fair-software.html#testing",
    "title": "How can you publish FAIR software",
    "section": "Testing",
    "text": "Testing\nTesting your code is a crucial aspect of software development, ensuring that your application behaves as expected and maintains a high level of quality. You can usually catch bugs much earlier, although it also requires some investment, especially in the beginning. Apart from catching bugs, testing can also focus on syntax use.\n\nCode testing\nOne of the most frequently used Python packages for software testing is pytest. Here are some quick steps to set up pytest in your repository:\n\nPython\n\nInstall pytest:\npip install pytest\nCreate a tests directory in your repository’s main folder.\nAssuming you have a function called add_one in the file my_package/math_functions.py, you can start by creating a test file within the tests directory to test this function:\n# my_package/math_functions.py\ndef add_one(x):\n    return x + 1\nCreate a test file named test_math_functions.py inside the tests directory. This file will contain the tests for your add_one function:\n# tests/test_math_functions.py\nfrom my_package.math_functions import add_one\n\ndef test_add_one():\n    assert add_one(1) == 2\n    assert add_one(0) == 1\n    assert add_one(-1) == 0\n    assert add_one(100) == 101\nRun the tests by executing pytest from the command line. Navigate to your project’s root directory and run:\npytest\n\n\n\nR\nFor R, the most frequently used package for software testing is testthat, more information can be found in the testthat repository.\n\n\nC++\nFor C++, there are a lot of different testing frameworks available, but one of the most frequently used are Catch2 and Google Test.\n\n\n\nTesting tools\n\nThe Visual Studio Code Python extension has really good support for testing, saving you lots of time.\nOn GitHub, you can use GitHub Actions to automatically run your tests when you push new commits to your repository. For example for Python, pytest publishes GitHub actions that can be used to automatically run your tests."
  },
  {
    "objectID": "guides/publishing-fair-software.html#updating",
    "href": "guides/publishing-fair-software.html#updating",
    "title": "How can you publish FAIR software",
    "section": "Updating",
    "text": "Updating\nRegularly updating your repository and engaging with users can help build a community around your software. For example, users can report bugs to your repository or even contribute to new features (or fix those bugs).\n\nGitHub Issues\nGitHub Issues is a feature that allows project maintainers and contributors to track tasks, enhancements, and bugs for their projects. It can be found by clicking on “Issues” for most repositories (unless explicitly disabled). For example, issues can be used to:\n\nReport Bugs: Users and developers can report bugs they encounter, including descriptions, steps to reproduce, and screenshots.\nRequest Features: Suggestions for new features or improvements can be tracked as issues, allowing maintainers to prioritize and discuss them."
  },
  {
    "objectID": "guides/publishing-fair-software.html#publication",
    "href": "guides/publishing-fair-software.html#publication",
    "title": "How can you publish FAIR software",
    "section": "Publication",
    "text": "Publication\nFinally, publishing your code alongside a scientific publication can help build trust in the software you developed. This can, of course, be done in a traditional journal alongside a journal article. However, in some cases, it may be useful to publish your code in a journal specifically focused on software development. Here, we recommend JOSS (Journal of Open Source Software).\nIncreasingly, traditional scientific publications also include a section that describes where the code can be found. This can be a DOI, a link to a GitHub repository, or a link to a Zenodo repository. This allows other researchers to reliably cite your software, which also improves the findability. An example of such a section can be found here:\nCode for data cleaning and analysis is provided as part of the replication package, written in R. The specific code that was used for this article is available at https://doi.org/10.xxxx/path/to/journal/archive, while further updates are released at https://github.com/repository/your_code."
  },
  {
    "objectID": "blog/2024-11-28hackathon.html",
    "href": "blog/2024-11-28hackathon.html",
    "title": "Fifth Handbook Hackathon",
    "section": "",
    "text": "On November 28, 2024, all authors participated in the fifth hackathon for the Research Support Handbook. For this hackathon, we focused on adding new content and consolidating requests.\nWe had a large number of contributions related to tools. The handbook now has information about Research Cloud, SciCloud and Yoda. These were long-standing issues and it is really nice that they turned into topics.\nIrene helped us to revise the metadata topic.\nTycho is working on a page for ORCID, the ORCID Libguide page will be adjusted to redirect to the handbook.\nLena was working on a data backup topic, trying to make it generic and applicable to multiple tools.\nWe had a discussion of an overview page. New colleagues also within support miss an overview of the services available. There are many pages that give some ideas: the RDS portal on Tools, the guide on available services and RISP - but all these overviews have diverse struggles so we are still looking for a good way of doing it.\nITvO colleagues noticed that they miss an official VU page which gives a summary of what ITvO is and does.\nQuestion that came up: how to add new contributors? Do they need access rights? Do they work with forks or branches?"
  },
  {
    "objectID": "blog/2024-11-28hackathon.html#hackathon-issues",
    "href": "blog/2024-11-28hackathon.html#hackathon-issues",
    "title": "Fifth Handbook Hackathon",
    "section": "Hackathon Issues",
    "text": "Hackathon Issues\nhttps://github.com/ubvu/open-handbook/issues/275"
  },
  {
    "objectID": "blog/2024-11-28hackathon.html#hackathon-pull-requests",
    "href": "blog/2024-11-28hackathon.html#hackathon-pull-requests",
    "title": "Fifth Handbook Hackathon",
    "section": "Hackathon Pull Requests",
    "text": "Hackathon Pull Requests\nhttps://github.com/ubvu/open-handbook/pull/277\nhttps://github.com/ubvu/open-handbook/pull/276\nhttps://github.com/ubvu/open-handbook/pull/140\nhttps://github.com/ubvu/open-handbook/pull/273\nMerged https://github.com/ubvu/open-handbook/pull/270#pullrequestreview-2467652120"
  },
  {
    "objectID": "blog/2024-09-30hackathon.html",
    "href": "blog/2024-09-30hackathon.html",
    "title": "Third Handbook Hackathon",
    "section": "",
    "text": "In the third hackathon for the Research Support Handbook, held on September 25th, 2024, contributors gathered to make significant progress towards migrating the handbook to the VU domain (rdm.vu.nl). The event centered around sprinting to a finish line by refining existing content and ensuring accessibility standards are met.\nKey activities included:\nOverall, the hackathon was a productive session, and the handbook is now in its final stage, with the team preparing for the official launch on &lt;rdm.vu.nl&gt;. In next hackathons, we may focus on splitting existing topics and adding new ones, as our list of idea topics is growing rapidly."
  },
  {
    "objectID": "blog/2024-09-30hackathon.html#hackathon-issues",
    "href": "blog/2024-09-30hackathon.html#hackathon-issues",
    "title": "Third Handbook Hackathon",
    "section": "Hackathon Issues",
    "text": "Hackathon Issues\nhttps://github.com/ubvu/open-handbook/issues/175 https://github.com/ubvu/open-handbook/issues/178"
  },
  {
    "objectID": "blog/2024-09-30hackathon.html#hackathon-pull-requests",
    "href": "blog/2024-09-30hackathon.html#hackathon-pull-requests",
    "title": "Third Handbook Hackathon",
    "section": "Hackathon Pull Requests",
    "text": "Hackathon Pull Requests\nhttps://github.com/ubvu/open-handbook/pull/118 https://github.com/ubvu/open-handbook/pull/165 https://github.com/ubvu/open-handbook/pull/176 https://github.com/ubvu/open-handbook/pull/177 https://github.com/ubvu/open-handbook/pull/179 https://github.com/ubvu/open-handbook/pull/180 https://github.com/ubvu/open-handbook/pull/181 https://github.com/ubvu/open-handbook/pull/184 https://github.com/ubvu/open-handbook/pull/186 https://github.com/ubvu/open-handbook/pull/188"
  },
  {
    "objectID": "blog/2025-07-24hackathon.html",
    "href": "blog/2025-07-24hackathon.html",
    "title": "Sixth Handbook Hackathon",
    "section": "",
    "text": "On July 24, 2025, all authors participated in the sixth hackathon for the Research Support Handbook. For this hackathon, we focused on adding and updating topics."
  },
  {
    "objectID": "blog/2025-07-24hackathon.html#overview-of-results",
    "href": "blog/2025-07-24hackathon.html#overview-of-results",
    "title": "Sixth Handbook Hackathon",
    "section": "Overview of results",
    "text": "Overview of results\nNew topics that we have added during or in the days after the Hackathon:\n\nITvO\nPure\nCARE Principles\nSoftware Archiving\nSoftware Publishing\nOSF\n\nWe have started on the following topics, but these still need some work before they can be published:\n\nRDM tools overview (to replace the current one on the VU website)\nDe-identifying data: Pseudonymisation and Anonymisation\nInformed consent forms (content will be discussed with the privacy experts)\n\nThe following topics have been updated:\n\nDMP: we moved the instructions for selecting the VU DMP template to the guide How can you set up research data management from the start?\n\nWe worked on some guides as well:\n\nWe updated the guide What research data services and support are available for VU researchers?\nWe transferred all information related to OSF from the VU OSF Wiki to the Handbook, resulting in a topic (see above) and a guide How can you use Open Science Framework (OSF) in your research project?\nWe updated the guide How can you set up research data management from the start?, where we included the instructions for selecting the VU DMP template\n\nIn addition, we introduced a new type of page: Manuals (a big thanks to Peter, who put a lot of effort in preparing this 🙏). A user manual provides guidance and instructions to users of a tool. User manuals are created to be easily understood by individuals with varying levels of technical knowledge. It can be assumed that most of the tools will already have their own manuals on the suppliers website. We will link to those as much as possible, we don’t want to duplicate information. If you’re interested, you can read more in Issue #416. The Yoda manuals have now been included in the Handbook (the website yoda.vu.nl will be phased out). Manuals on the handbook will be written in the form of a how-to, the aim is to provide guidance for specific tasks “How do I?”. From the basic: “How do I log in” to the more in-depth “How do I use CUDA on ADA”.\nFinally, we also worked on contributing guidelines and categorised the blog posts, introducing a new type of blog post by ITvO:\n\nInstructions for using VSCode to contribute\nUpdated instructions for rendering the Research Support Handbook locally\nIntroduced Blog categories and ITvO Blog"
  },
  {
    "objectID": "blog/2025-07-24hackathon.html#hackathon-issues-and-pull-requests",
    "href": "blog/2025-07-24hackathon.html#hackathon-issues-and-pull-requests",
    "title": "Sixth Handbook Hackathon",
    "section": "Hackathon Issues and Pull Requests",
    "text": "Hackathon Issues and Pull Requests\n\n(Yoda) manuals: Issue #416 and PR #484\nInformation about ITvO: Issue #344 and PR #516\nSoftware Archiving: Issue #354 and PR #500\nSoftware Publishing: Issue #354 and PR #501\nOSF: Issue #100 and PR #538 (topic) and PR #541 (guide)\nCARE Principles: Issue #448 and PR #503\nWhat research data services and support are available for VU researchers? PR #530\nPure: Issue #482 and PR #497 and #PR 537\nHow can you set up research data management from the start?: PR #524\nDMP: PR #525\nUsing VSCode to contribute: PR #509\nRendering Handbook locally: PR #463\nIntroducing Blog categories and ITvO Blog PR #533"
  },
  {
    "objectID": "blog/2025-07-24hackathon.html#ai-generated-texts",
    "href": "blog/2025-07-24hackathon.html#ai-generated-texts",
    "title": "Sixth Handbook Hackathon",
    "section": "AI-generated texts",
    "text": "AI-generated texts\nIn preparation for this hackathon, we had some texts for new topics drafted by Claude LLM, as part of a trial to explore AI-assisted content creation for the handbook. The idea was that it is easier for people to review existing content than creating something from scratch. During the hackathon, most people seemed to have a preference for writing text themselves. It is more fun, and part of the content created by Claude LLM was not useful. So for now, we think we will keep writing our own texts."
  },
  {
    "objectID": "blog/2025-05-15embed-iframe.html",
    "href": "blog/2025-05-15embed-iframe.html",
    "title": "How to embed handbook pages using iframes",
    "section": "",
    "text": "If you want to reuse content from the Research Support Handbook, you can do so using an HTML iframe. This post will help you through the steps to successfully embed a handbook page on a website you administer."
  },
  {
    "objectID": "blog/2025-05-15embed-iframe.html#selecting-what-to-embed",
    "href": "blog/2025-05-15embed-iframe.html#selecting-what-to-embed",
    "title": "How to embed handbook pages using iframes",
    "section": "Selecting what to embed",
    "text": "Selecting what to embed\nBefore we can embed a page, we need to select what to embed.\nEach page in the Research Support Handbook has sections, which can be used as anchors for embedding the content. This ensures that the right page shows up displaying the right content.\nFor example, if you are interested in the DataverseNL page, you can select any of the headings as an anchor. Here are the steps involved:\n\nIdentify the specific anchor to embed at (for example, “How to request access”)\nClick the link icon next to the anchor\n\n\n\n\nScreenshot of the anchor and the link icon highlighted\n\n\n\nGo to your browser’s navigation bar and copy the new link (https://rdm.vu.nl/topics/dataversenl.html#how-to-request-access)\n\nThis link is all you need to anchor the embedding itself, which we explain in the section How to embed."
  },
  {
    "objectID": "blog/2025-05-15embed-iframe.html#how-to-embed",
    "href": "blog/2025-05-15embed-iframe.html#how-to-embed",
    "title": "How to embed handbook pages using iframes",
    "section": "How to embed",
    "text": "How to embed\nAfter you identified the page and possible anchor to embed, we can now move on to actually embedding it. Embedding the pages themselves is supported by all major browsers using the HTML element iframe.\nConcretely, you can use the following example code for the link we found in Selecting what to embed.\n&lt;iframe\n    src=\"https://rdm.vu.nl/topics/dataversenl.html#how-to-request-access\"\n    title=\"How to request access to DataverseNL\"\n    width=\"100%\"\n    height=\"300px\"\n    loading=lazy\n    style=\"border: solid 1px #0080c9\"&gt;\n&lt;/iframe&gt;\nYou can switch out the link, title, and other attributes to your liking – we include some styling options here to get started. You can copy-paste this into any handbook page directly or into any HTML editor:\n\n\nYou can find the detailed code on how this page embeds the content, on GitHub, from line 43.\nThanks for reading and good luck creating your own embeds of the Research Support Handbook across VU Amsterdam pages 😊 If you have questions or it does not work and you don’t understand why, please contact the RDM Support Desk and one of the editors will try to help you."
  },
  {
    "objectID": "blog/2025-07-28manuals.html",
    "href": "blog/2025-07-28manuals.html",
    "title": "New Manuals section in the Handbook",
    "section": "",
    "text": "Last week we added a new section to the Research Support Handbook: Manuals. Manuals are short pages describing how to accomplish specific tasks in a Tool and should be easily understood by individuals with varying levels of technical knowledge. Manuals on the handbook will be written in the form of a how-to. The aim is to provide guidance for specific tasks “How do I?”. From the basic: “How do I log in” to the more in-depth “How do I use CUDA on ADA”.\nWe have started by migrating the manuals on using Yoda, from their old spot on yoda.vu.nl. Next step will be migrating the ADA HPC manuals from readthedocs.\nBy consolidating all user manuals on the Research Support Handbook we hope to increase the findability of both the manuals and the rest of the Research Support Handbook."
  },
  {
    "objectID": "blog/2025-07-28manuals.html#maintaining-the-manuals",
    "href": "blog/2025-07-28manuals.html#maintaining-the-manuals",
    "title": "New Manuals section in the Handbook",
    "section": "Maintaining the manuals",
    "text": "Maintaining the manuals\nEven more than Topic and Guide pages, Manuals have a short shelf life. Hence, they must be checked regularly. Each manual will have one or two support staff responsible for keeping it up to date. To make sure enough time is set aside to work on the manuals we plan to have two update moments per year, perhaps in the form of a Hackathon."
  },
  {
    "objectID": "blog/2024-09-05hackathon.html",
    "href": "blog/2024-09-05hackathon.html",
    "title": "Second Handbook Hackathon",
    "section": "",
    "text": "On September 5th, 2024, all authors participated in the second hackathon for the Research Support Handbook. For this hackathon, we focused on quality assurance. Quality assurance is crucial in ensuring that all parties at VU Amsterdam feel confident adopting this evolving, community-led resource as an official university page. Our goal is to migrate the handbook to rdm.vu.nl in the near future, which requires us to everything is in tip-top shape.\nCollectively, we proofread the migrated LibGuide pages. The result of this are seven GitHub issues and nine pull requests for revisions. These include making sure all images are migrated into the handbook, ensuring appropriate page titles, and refining the contribution guide.\nDuring the hackathon, we observed a lot of links in the old LibGuide resource, are broken. We did some much needed maintenance work during the hackathon, given that the Research Support Handbook will replace the LibGuide resource. We identified broken links and replaced them where possible. There is a need to make this a less manual process in the future and will seek out automations to help us maintain the links moving forward. Additionally, there are many internal links that need updating, changing from LibGuide URLs to GitHub pages. We also discovered several links accessible only with university credentials, which we believe detract from the user experience; these links will require special labeling and contextualization.\nThe general sentiment at the end of the hackathon is that there is still lots of work to do. The community standards are manifesting themselves, and it is clear that pathways need more work to be production ready. These discussions surfaced a wish to have more frequent hackathons at this time, until the standards are set and the included content is ready for rdm.vu.nl."
  },
  {
    "objectID": "blog/2024-09-05hackathon.html#hackathon-issues",
    "href": "blog/2024-09-05hackathon.html#hackathon-issues",
    "title": "Second Handbook Hackathon",
    "section": "Hackathon Issues",
    "text": "Hackathon Issues\n\nhttps://github.com/ubvu/open-handbook/issues/123\nhttps://github.com/ubvu/open-handbook/issues/128\nhttps://github.com/ubvu/open-handbook/issues/125\nhttps://github.com/ubvu/open-handbook/issues/124\nhttps://github.com/ubvu/open-handbook/issues/123\nhttps://github.com/ubvu/open-handbook/issues/130\nhttps://github.com/ubvu/open-handbook/issues/131"
  },
  {
    "objectID": "blog/2024-09-05hackathon.html#hackathon-pull-requests",
    "href": "blog/2024-09-05hackathon.html#hackathon-pull-requests",
    "title": "Second Handbook Hackathon",
    "section": "Hackathon Pull Requests",
    "text": "Hackathon Pull Requests\n\nhttps://github.com/ubvu/open-handbook/pull/126\nhttps://github.com/ubvu/open-handbook/pull/110\nhttps://github.com/ubvu/open-handbook/pull/127\nhttps://github.com/ubvu/open-handbook/pull/129\nhttps://github.com/ubvu/open-handbook/pull/132\nhttps://github.com/ubvu/open-handbook/pull/133\nhttps://github.com/ubvu/open-handbook/pull/134\nhttps://github.com/ubvu/open-handbook/pull/135"
  },
  {
    "objectID": "lifecycle/03-collect-store.html",
    "href": "lifecycle/03-collect-store.html",
    "title": "Collect & Store",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nData Backup\n\n\n3 min\n\n\n\n\n\n\nData Collection\n\n\n6 min\n\n\n\n\n\n\nData Protection\n\n\n5 min\n\n\n\n\n\n\nData Storage\n\n\n5 min\n\n\n\n\n\n\nQualtrics\n\n\n5 min\n\n\n\n\n\n\nResearch Drive\n\n\n4 min\n\n\n\n\n\n\nSafe Data Transportation and Transfer\n\n\n4 min\n\n\n\n\n\n\nSciStor\n\n\n7 min\n\n\n\n\n\n\nYoda\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/03-collect-store.html#topics",
    "href": "lifecycle/03-collect-store.html#topics",
    "title": "Collect & Store",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nData Backup\n\n\n3 min\n\n\n\n\n\n\nData Collection\n\n\n6 min\n\n\n\n\n\n\nData Protection\n\n\n5 min\n\n\n\n\n\n\nData Storage\n\n\n5 min\n\n\n\n\n\n\nQualtrics\n\n\n5 min\n\n\n\n\n\n\nResearch Drive\n\n\n4 min\n\n\n\n\n\n\nSafe Data Transportation and Transfer\n\n\n4 min\n\n\n\n\n\n\nSciStor\n\n\n7 min\n\n\n\n\n\n\nYoda\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/03-collect-store.html#guides",
    "href": "lifecycle/03-collect-store.html#guides",
    "title": "Collect & Store",
    "section": "Guides",
    "text": "Guides\n\n\n\n\n\n\n\n\n\n\nHow can you ensure data protection and security during collection, storage, and transfer?\n\n\nLearn about how to secure research data at any stage.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you use Open Science Framework (OSF) in your research project?\n\n\nOSF supports an open research life cycle.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/04-process-analyse.html",
    "href": "lifecycle/04-process-analyse.html",
    "title": "Process & Analyse",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nADA HPC\n\n\n4 min\n\n\n\n\n\n\nSURF Research Cloud\n\n\n3 min\n\n\n\n\n\n\nSafe Data Transportation and Transfer\n\n\n4 min\n\n\n\n\n\n\nSciCloud\n\n\n3 min\n\n\n\n\n\n\nSnellius\n\n\n3 min\n\n\n\n\n\n\nVU Compute Hub\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/04-process-analyse.html#topics",
    "href": "lifecycle/04-process-analyse.html#topics",
    "title": "Process & Analyse",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nADA HPC\n\n\n4 min\n\n\n\n\n\n\nSURF Research Cloud\n\n\n3 min\n\n\n\n\n\n\nSafe Data Transportation and Transfer\n\n\n4 min\n\n\n\n\n\n\nSciCloud\n\n\n3 min\n\n\n\n\n\n\nSnellius\n\n\n3 min\n\n\n\n\n\n\nVU Compute Hub\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/04-process-analyse.html#guides",
    "href": "lifecycle/04-process-analyse.html#guides",
    "title": "Process & Analyse",
    "section": "Guides",
    "text": "Guides\n\n\n\n\n\n\n\n\n\n\nHow can you ensure data provenance and accurate data analysis?\n\n\nWhere data and results come from matters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you use Open Science Framework (OSF) in your research project?\n\n\nOSF supports an open research life cycle.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/01-discover-initiate.html",
    "href": "lifecycle/01-discover-initiate.html",
    "title": "Discover & Initiate",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nFinding Existing Data\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/01-discover-initiate.html#topics",
    "href": "lifecycle/01-discover-initiate.html#topics",
    "title": "Discover & Initiate",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nFinding Existing Data\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lifecycle/01-discover-initiate.html#guides",
    "href": "lifecycle/01-discover-initiate.html#guides",
    "title": "Discover & Initiate",
    "section": "Guides",
    "text": "Guides\n\n\n\n\n\n\n\n\n\n\nHow can you discover and reuse existing research data?\n\n\nThere is so much data out there, that we want to help you find your way more easily.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]